{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "19jBb471CTj5"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import yfinance as yf  # For downloading stock data\n",
    "import ta  # For technical analysis indicators\n",
    "from sklearn.preprocessing import RobustScaler  # For scaling features\n",
    "from sklearn.model_selection import TimeSeriesSplit  # For time series cross-validation\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Gradient Boosting model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error  # For model evaluation\n",
    "from sklearn.feature_selection import SelectFromModel  # For feature selection\n",
    "from sklearn.pipeline import Pipeline  # For creating a model pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # For custom transformers\n",
    "from sklearn.impute import SimpleImputer# For handling missing values\n",
    "from sklearn.feature_selection import RFECV, mutual_info_regression\n",
    "from xgboost import XGBRegressor  # XGBoost model\n",
    "from lightgbm import LGBMRegressor  # LightGBM model\n",
    "from keras.models import Sequential  # For building neural networks\n",
    "from keras.layers import LSTM, Dense, Dropout  # Layers for LSTM model\n",
    "from keras.optimizers import Adam  # Adam optimizer for neural networks\n",
    "import optuna  # For hyperparameter optimization\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX  # For SARIMA modeling\n",
    "from prophet import Prophet  # Facebook's Prophet model for time series forecasting\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import shap  # For model interpretability\n",
    "from textblob import TextBlob  # For sentiment analysis\n",
    "import requests  # For making HTTP requests\n",
    "import json\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing  # For Holt-Winters' exponential smoothing\n",
    "from pmdarima import auto_arima  # For automatic ARIMA modeling\n",
    "from sklearn.linear_model import ElasticNet  # Elastic Net regression\n",
    "from sklearn.ensemble import VotingRegressor  # For ensemble modeling\n",
    "from datetime import datetime, timedelta  # For date and time operations\n",
    "import pytz  # For timezone handling\n",
    "import torch  # PyTorch for deep learning\n",
    "import torch.nn as nn  # Neural network modules\n",
    "import torch.optim as optim  # Optimization algorithms\n",
    "from torch.utils.data import DataLoader, TensorDataset  # For data loading\n",
    "from transformers import TimeSeriesTransformerModel, TimeSeriesTransformerConfig  # For time series transformers\n",
    "import gym  # For reinforcement learning environments\n",
    "from stable_baselines3 import PPO  # Proximal Policy Optimization algorithm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv  # For vectorized environments\n",
    "import warnings  # For handling warnings\n",
    "from sklearn.feature_selection import RFECV  # Recursive Feature Elimination with Cross-Validation\n",
    "from sklearn.linear_model import LassoCV  # Lasso regression with built-in cross-validation\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bykl1WP4C3Fv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3485 entries, 2015-01-01 00:00:00+00:00 to 2024-08-22 00:00:00+00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Open       3485 non-null   float64\n",
      " 1   High       3485 non-null   float64\n",
      " 2   Low        3485 non-null   float64\n",
      " 3   Close      3485 non-null   float64\n",
      " 4   Adj Close  3485 non-null   float64\n",
      " 5   Volume     3485 non-null   int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 190.6 KB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2015-01-01 00:00:00+00:00  320.434998  320.434998  314.002991  314.248993   \n",
      "2015-01-02 00:00:00+00:00  314.079010  315.838989  313.565002  315.032013   \n",
      "2015-01-03 00:00:00+00:00  314.846008  315.149994  281.082001  281.082001   \n",
      "2015-01-04 00:00:00+00:00  281.145996  287.230011  257.612000  264.195007   \n",
      "2015-01-05 00:00:00+00:00  265.084015  278.341003  265.084015  274.473999   \n",
      "\n",
      "                            Adj Close    Volume  \n",
      "Date                                             \n",
      "2015-01-01 00:00:00+00:00  314.248993   8036550  \n",
      "2015-01-02 00:00:00+00:00  315.032013   7860650  \n",
      "2015-01-03 00:00:00+00:00  281.082001  33054400  \n",
      "2015-01-04 00:00:00+00:00  264.195007  55629100  \n",
      "2015-01-05 00:00:00+00:00  274.473999  43962800  \n",
      "\n",
      "Column Data Types:\n",
      "Open         float64\n",
      "High         float64\n",
      "Low          float64\n",
      "Close        float64\n",
      "Adj Close    float64\n",
      "Volume         int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "               Open          High           Low         Close     Adj Close  \\\n",
      "count   3485.000000   3485.000000   3485.000000   3485.000000   3485.000000   \n",
      "mean   18175.149220  18614.142366  17703.444568  18192.151237  18192.151237   \n",
      "std    19472.443453  19928.809741  18970.720503  19483.191509  19483.191509   \n",
      "min      176.897003    211.731003    171.509995    178.102997    178.102997   \n",
      "25%     1984.239990   2084.729980   1890.250000   1998.859985   1998.859985   \n",
      "50%     9380.870117   9566.810000   9193.709961   9384.450000   9384.450000   \n",
      "75%    29409.220000  30016.540000  28962.890000  29410.720000  29410.720000   \n",
      "max    73118.090000  73802.640000  71329.700000  73118.090000  73118.090000   \n",
      "\n",
      "             Volume  \n",
      "count  3.485000e+03  \n",
      "mean   9.561933e+08  \n",
      "std    2.492694e+09  \n",
      "min    3.495960e+06  \n",
      "25%    2.726201e+07  \n",
      "50%    4.709759e+07  \n",
      "75%    1.113490e+08  \n",
      "max    2.384090e+10  \n",
      "\n",
      "Missing Values:\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_bitcoin_data_yfinance_format(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetching Bitcoin price data from multiple sources and combining them into a single DataFrame.\n",
    "\n",
    "    This function retrieves data from yfinance for dates before 2019-01-24,\n",
    "    and from CryptoCompare for dates from 2019-01-24 onwards. We use this hybrid \n",
    "    approach because CryptoCompare doesn't have data before 2019-01-24, and we \n",
    "    prefer to use CryptoCompare for more recent data as it provides more up-to-date \n",
    "    and point-in-time accurate information for cryptocurrency prices.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Converting date strings to datetime objects in UTC\n",
    "    start_dt = pd.to_datetime(start_date).tz_localize('UTC')\n",
    "    end_dt = pd.to_datetime(end_date).tz_localize('UTC')\n",
    "\n",
    "    # Defining the split date (2019-01-24)\n",
    "    split_date = pd.Timestamp('2019-01-24').tz_localize('UTC')\n",
    "\n",
    "    # Fetching data from yfinance for dates before 2019-01-24\n",
    "    if start_dt < split_date:\n",
    "        yf_end_date = min(split_date, end_dt)\n",
    "        yf_data = yf.download(\"BTC-USD\", start=start_dt, end=yf_end_date)\n",
    "        yf_data = yf_data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "        yf_data.index = yf_data.index.tz_localize('UTC') \n",
    "    else:\n",
    "        yf_data = pd.DataFrame()\n",
    "\n",
    "    # Fetching data from CryptoCompare for dates from 2019-01-24 onwards\n",
    "    if end_dt >= split_date:\n",
    "        cc_start_date = max(start_dt, split_date)\n",
    "        cc_end_ts = int(end_dt.timestamp())\n",
    "        cc_days_diff = (end_dt - cc_start_date).days + 1\n",
    "\n",
    "        url = \"https://min-api.cryptocompare.com/data/v2/histoday\"\n",
    "        limit = min(cc_days_diff, 2000) \n",
    "\n",
    "        params = {\n",
    "            \"fsym\": \"BTC\",\n",
    "            \"tsym\": \"USD\",\n",
    "            \"limit\": limit,\n",
    "            \"toTs\": cc_end_ts\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()['Data']['Data']\n",
    "            cc_data = pd.DataFrame(data)\n",
    "            cc_data['Date'] = pd.to_datetime(cc_data['time'], unit='s', utc=True)\n",
    "            cc_data.set_index('Date', inplace=True)\n",
    "            cc_data = cc_data[['open', 'high', 'low', 'close', 'volumefrom']]\n",
    "            cc_data.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "            cc_data['Adj Close'] = cc_data['Close']\n",
    "\n",
    "            # Round price columns to 6 decimal places\n",
    "            for col in ['Open', 'High', 'Low', 'Close', 'Adj Close']:\n",
    "                cc_data[col] = cc_data[col].round(6)\n",
    "\n",
    "            # Converting volume to integer\n",
    "            cc_data['Volume'] = (cc_data['Volume'] * 1000).astype(int)\n",
    "\n",
    "            cc_data = cc_data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "        else:\n",
    "            raise Exception(f\"Error fetching data: HTTP {response.status_code}\")\n",
    "    else:\n",
    "        cc_data = pd.DataFrame()\n",
    "\n",
    "    df = pd.concat([yf_data, cc_data])\n",
    "    df = df[~df.index.duplicated(keep='last')]  \n",
    "\n",
    "\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize('UTC')\n",
    "\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    df = df.loc[start_dt:end_dt]\n",
    "\n",
    "    return df\n",
    "\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "df = get_bitcoin_data_yfinance_format(start_date, end_date)\n",
    "\n",
    "print(\"DataFrame Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nColumn Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HiMjYawRC910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from 2015-01-01 00:00:00+00:00 to 2024-08-22 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Loading data from 2015-01-01 to the latest available date\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Fetching Bitcoin data using a custom function \n",
    "df = get_bitcoin_data_yfinance_format(start_date, end_date)\n",
    "\n",
    "print(f\"Using data from {df.index[0]} to {df.index[-1]}\")\n",
    "\n",
    "def get_crypto_sentiment():\n",
    "    \"\"\"\n",
    "    This function uses the free tier of the CryptoPanic API to retrieve recent cryptocurrency\n",
    "    news and posts. It then performs basic sentiment analysis on the post titles using\n",
    "    TextBlob, a simple NLP library. While this approach provides a quick and cost-effective\n",
    "    way to gauge market sentiment, it has limitations in terms of accuracy and depth of analysis.\n",
    "\n",
    "    Returns:\n",
    "    float: Average sentiment score (-1 to 1, where -1 is very negative, 0 is neutral, and 1 is very positive)\n",
    "\n",
    "    Note:\n",
    "    - This function requires a free API key from CryptoPanic. Replace 'API_KEY' in the URL with your actual key.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # CryptoPanic API endpoint (replace API_KEY with your actual API key)\n",
    "        url = \"https://cryptopanic.com/api/v1/posts/?auth_token=API_KEY&currencies=BTC\"\n",
    "    \n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  \n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Calculating sentiment scores for each post title\n",
    "        sentiment_scores = []\n",
    "        for post in data['results']:\n",
    "            text = post['title']\n",
    "            blob = TextBlob(text)\n",
    "            sentiment_scores.append(blob.sentiment.polarity)\n",
    "        \n",
    "        \n",
    "        return np.mean(sentiment_scores) if sentiment_scores else 0\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "    \n",
    "        print(f\"Error fetching sentiment data: {e}\")\n",
    "        return 0  \n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        \n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return 0  \n",
    "    \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Unexpected error in get_crypto_sentiment: {e}\")\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9fSb-_VbNKgx"
   },
   "outputs": [],
   "source": [
    "# Function to classify ROI predictions\n",
    "def classify_prediction(roi):\n",
    "    \"\"\"\n",
    "    Classifies the Return on Investment (ROI) prediction into categories.\n",
    "    \n",
    "    \"\"\"\n",
    "    if roi <= -0.08:\n",
    "        return \"Strong Bear\"\n",
    "    elif -0.08 < roi <= 0:\n",
    "        return \"Weak Bear\"\n",
    "    elif 0 < roi <= 0.06:\n",
    "        return \"Choppy\"\n",
    "    elif 0.06 < roi <= 0.16:\n",
    "        return \"Weak Bull\"\n",
    "    else:\n",
    "        return \"Strong Bull\"\n",
    "\n",
    "# Custom transformer for Recursive Feature Elimination with Cross-Validation\n",
    "class RFECVTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom transformer that performs feature selection using SelectFromModel.\n",
    "\n",
    "    This transformer is designed to work with scikit-learn's pipeline and\n",
    "    cross-validation tools.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, step=1, cv=5):\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.step = step\n",
    "        self.cv = cv\n",
    "        self.selector = SelectFromModel(estimator=estimator, threshold='median')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.selector.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        return self.selector.transform(X)\n",
    "\n",
    "# Function to calculate double exponential moving average\n",
    "def double_ema(data, period=30):\n",
    "    ema1 = data.ewm(span=period, adjust=False).mean()\n",
    "    ema2 = ema1.ewm(span=period, adjust=False).mean()\n",
    "    return 2 * ema1 - ema2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TNbFWFFxNKeP"
   },
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    # Check if there's enough data to calculate all features\n",
    "    if len(df) < 365:\n",
    "        print(\"Warning: Not enough data to calculate all features. Returning original DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # Calculate 7-day Return on Investment (ROI)\n",
    "    df['7d_ROI'] = df['Close'].pct_change(7)\n",
    "\n",
    "    # 7-day percentage change in closing price\n",
    "    df['Close_Pct_Change_7'] = df['Close'].pct_change(periods=7)\n",
    "    # 7-day Rate of Change (ROC)\n",
    "    df['ROC_7'] = (df['Close'] - df['Close'].shift(7)) / df['Close'].shift(7) * 100\n",
    "    # Price Momentum (ratio of current price to 10-day moving average)\n",
    "    df['Price_Momentum'] = df['Close'] / df['Close'].rolling(window=min(10, len(df))).mean() - 1\n",
    "    # Keltner Channel Width (measure of volatility)\n",
    "    df['Keltner_Channel_Width'] = ta.volatility.KeltnerChannel(df['High'], df['Low'], df['Close']).keltner_channel_wband()\n",
    "\n",
    "    # 14-day percentage change in closing price\n",
    "    df['Close_Pct_Change_14'] = df['Close'].pct_change(periods=14)\n",
    "    # 14-day Rate of Change (ROC)\n",
    "    df['ROC_14'] = (df['Close'] - df['Close'].shift(14)) / df['Close'].shift(14) * 100\n",
    "    # 30-day Rate of Change (ROC)\n",
    "    df['ROC_30'] = (df['Close'] - df['Close'].shift(30)) / df['Close'].shift(30) * 100\n",
    "\n",
    "    # Volatility features\n",
    "    # Ratio of short-term (10-day) to long-term (30-day) volatility\n",
    "    for lag in [1, 3, 7]:\n",
    "        df[f'Volatility_Ratio_Lag_{lag}'] = (df['High'] - df['Low']).rolling(window=10).std().shift(lag) / (df['High'] - df['Low']).rolling(window=30).std().shift(lag)\n",
    "\n",
    "    # Volume features\n",
    "    # Percentage change in volume over different time periods\n",
    "    for lag in [150, 240]:\n",
    "        df[f'Volume_Lag_{lag}'] = df['Volume'].pct_change(lag)\n",
    "\n",
    "    # Trend indicators\n",
    "    # Aroon Indicator (measures the strength of a trend)\n",
    "    aroon = ta.trend.AroonIndicator(df['High'], df['Low'])\n",
    "    df['Aroon_Up_Lag_1'] = aroon.aroon_up().shift(1)\n",
    "    df['Aroon_Down_Lag_1'] = aroon.aroon_down().shift(1)\n",
    "\n",
    "    # Momentum indicators\n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    macd = ta.trend.MACD(df['Close'])\n",
    "    df['MACD'] = macd.macd()\n",
    "    df['MACD_Signal'] = macd.macd_signal()\n",
    "    df['MACD_Diff'] = macd.macd_diff()\n",
    "    for lag in [1, 3, 7]:\n",
    "        df[f'MACD_Diff_Lag_{lag}'] = df['MACD_Diff'].shift(lag)\n",
    "\n",
    "    # Additional features\n",
    "    # Zigzag Indicator (identifies potential reversal points)\n",
    "    df['Zigzag_Indicator_Lag_1'] = (df['Close'] - df['Close'].rolling(window=20).min()) / (df['Close'].rolling(window=20).max() - df['Close'].rolling(window=20).min()).shift(1)\n",
    "    df['Zigzag_Indicator_Lag_3'] = (df['Close'] - df['Close'].rolling(window=20).min()) / (df['Close'].rolling(window=20).max() - df['Close'].rolling(window=20).min()).shift(3)\n",
    "\n",
    "    # RSI features (Relative Strength Index)\n",
    "    for window in [14, 30]:\n",
    "        df[f'RSI_{window}'] = ta.momentum.RSIIndicator(df['Close'], window=window).rsi()\n",
    "        for lag in [1, 3, 7]:\n",
    "            df[f'RSI_{window}_Lag_{lag}'] = df[f'RSI_{window}'].shift(lag)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    bb = ta.volatility.BollingerBands(df['Close'])\n",
    "    df['BB_Width'] = bb.bollinger_wband()\n",
    "    df['BB_Width_Lag_1'] = df['BB_Width'].shift(1)\n",
    "    df['BB_Width_Lag_3'] = df['BB_Width'].shift(3)\n",
    "\n",
    "    # Moving Averages\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['SMA_200'] = df['Close'].rolling(window=200).mean()\n",
    "    df['EMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "    # DEMA (Double Exponential Moving Average)\n",
    "    def DEMA(data, period):\n",
    "        ema = data.ewm(span=period, adjust=False).mean()\n",
    "        dema = 2 * ema - ema.ewm(span=period, adjust=False).mean()\n",
    "        return dema\n",
    "\n",
    "    df['DEMA_20'] = DEMA(df['Close'], 20)\n",
    "    df['DEMA_50'] = DEMA(df['Close'], 50)\n",
    "\n",
    "    # Fibonacci Retracement levels\n",
    "    df['Fib_38.2'] = df['Low'] + 0.382 * (df['High'] - df['Low'])\n",
    "    df['Fib_61.8'] = df['Low'] + 0.618 * (df['High'] - df['Low'])\n",
    "    for lag in [1, 3]:\n",
    "        df[f'Fib_38.2_Lag_{lag}'] = df['Fib_38.2'].shift(lag)\n",
    "        df[f'Fib_61.8_Lag_{lag}'] = df['Fib_61.8'].shift(lag)\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    stoch = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Close'])\n",
    "    df['Stoch_K'] = stoch.stoch()\n",
    "    df['Stoch_D'] = stoch.stoch_signal()\n",
    "    for lag in [1, 3]:\n",
    "        df[f'Stoch_K_Lag_{lag}'] = df['Stoch_K'].shift(lag)\n",
    "        df[f'Stoch_D_Lag_{lag}'] = df['Stoch_D'].shift(lag)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "35sTZWhIPQvO"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def advanced_feature_selection(X, y, n_splits=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Performing advanced feature selection using multiple methods.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialize TimeSeriesSplit for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    # Define a custom scoring function that combines MSE and Spearman correlation\n",
    "    def custom_score(y_true, y_pred):\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        corr, _ = spearmanr(y_true, y_pred)\n",
    "        return -mse * (1 + corr) / 2 \n",
    "\n",
    "    custom_scorer = make_scorer(custom_score, greater_is_better=True)\n",
    "\n",
    "    # Recursive Feature Elimination with Cross-Validation (RFECV) using XGBoost\n",
    "    xgb_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "    rfecv = RFECV(estimator=xgb_model, step=1, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1, min_features_to_select=1)\n",
    "    rfecv.fit(X, y)\n",
    "    rfecv_features = X.columns[rfecv.support_].tolist()\n",
    "\n",
    "    # LASSO feature selection\n",
    "    lasso = LassoCV(cv=tscv, random_state=42, n_jobs=-1)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    lasso_features = X.columns[np.abs(lasso.coef_) > np.percentile(np.abs(lasso.coef_), 75)].tolist()\n",
    "\n",
    "    # Random Forest feature importance\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf_model.fit(X, y)\n",
    "   \n",
    "    importance_threshold = np.percentile(rf_model.feature_importances_, 75)\n",
    "    rf_features = X.columns[rf_model.feature_importances_ > importance_threshold].tolist()\n",
    "\n",
    "    # Mutual Information feature selection\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "  \n",
    "    mi_threshold = np.percentile(mi_scores, 75)\n",
    "    mi_features = X.columns[mi_scores > mi_threshold].tolist()\n",
    "\n",
    "    # Combine all selected features \n",
    "    selected_features = list(set(rfecv_features) | set(lasso_features) | set(rf_features) | set(mi_features))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"RFECV selected {len(rfecv_features)} features\")\n",
    "        print(f\"LASSO selected {len(lasso_features)} features\")\n",
    "        print(f\"Random Forest selected {len(rf_features)} features\")\n",
    "        print(f\"Mutual Information selected {len(mi_features)} features\")\n",
    "        print(f\"Combined selection: {len(selected_features)} features\")\n",
    "\n",
    "        \n",
    "        feature_importance = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "        print(\"\\nTop 10 features by Random Forest importance:\")\n",
    "        for importance, feature in feature_importance[:10]:\n",
    "            print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "   \n",
    "    if len(selected_features) < 5:\n",
    "        print(\"Too few features selected. Using top 10 features by Random Forest importance.\")\n",
    "        return [feature for _, feature in feature_importance[:10]]\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OICJ2tUwNKWz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV selected 4 features\n",
      "LASSO selected 1 features\n",
      "Random Forest selected 14 features\n",
      "Mutual Information selected 14 features\n",
      "Combined selection: 20 features\n",
      "\n",
      "Top 10 features by Random Forest importance:\n",
      "Close_Pct_Change_7: 0.5254\n",
      "ROC_7: 0.4689\n",
      "Volume_Lag_240: 0.0012\n",
      "Close_Pct_Change_14: 0.0008\n",
      "Price_Momentum: 0.0007\n",
      "Stoch_K: 0.0003\n",
      "ROC_14: 0.0003\n",
      "Zigzag_Indicator_Lag_3: 0.0003\n",
      "Volatility_Ratio_Lag_7: 0.0003\n",
      "RSI_30: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "\n",
    "df = yf.download(\"BTC-USD\", start=start_date, end=end_date)\n",
    "\n",
    "# Engineer features \n",
    "df = engineer_features(df)\n",
    "\n",
    "# Data Cleaning\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Feature Selection\n",
    "X = df.drop('7d_ROI', axis=1)\n",
    "y = df['7d_ROI']\n",
    "\n",
    "selected_features = advanced_feature_selection(X, y)\n",
    "X = X[selected_features]\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(len(X) * 0.8)\n",
    "split_date = X.index[train_size]\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:split_date], y[split_date:]\n",
    "\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "# Function to clean target variable\n",
    "def clean_target_variable(y):\n",
    "    y = y.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    mean = y.mean()\n",
    "    std = y.std()\n",
    "    y = y[(y > mean - 5*std) & (y < mean + 5*std)]\n",
    "\n",
    "    return y\n",
    "\n",
    "X = df[selected_features]\n",
    "y = clean_target_variable(df['7d_ROI'])\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# LSTM Model Definition\n",
    "def create_lstm_model(input_shape, dropout_rate=0.5, neurons=[512, 256, 128]):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First LSTM layer\n",
    "    model.add(LSTM(neurons[0], input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Additional LSTM layers\n",
    "    for units in neurons[1:-1]:\n",
    "        model.add(LSTM(units, return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Final LSTM layer\n",
    "    model.add(LSTM(neurons[-1]))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Transformer Model Definition\n",
    "def create_transformer_model(input_shape):\n",
    "    config = TimeSeriesTransformerConfig(\n",
    "        d_model=64,\n",
    "        n_heads=4,\n",
    "        n_layers=4,\n",
    "        dim_feedforward=256,\n",
    "        dropout=0.1,\n",
    "        activation=\"gelu\",\n",
    "        context_length=input_shape[0],\n",
    "        prediction_length=1\n",
    "    )\n",
    "    model = TimeSeriesTransformerModel(config)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-7ioj47HK6-X"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class CustomImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.knn_imputer = KNNImputer(n_neighbors=5)\n",
    "        self.median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.cont_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "        self.other_features = X.columns.difference(self.cont_features)\n",
    "        if not self.cont_features.empty:\n",
    "            self.knn_imputer.fit(X[self.cont_features])\n",
    "        if not self.other_features.empty:\n",
    "            self.median_imputer.fit(X[self.other_features])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if not self.cont_features.empty:\n",
    "            X_cont = pd.DataFrame(\n",
    "                self.knn_imputer.transform(X[self.cont_features]),\n",
    "                columns=self.cont_features,\n",
    "                index=X.index\n",
    "            )\n",
    "            X_transformed[self.cont_features] = X_cont\n",
    "        if not self.other_features.empty:\n",
    "            X_other = pd.DataFrame(\n",
    "                self.median_imputer.transform(X[self.other_features]),\n",
    "                columns=self.other_features,\n",
    "                index=X.index\n",
    "            )\n",
    "            X_transformed[self.other_features] = X_other\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "# Objective function for hyperparameter optimization\n",
    "def objective(trial, X, y, cv, preprocessor):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 10)\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        X_train_processed = preprocessor.fit_transform(X_train)\n",
    "        X_val_processed = preprocessor.transform(X_val)\n",
    "        model.fit(X_train_processed, y_train)\n",
    "        pred = model.predict(X_val_processed)\n",
    "        score = mean_squared_error(y_val, pred)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qxtwBzW1K677"
   },
   "outputs": [],
   "source": [
    "class ExtremeValueHandler(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, threshold=3):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "\n",
    "        for column in X.columns:\n",
    "            # mean and standard deviation for the column\n",
    "            mean = X[column].mean()\n",
    "            std = X[column].std()\n",
    "\n",
    "            # Cliping values outside the range [mean - threshold * std, mean + threshold * std]\n",
    "            X_transformed[column] = X[column].clip(\n",
    "                lower=mean - self.threshold * std,\n",
    "                upper=mean + self.threshold * std\n",
    "            )\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LNVzsyvJK65S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 23:31:08,433] A new study created in memory with name: no-name-944fa289-13a9-417a-9ff0-d80b82583005\n",
      "[I 2024-08-22 23:31:11,079] Trial 0 finished with value: 0.0023981597858777114 and parameters: {'evh_threshold': 3.214642739882671, 'knn_neighbors': 3, 'qt_quantiles': 676, 'vt_threshold': 0.011774932596548274, 'corr_threshold': 0.9093198570081922, 'k_best': 25, 'pca_components': 0.9056621684858661, 'n_estimators': 297, 'max_depth': 10, 'learning_rate': 0.040817965998691495, 'subsample': 0.9793622691283526, 'colsample_bytree': 0.9151231814936054, 'min_child_weight': 6}. Best is trial 0 with value: 0.0023981597858777114.\n",
      "[I 2024-08-22 23:31:11,666] Trial 1 finished with value: 0.003427414942613771 and parameters: {'evh_threshold': 3.4048009077173997, 'knn_neighbors': 4, 'qt_quantiles': 114, 'vt_threshold': 0.017424557009171865, 'corr_threshold': 0.938422400753448, 'k_best': 23, 'pca_components': 0.8564268352317461, 'n_estimators': 278, 'max_depth': 9, 'learning_rate': 0.19290530852088458, 'subsample': 0.6809316334093882, 'colsample_bytree': 0.7744340942712253, 'min_child_weight': 8}. Best is trial 0 with value: 0.0023981597858777114.\n",
      "[I 2024-08-22 23:31:12,552] Trial 2 finished with value: 0.0009281059580037516 and parameters: {'evh_threshold': 2.4736826821591853, 'knn_neighbors': 5, 'qt_quantiles': 151, 'vt_threshold': 0.013363790585954532, 'corr_threshold': 0.9527300627590799, 'k_best': 12, 'pca_components': 0.9103807379196964, 'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.03594689114281904, 'subsample': 0.8233277462916723, 'colsample_bytree': 0.726194930525402, 'min_child_weight': 9}. Best is trial 2 with value: 0.0009281059580037516.\n",
      "[I 2024-08-22 23:31:13,084] Trial 3 finished with value: 0.0006544928180718233 and parameters: {'evh_threshold': 2.9154405175421054, 'knn_neighbors': 7, 'qt_quantiles': 290, 'vt_threshold': 0.018419875250584247, 'corr_threshold': 0.9347500998427977, 'k_best': 12, 'pca_components': 0.9560575003215308, 'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.24245900171642065, 'subsample': 0.9968735806055581, 'colsample_bytree': 0.6574957488383933, 'min_child_weight': 7}. Best is trial 3 with value: 0.0006544928180718233.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=37 is greater than n_features=31. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=37 is greater than n_features=29. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=37 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=37 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=37 is greater than n_features=31. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:13,542] Trial 4 finished with value: 0.003121021027134828 and parameters: {'evh_threshold': 3.8951231988663633, 'knn_neighbors': 4, 'qt_quantiles': 507, 'vt_threshold': 0.014248884281577098, 'corr_threshold': 0.9276208683347055, 'k_best': 37, 'pca_components': 0.8386438126271711, 'n_estimators': 272, 'max_depth': 4, 'learning_rate': 0.11022204161912943, 'subsample': 0.8957573854354889, 'colsample_bytree': 0.7700482431478763, 'min_child_weight': 1}. Best is trial 3 with value: 0.0006544928180718233.\n",
      "[I 2024-08-22 23:31:14,037] Trial 5 finished with value: 0.0006218148527232369 and parameters: {'evh_threshold': 3.0987628085060877, 'knn_neighbors': 3, 'qt_quantiles': 504, 'vt_threshold': 0.017781277959217627, 'corr_threshold': 0.9685906801366886, 'k_best': 19, 'pca_components': 0.9636371684658606, 'n_estimators': 263, 'max_depth': 5, 'learning_rate': 0.1329877444883629, 'subsample': 0.9915697501501486, 'colsample_bytree': 0.6438749562037641, 'min_child_weight': 4}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:14,590] Trial 6 finished with value: 0.004774908537333957 and parameters: {'evh_threshold': 3.9048126714615847, 'knn_neighbors': 6, 'qt_quantiles': 330, 'vt_threshold': 0.005770961058884186, 'corr_threshold': 0.9713465896395981, 'k_best': 24, 'pca_components': 0.8118119045120321, 'n_estimators': 199, 'max_depth': 10, 'learning_rate': 0.35089874336035676, 'subsample': 0.695713076278143, 'colsample_bytree': 0.6519597882148825, 'min_child_weight': 4}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:16,025] Trial 7 finished with value: 0.0038445233770506592 and parameters: {'evh_threshold': 2.1784262824567593, 'knn_neighbors': 6, 'qt_quantiles': 927, 'vt_threshold': 0.00796718519251664, 'corr_threshold': 0.9829380066032603, 'k_best': 23, 'pca_components': 0.8322140300870396, 'n_estimators': 90, 'max_depth': 5, 'learning_rate': 0.016326770852981502, 'subsample': 0.7162518354203413, 'colsample_bytree': 0.9262598125045014, 'min_child_weight': 3}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=56 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=56 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=56 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=56 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=56 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:17,524] Trial 8 finished with value: 0.005917632220207639 and parameters: {'evh_threshold': 2.713961041597085, 'knn_neighbors': 6, 'qt_quantiles': 692, 'vt_threshold': 0.0159202345915385, 'corr_threshold': 0.9728720057613406, 'k_best': 56, 'pca_components': 0.8422056926570208, 'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.008390504652744256, 'subsample': 0.9365419260732117, 'colsample_bytree': 0.6703972580653975, 'min_child_weight': 3}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:19,073] Trial 9 finished with value: 0.0016927625206717557 and parameters: {'evh_threshold': 2.1529577351435423, 'knn_neighbors': 6, 'qt_quantiles': 941, 'vt_threshold': 0.01599775903786811, 'corr_threshold': 0.9861526410205361, 'k_best': 21, 'pca_components': 0.899031845830801, 'n_estimators': 118, 'max_depth': 9, 'learning_rate': 0.045673656681015265, 'subsample': 0.7663287970857687, 'colsample_bytree': 0.7942495083776522, 'min_child_weight': 6}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=39 is greater than n_features=37. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=39 is greater than n_features=37. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=39 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=39 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=39 is greater than n_features=37. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:19,607] Trial 10 finished with value: 0.004255234685147637 and parameters: {'evh_threshold': 3.4901951051315487, 'knn_neighbors': 3, 'qt_quantiles': 486, 'vt_threshold': 0.019196488316614635, 'corr_threshold': 0.9572720450270978, 'k_best': 39, 'pca_components': 0.9890033452909933, 'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.9123052084055984, 'subsample': 0.6115108831512857, 'colsample_bytree': 0.8622645224920733, 'min_child_weight': 10}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:20,092] Trial 11 finished with value: 0.007425433169142577 and parameters: {'evh_threshold': 2.925522656372813, 'knn_neighbors': 7, 'qt_quantiles': 324, 'vt_threshold': 0.019002161885706737, 'corr_threshold': 0.9210229302745406, 'k_best': 12, 'pca_components': 0.9669641915821962, 'n_estimators': 182, 'max_depth': 6, 'learning_rate': 0.0016915939862640105, 'subsample': 0.978536644700906, 'colsample_bytree': 0.6092013700802468, 'min_child_weight': 7}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:20,539] Trial 12 finished with value: 0.0007065700106729844 and parameters: {'evh_threshold': 2.974782858024823, 'knn_neighbors': 7, 'qt_quantiles': 323, 'vt_threshold': 0.01918229474044758, 'corr_threshold': 0.941972249035362, 'k_best': 10, 'pca_components': 0.9462501129840268, 'n_estimators': 240, 'max_depth': 5, 'learning_rate': 0.644565882646296, 'subsample': 0.8716650886505579, 'colsample_bytree': 0.6921772960408428, 'min_child_weight': 4}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:21,072] Trial 13 finished with value: 0.0008168286390283086 and parameters: {'evh_threshold': 2.5640025004889417, 'knn_neighbors': 4, 'qt_quantiles': 639, 'vt_threshold': 0.011158622177149276, 'corr_threshold': 0.9623496008350167, 'k_best': 17, 'pca_components': 0.9401987966582402, 'n_estimators': 146, 'max_depth': 6, 'learning_rate': 0.11737820735263246, 'subsample': 0.9944949531272437, 'colsample_bytree': 0.6256235258749856, 'min_child_weight': 1}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=32 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=32 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=32 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=32 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=32 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:21,507] Trial 14 finished with value: 0.002283149481118867 and parameters: {'evh_threshold': 3.2422140204190932, 'knn_neighbors': 5, 'qt_quantiles': 419, 'vt_threshold': 0.01655812350616183, 'corr_threshold': 0.9020596998818439, 'k_best': 32, 'pca_components': 0.9405805897787309, 'n_estimators': 155, 'max_depth': 3, 'learning_rate': 0.2880337388575849, 'subsample': 0.9242497629417167, 'colsample_bytree': 0.712132729242862, 'min_child_weight': 5}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=31 is greater than n_features=30. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=31 is greater than n_features=29. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:22,102] Trial 15 finished with value: 0.0011362538310761422 and parameters: {'evh_threshold': 3.608319762190174, 'knn_neighbors': 3, 'qt_quantiles': 234, 'vt_threshold': 0.009859526254449075, 'corr_threshold': 0.9317591244695567, 'k_best': 31, 'pca_components': 0.9870244505869296, 'n_estimators': 233, 'max_depth': 5, 'learning_rate': 0.0997291837063859, 'subsample': 0.855542558122181, 'colsample_bytree': 0.6061114774948093, 'min_child_weight': 8}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:23,689] Trial 16 finished with value: 0.0038874695205737067 and parameters: {'evh_threshold': 2.7684551835435105, 'knn_neighbors': 7, 'qt_quantiles': 782, 'vt_threshold': 0.01411333663987448, 'corr_threshold': 0.9171799733789532, 'k_best': 17, 'pca_components': 0.9589617719862112, 'n_estimators': 93, 'max_depth': 8, 'learning_rate': 0.00998706889277061, 'subsample': 0.9423102840208533, 'colsample_bytree': 0.8451506705063261, 'min_child_weight': 7}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=51 is greater than n_features=36. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=51 is greater than n_features=37. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=51 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=51 is greater than n_features=36. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=51 is greater than n_features=36. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:24,143] Trial 17 finished with value: 0.002425872158732802 and parameters: {'evh_threshold': 3.2213860706293866, 'knn_neighbors': 4, 'qt_quantiles': 404, 'vt_threshold': 0.017578246576365215, 'corr_threshold': 0.9468470827738563, 'k_best': 51, 'pca_components': 0.8740729628173781, 'n_estimators': 164, 'max_depth': 4, 'learning_rate': 0.4590741110217362, 'subsample': 0.8025631175402882, 'colsample_bytree': 0.9823248542007108, 'min_child_weight': 5}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=44 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=44 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=44 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=44 is greater than n_features=38. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=44 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:24,623] Trial 18 finished with value: 0.009240196757231131 and parameters: {'evh_threshold': 2.4515308410750647, 'knn_neighbors': 5, 'qt_quantiles': 592, 'vt_threshold': 0.015252685319393122, 'corr_threshold': 0.9661721910769042, 'k_best': 44, 'pca_components': 0.9268406754472196, 'n_estimators': 56, 'max_depth': 6, 'learning_rate': 0.001488131325378749, 'subsample': 0.897659707546332, 'colsample_bytree': 0.742914092922895, 'min_child_weight': 3}. Best is trial 5 with value: 0.0006218148527232369.\n",
      "[I 2024-08-22 23:31:25,069] Trial 19 finished with value: 0.0005914425845454942 and parameters: {'evh_threshold': 3.069878510671538, 'knn_neighbors': 7, 'qt_quantiles': 234, 'vt_threshold': 0.017882310209317267, 'corr_threshold': 0.9507133097235723, 'k_best': 17, 'pca_components': 0.9610937612594388, 'n_estimators': 247, 'max_depth': 4, 'learning_rate': 0.07020491512159187, 'subsample': 0.9626708403956362, 'colsample_bytree': 0.6529748008756566, 'min_child_weight': 2}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:25,609] Trial 20 finished with value: 0.00514175961751395 and parameters: {'evh_threshold': 3.6709811017820346, 'knn_neighbors': 3, 'qt_quantiles': 200, 'vt_threshold': 0.01990787361531619, 'corr_threshold': 0.950935655047246, 'k_best': 29, 'pca_components': 0.9728466071440699, 'n_estimators': 253, 'max_depth': 4, 'learning_rate': 0.0033461228553236, 'subsample': 0.756015402413307, 'colsample_bytree': 0.8330974664578916, 'min_child_weight': 2}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:26,057] Trial 21 finished with value: 0.0009175096905574122 and parameters: {'evh_threshold': 3.0339352896693934, 'knn_neighbors': 7, 'qt_quantiles': 242, 'vt_threshold': 0.017554845030196775, 'corr_threshold': 0.9369605924489084, 'k_best': 17, 'pca_components': 0.9225390103025681, 'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.07233109991096286, 'subsample': 0.958065489723036, 'colsample_bytree': 0.6557586342356028, 'min_child_weight': 2}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:26,513] Trial 22 finished with value: 0.0006069947982491695 and parameters: {'evh_threshold': 3.0914441367145655, 'knn_neighbors': 7, 'qt_quantiles': 411, 'vt_threshold': 0.01802246453935606, 'corr_threshold': 0.9794240309670936, 'k_best': 15, 'pca_components': 0.9561989417073028, 'n_estimators': 297, 'max_depth': 4, 'learning_rate': 0.19606927554539264, 'subsample': 0.9962351891730743, 'colsample_bytree': 0.6884595352365105, 'min_child_weight': 4}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:26,967] Trial 23 finished with value: 0.003122276591829668 and parameters: {'evh_threshold': 3.123675189706375, 'knn_neighbors': 6, 'qt_quantiles': 408, 'vt_threshold': 0.015190165343705748, 'corr_threshold': 0.978197985339991, 'k_best': 18, 'pca_components': 0.8835408403998448, 'n_estimators': 292, 'max_depth': 4, 'learning_rate': 0.021442191954803947, 'subsample': 0.9106983975129372, 'colsample_bytree': 0.6939235791275128, 'min_child_weight': 4}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:27,452] Trial 24 finished with value: 0.0008130291513433632 and parameters: {'evh_threshold': 3.354006585418963, 'knn_neighbors': 5, 'qt_quantiles': 548, 'vt_threshold': 0.017670104999114186, 'corr_threshold': 0.9894106994320666, 'k_best': 28, 'pca_components': 0.9780676233026043, 'n_estimators': 260, 'max_depth': 3, 'learning_rate': 0.1587374143405154, 'subsample': 0.9610882380059055, 'colsample_bytree': 0.7365807060159023, 'min_child_weight': 2}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:27,898] Trial 25 finished with value: 0.000808852405465264 and parameters: {'evh_threshold': 2.7688672144141737, 'knn_neighbors': 7, 'qt_quantiles': 467, 'vt_threshold': 0.01677211565484535, 'corr_threshold': 0.9617119710079948, 'k_best': 15, 'pca_components': 0.9295956752713269, 'n_estimators': 233, 'max_depth': 4, 'learning_rate': 0.06706477562479969, 'subsample': 0.8551338127737087, 'colsample_bytree': 0.6304798023412385, 'min_child_weight': 4}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:29,391] Trial 26 finished with value: 0.0006832945900577288 and parameters: {'evh_threshold': 3.1059401854005895, 'knn_neighbors': 6, 'qt_quantiles': 775, 'vt_threshold': 0.01266476455411147, 'corr_threshold': 0.9756809765382067, 'k_best': 20, 'pca_components': 0.953264757591221, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06172408548923677, 'subsample': 0.9986341057066357, 'colsample_bytree': 0.6922779763758918, 'min_child_weight': 3}. Best is trial 19 with value: 0.0005914425845454942.\n",
      "[I 2024-08-22 23:31:29,817] Trial 27 finished with value: 0.0004989098585823109 and parameters: {'evh_threshold': 3.599423402562286, 'knn_neighbors': 7, 'qt_quantiles': 384, 'vt_threshold': 0.01998794172236723, 'corr_threshold': 0.9676240077118633, 'k_best': 14, 'pca_components': 0.9644566427532801, 'n_estimators': 273, 'max_depth': 3, 'learning_rate': 0.1720108545576908, 'subsample': 0.9545458422413818, 'colsample_bytree': 0.6803828242184855, 'min_child_weight': 5}. Best is trial 27 with value: 0.0004989098585823109.\n",
      "[I 2024-08-22 23:31:30,236] Trial 28 finished with value: 0.001604435420541748 and parameters: {'evh_threshold': 3.684985014771279, 'knn_neighbors': 7, 'qt_quantiles': 372, 'vt_threshold': 0.01982400444223004, 'corr_threshold': 0.9807703269733266, 'k_best': 14, 'pca_components': 0.9187939671530228, 'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.4232150555265956, 'subsample': 0.9493812656359254, 'colsample_bytree': 0.7499979339507807, 'min_child_weight': 5}. Best is trial 27 with value: 0.0004989098585823109.\n",
      "[I 2024-08-22 23:31:30,702] Trial 29 finished with value: 0.0013603291989143734 and parameters: {'evh_threshold': 3.518608342853739, 'knn_neighbors': 7, 'qt_quantiles': 162, 'vt_threshold': 0.010849645481966938, 'corr_threshold': 0.9566822350845955, 'k_best': 26, 'pca_components': 0.9778163584830712, 'n_estimators': 246, 'max_depth': 3, 'learning_rate': 0.026300724587072142, 'subsample': 0.9650507342389222, 'colsample_bytree': 0.6784454771837757, 'min_child_weight': 6}. Best is trial 27 with value: 0.0004989098585823109.\n",
      "[I 2024-08-22 23:31:31,158] Trial 30 finished with value: 0.0007967249117529851 and parameters: {'evh_threshold': 3.7885717392618585, 'knn_neighbors': 6, 'qt_quantiles': 269, 'vt_threshold': 0.018509410342342963, 'corr_threshold': 0.9645044131230188, 'k_best': 15, 'pca_components': 0.9405403384423201, 'n_estimators': 291, 'max_depth': 4, 'learning_rate': 0.19505134222619236, 'subsample': 0.8770499587840979, 'colsample_bytree': 0.7115745462560901, 'min_child_weight': 2}. Best is trial 27 with value: 0.0004989098585823109.\n",
      "[I 2024-08-22 23:31:31,601] Trial 31 finished with value: 0.0006257962368996629 and parameters: {'evh_threshold': 3.3083423164262746, 'knn_neighbors': 7, 'qt_quantiles': 441, 'vt_threshold': 0.01827225800904604, 'corr_threshold': 0.969203322976498, 'k_best': 20, 'pca_components': 0.9629952060964823, 'n_estimators': 259, 'max_depth': 4, 'learning_rate': 0.13701148245284858, 'subsample': 0.9792411803959397, 'colsample_bytree': 0.636528523099386, 'min_child_weight': 5}. Best is trial 27 with value: 0.0004989098585823109.\n",
      "[I 2024-08-22 23:31:32,023] Trial 32 finished with value: 0.00043086072133262506 and parameters: {'evh_threshold': 3.163835564712399, 'knn_neighbors': 7, 'qt_quantiles': 510, 'vt_threshold': 0.01999233035929973, 'corr_threshold': 0.9750103735185651, 'k_best': 10, 'pca_components': 0.969895093900816, 'n_estimators': 270, 'max_depth': 3, 'learning_rate': 0.23632878263837132, 'subsample': 0.923952318091214, 'colsample_bytree': 0.6328452892119442, 'min_child_weight': 6}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:32,486] Trial 33 finished with value: 0.00046409566872307863 and parameters: {'evh_threshold': 3.406652749483969, 'knn_neighbors': 7, 'qt_quantiles': 577, 'vt_threshold': 0.01989730495131374, 'corr_threshold': 0.9772669120759961, 'k_best': 10, 'pca_components': 0.9746066407544087, 'n_estimators': 275, 'max_depth': 3, 'learning_rate': 0.5815342857601044, 'subsample': 0.9226415257704902, 'colsample_bytree': 0.6022259426130346, 'min_child_weight': 6}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:32,935] Trial 34 finished with value: 0.00048800275543947543 and parameters: {'evh_threshold': 3.433496502584449, 'knn_neighbors': 7, 'qt_quantiles': 576, 'vt_threshold': 0.0199705677930049, 'corr_threshold': 0.956922658592718, 'k_best': 11, 'pca_components': 0.9898754175997355, 'n_estimators': 275, 'max_depth': 3, 'learning_rate': 0.6658136134252467, 'subsample': 0.9183989193845126, 'colsample_bytree': 0.6169933793562201, 'min_child_weight': 6}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:33,393] Trial 35 finished with value: 0.0008467172058937869 and parameters: {'evh_threshold': 3.4358263528693187, 'knn_neighbors': 7, 'qt_quantiles': 564, 'vt_threshold': 0.01985304553920781, 'corr_threshold': 0.9567775004465038, 'k_best': 10, 'pca_components': 0.9888489312152102, 'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.9909784406070148, 'subsample': 0.8377479774478731, 'colsample_bytree': 0.6110426912890508, 'min_child_weight': 6}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:34,795] Trial 36 finished with value: 0.0004762028127767058 and parameters: {'evh_threshold': 3.5373680881798903, 'knn_neighbors': 6, 'qt_quantiles': 692, 'vt_threshold': 0.019998236888615416, 'corr_threshold': 0.9743592530328277, 'k_best': 10, 'pca_components': 0.9752348954016902, 'n_estimators': 271, 'max_depth': 3, 'learning_rate': 0.6442729486343879, 'subsample': 0.913119397716175, 'colsample_bytree': 0.607308221372947, 'min_child_weight': 8}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:36,195] Trial 37 finished with value: 0.0005459102397427039 and parameters: {'evh_threshold': 3.8101219125828547, 'knn_neighbors': 6, 'qt_quantiles': 687, 'vt_threshold': 0.01893798737090776, 'corr_threshold': 0.9742635807467213, 'k_best': 10, 'pca_components': 0.9779011740352606, 'n_estimators': 222, 'max_depth': 3, 'learning_rate': 0.6146194207926972, 'subsample': 0.9107054622442404, 'colsample_bytree': 0.6050558170641496, 'min_child_weight': 8}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:37,635] Trial 38 finished with value: 0.0005410962682419175 and parameters: {'evh_threshold': 3.984529353009411, 'knn_neighbors': 6, 'qt_quantiles': 756, 'vt_threshold': 0.016672677594715555, 'corr_threshold': 0.9877194743306497, 'k_best': 12, 'pca_components': 0.9731426476679925, 'n_estimators': 270, 'max_depth': 3, 'learning_rate': 0.65001647749207, 'subsample': 0.889785356734052, 'colsample_bytree': 0.6255901458752787, 'min_child_weight': 8}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:38,102] Trial 39 finished with value: 0.00043666792907295644 and parameters: {'evh_threshold': 3.354535774906511, 'knn_neighbors': 6, 'qt_quantiles': 625, 'vt_threshold': 0.007593784979940996, 'corr_threshold': 0.9833714739308497, 'k_best': 12, 'pca_components': 0.9822339854459583, 'n_estimators': 186, 'max_depth': 3, 'learning_rate': 0.3700438556612734, 'subsample': 0.921012932387559, 'colsample_bytree': 0.6408032541294904, 'min_child_weight': 9}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:39,599] Trial 40 finished with value: 0.0025327793508654987 and parameters: {'evh_threshold': 3.3192879651067573, 'knn_neighbors': 5, 'qt_quantiles': 857, 'vt_threshold': 0.008249922168474652, 'corr_threshold': 0.9846842383112521, 'k_best': 22, 'pca_components': 0.9081768708752412, 'n_estimators': 189, 'max_depth': 9, 'learning_rate': 0.31227222663116144, 'subsample': 0.8130073842544779, 'colsample_bytree': 0.663455046597875, 'min_child_weight': 10}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:40,099] Trial 41 finished with value: 0.0004393222550621649 and parameters: {'evh_threshold': 3.441309816838948, 'knn_neighbors': 6, 'qt_quantiles': 642, 'vt_threshold': 0.005561000379153693, 'corr_threshold': 0.9759173810483589, 'k_best': 12, 'pca_components': 0.9840617751266717, 'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.4673476069450947, 'subsample': 0.9208703436096568, 'colsample_bytree': 0.6299293222233249, 'min_child_weight': 9}. Best is trial 32 with value: 0.00043086072133262506.\n",
      "[I 2024-08-22 23:31:40,588] Trial 42 finished with value: 0.00039117742661030615 and parameters: {'evh_threshold': 3.507319738045297, 'knn_neighbors': 6, 'qt_quantiles': 640, 'vt_threshold': 0.0075073868186766955, 'corr_threshold': 0.9756981965437023, 'k_best': 13, 'pca_components': 0.9804507069094965, 'n_estimators': 225, 'max_depth': 3, 'learning_rate': 0.25950290980697827, 'subsample': 0.9281197611337433, 'colsample_bytree': 0.641599010730175, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:41,084] Trial 43 finished with value: 0.0006661283630235612 and parameters: {'evh_threshold': 3.238120941006307, 'knn_neighbors': 6, 'qt_quantiles': 631, 'vt_threshold': 0.005161538186932614, 'corr_threshold': 0.9820766803249735, 'k_best': 13, 'pca_components': 0.9487472543299147, 'n_estimators': 219, 'max_depth': 4, 'learning_rate': 0.41723951086489997, 'subsample': 0.9343810307165642, 'colsample_bytree': 0.6503740248300608, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:41,548] Trial 44 finished with value: 0.0010806672272640047 and parameters: {'evh_threshold': 3.34841146430322, 'knn_neighbors': 6, 'qt_quantiles': 519, 'vt_threshold': 0.006820976060031822, 'corr_threshold': 0.9779131938409668, 'k_best': 36, 'pca_components': 0.9825378855423015, 'n_estimators': 231, 'max_depth': 3, 'learning_rate': 0.2488701854701471, 'subsample': 0.8850607574335814, 'colsample_bytree': 0.6432681860722405, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:42,110] Trial 45 finished with value: 0.0010685716207565576 and parameters: {'evh_threshold': 3.7422113144483053, 'knn_neighbors': 5, 'qt_quantiles': 629, 'vt_threshold': 0.0066741381880295785, 'corr_threshold': 0.9723508785634093, 'k_best': 12, 'pca_components': 0.9705166207836587, 'n_estimators': 196, 'max_depth': 8, 'learning_rate': 0.3428161156309166, 'subsample': 0.8598447703824504, 'colsample_bytree': 0.6316850256525651, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:43,612] Trial 46 finished with value: 0.004224695369240963 and parameters: {'evh_threshold': 3.176844625156845, 'knn_neighbors': 6, 'qt_quantiles': 712, 'vt_threshold': 0.008554014691642478, 'corr_threshold': 0.9899794813957603, 'k_best': 25, 'pca_components': 0.8579641451700867, 'n_estimators': 172, 'max_depth': 10, 'learning_rate': 0.4750167572256489, 'subsample': 0.8308557098268071, 'colsample_bytree': 0.9223435120680483, 'min_child_weight': 10}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:44,031] Trial 47 finished with value: 0.0006130665457581597 and parameters: {'evh_threshold': 3.447468153942871, 'knn_neighbors': 6, 'qt_quantiles': 523, 'vt_threshold': 0.0075486932450058095, 'corr_threshold': 0.9841859563181667, 'k_best': 14, 'pca_components': 0.9670314164745708, 'n_estimators': 139, 'max_depth': 3, 'learning_rate': 0.24810608495137684, 'subsample': 0.9319859531537878, 'colsample_bytree': 0.70905652799849, 'min_child_weight': 7}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:44,471] Trial 48 finished with value: 0.0038792603825046567 and parameters: {'evh_threshold': 3.597857858963579, 'knn_neighbors': 5, 'qt_quantiles': 601, 'vt_threshold': 0.005982499048932122, 'corr_threshold': 0.9697566652676078, 'k_best': 19, 'pca_components': 0.8024476654868608, 'n_estimators': 284, 'max_depth': 3, 'learning_rate': 0.8683150533441798, 'subsample': 0.8980713129978571, 'colsample_bytree': 0.7757527611816274, 'min_child_weight': 10}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:45,911] Trial 49 finished with value: 0.0005644961135049999 and parameters: {'evh_threshold': 2.871842192832887, 'knn_neighbors': 6, 'qt_quantiles': 817, 'vt_threshold': 0.009674894048592434, 'corr_threshold': 0.9770961131392979, 'k_best': 16, 'pca_components': 0.9824831039875876, 'n_estimators': 257, 'max_depth': 4, 'learning_rate': 0.3527370841543708, 'subsample': 0.7730710981364541, 'colsample_bytree': 0.664274846064323, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:47,411] Trial 50 finished with value: 0.0004878446616622892 and parameters: {'evh_threshold': 3.2730361842729563, 'knn_neighbors': 5, 'qt_quantiles': 721, 'vt_threshold': 0.009226465939047012, 'corr_threshold': 0.9622934475010343, 'k_best': 12, 'pca_components': 0.9511519322835216, 'n_estimators': 243, 'max_depth': 7, 'learning_rate': 0.04380631685971838, 'subsample': 0.6180072543230352, 'colsample_bytree': 0.8876856770666393, 'min_child_weight': 7}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:48,809] Trial 51 finished with value: 0.0004750775377499613 and parameters: {'evh_threshold': 3.5166162663743457, 'knn_neighbors': 6, 'qt_quantiles': 668, 'vt_threshold': 0.006433961210508296, 'corr_threshold': 0.9742764657036413, 'k_best': 10, 'pca_components': 0.9718497511129865, 'n_estimators': 263, 'max_depth': 3, 'learning_rate': 0.5601399373737281, 'subsample': 0.9129533009179451, 'colsample_bytree': 0.6049608860647882, 'min_child_weight': 8}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:49,355] Trial 52 finished with value: 0.0005113290302996103 and parameters: {'evh_threshold': 3.4058102439123776, 'knn_neighbors': 6, 'qt_quantiles': 648, 'vt_threshold': 0.005049347868924244, 'corr_threshold': 0.9810710529560649, 'k_best': 13, 'pca_components': 0.9835464507000592, 'n_estimators': 267, 'max_depth': 3, 'learning_rate': 0.5210263005220578, 'subsample': 0.9284742270305241, 'colsample_bytree': 0.6008556834216174, 'min_child_weight': 9}. Best is trial 42 with value: 0.00039117742661030615.\n",
      "[I 2024-08-22 23:31:49,954] Trial 53 finished with value: 0.0003844462974476201 and parameters: {'evh_threshold': 3.5215891431205457, 'knn_neighbors': 6, 'qt_quantiles': 652, 'vt_threshold': 0.007245428056082694, 'corr_threshold': 0.9722543303029096, 'k_best': 10, 'pca_components': 0.9688514176986642, 'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.23138038460803648, 'subsample': 0.9019815265789163, 'colsample_bytree': 0.6226013011998539, 'min_child_weight': 8}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:50,424] Trial 54 finished with value: 0.0006960102042219642 and parameters: {'evh_threshold': 3.1569959015045512, 'knn_neighbors': 6, 'qt_quantiles': 600, 'vt_threshold': 0.007395576831738622, 'corr_threshold': 0.9854224747020156, 'k_best': 12, 'pca_components': 0.932333644511684, 'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.10992887908237134, 'subsample': 0.8714650560065416, 'colsample_bytree': 0.6399853080507686, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=43 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=43 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=43 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=43 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=43 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:31:50,957] Trial 55 finished with value: 0.0016858756588260012 and parameters: {'evh_threshold': 3.6630589684889765, 'knn_neighbors': 7, 'qt_quantiles': 539, 'vt_threshold': 0.005721056002197488, 'corr_threshold': 0.9705999649503928, 'k_best': 43, 'pca_components': 0.9610497748200023, 'n_estimators': 193, 'max_depth': 5, 'learning_rate': 0.24777636142186218, 'subsample': 0.9760502504561196, 'colsample_bytree': 0.6213966759636844, 'min_child_weight': 8}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:51,392] Trial 56 finished with value: 0.00045414537124938105 and parameters: {'evh_threshold': 3.379868730783497, 'knn_neighbors': 6, 'qt_quantiles': 494, 'vt_threshold': 0.00879094423338377, 'corr_threshold': 0.9654533993435835, 'k_best': 16, 'pca_components': 0.9822192018183459, 'n_estimators': 177, 'max_depth': 3, 'learning_rate': 0.20255199476544825, 'subsample': 0.9358986906188517, 'colsample_bytree': 0.6703315533121815, 'min_child_weight': 7}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:51,841] Trial 57 finished with value: 0.00044160149036580055 and parameters: {'evh_threshold': 3.5400516321000826, 'knn_neighbors': 5, 'qt_quantiles': 485, 'vt_threshold': 0.008914760531667914, 'corr_threshold': 0.9651535547101886, 'k_best': 16, 'pca_components': 0.9827193400451879, 'n_estimators': 167, 'max_depth': 4, 'learning_rate': 0.0878450831515697, 'subsample': 0.9450358542351268, 'colsample_bytree': 0.6668485532961816, 'min_child_weight': 7}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:52,280] Trial 58 finished with value: 0.0006338920620977084 and parameters: {'evh_threshold': 3.881895196345763, 'knn_neighbors': 4, 'qt_quantiles': 460, 'vt_threshold': 0.0073140316655516836, 'corr_threshold': 0.9725903309322724, 'k_best': 18, 'pca_components': 0.9542611343904268, 'n_estimators': 168, 'max_depth': 4, 'learning_rate': 0.09021980031669598, 'subsample': 0.945711128490208, 'colsample_bytree': 0.6486991371295731, 'min_child_weight': 8}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:53,754] Trial 59 finished with value: 0.0008940061240543886 and parameters: {'evh_threshold': 3.566849460922106, 'knn_neighbors': 5, 'qt_quantiles': 735, 'vt_threshold': 0.010467264001141112, 'corr_threshold': 0.9424153119092604, 'k_best': 22, 'pca_components': 0.9669198357975413, 'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.14499950197661676, 'subsample': 0.8904219080871366, 'colsample_bytree': 0.723247393871658, 'min_child_weight': 10}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:55,161] Trial 60 finished with value: 0.0006534235648565844 and parameters: {'evh_threshold': 2.984673855006733, 'knn_neighbors': 5, 'qt_quantiles': 979, 'vt_threshold': 0.008039903967959268, 'corr_threshold': 0.9616696337002414, 'k_best': 14, 'pca_components': 0.9447883890012394, 'n_estimators': 207, 'max_depth': 4, 'learning_rate': 0.0905378087681311, 'subsample': 0.9059800003610973, 'colsample_bytree': 0.9978477783214343, 'min_child_weight': 7}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:55,601] Trial 61 finished with value: 0.00044586869752914076 and parameters: {'evh_threshold': 3.491122572111559, 'knn_neighbors': 6, 'qt_quantiles': 492, 'vt_threshold': 0.008862989622380139, 'corr_threshold': 0.9695583742159124, 'k_best': 16, 'pca_components': 0.9832316110680187, 'n_estimators': 180, 'max_depth': 3, 'learning_rate': 0.1775938815230494, 'subsample': 0.9419100265406378, 'colsample_bytree': 0.6718051236599734, 'min_child_weight': 7}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:56,062] Trial 62 finished with value: 0.00044393881680055553 and parameters: {'evh_threshold': 3.5046781415026445, 'knn_neighbors': 5, 'qt_quantiles': 612, 'vt_threshold': 0.009368430679478554, 'corr_threshold': 0.9673270566625503, 'k_best': 16, 'pca_components': 0.9889685461241583, 'n_estimators': 182, 'max_depth': 3, 'learning_rate': 0.3215722856292244, 'subsample': 0.9676892378219729, 'colsample_bytree': 0.6748595029268357, 'min_child_weight': 7}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:57,120] Trial 63 finished with value: 0.00040284606434091275 and parameters: {'evh_threshold': 3.661520726446834, 'knn_neighbors': 4, 'qt_quantiles': 656, 'vt_threshold': 0.011811462094519472, 'corr_threshold': 0.9820475421382893, 'k_best': 13, 'pca_components': 0.9896219340239237, 'n_estimators': 155, 'max_depth': 4, 'learning_rate': 0.29000865489794053, 'subsample': 0.9704021382779933, 'colsample_bytree': 0.6583827677734182, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:58,514] Trial 64 finished with value: 0.0004920236881218062 and parameters: {'evh_threshold': 3.661755877531432, 'knn_neighbors': 4, 'qt_quantiles': 660, 'vt_threshold': 0.011601796273831866, 'corr_threshold': 0.9819626401125255, 'k_best': 12, 'pca_components': 0.9668556470947467, 'n_estimators': 132, 'max_depth': 4, 'learning_rate': 0.28132783264816824, 'subsample': 0.9848130438251663, 'colsample_bytree': 0.6564864214850518, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:31:58,981] Trial 65 finished with value: 0.0005164523552340141 and parameters: {'evh_threshold': 3.7401479518441008, 'knn_neighbors': 4, 'qt_quantiles': 543, 'vt_threshold': 0.012952665616715387, 'corr_threshold': 0.9860355095642659, 'k_best': 13, 'pca_components': 0.9825939217381465, 'n_estimators': 158, 'max_depth': 4, 'learning_rate': 0.38028399241539396, 'subsample': 0.950304095482122, 'colsample_bytree': 0.6320209549797611, 'min_child_weight': 8}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:00,393] Trial 66 finished with value: 0.0027951840549133274 and parameters: {'evh_threshold': 3.275174787394352, 'knn_neighbors': 3, 'qt_quantiles': 800, 'vt_threshold': 0.01350020420255307, 'corr_threshold': 0.9798127331851851, 'k_best': 18, 'pca_components': 0.899696187079103, 'n_estimators': 119, 'max_depth': 6, 'learning_rate': 0.7774120205568062, 'subsample': 0.9763881063477249, 'colsample_bytree': 0.6991963913824553, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:00,854] Trial 67 finished with value: 0.000595378358878881 and parameters: {'evh_threshold': 3.6173451438113693, 'knn_neighbors': 4, 'qt_quantiles': 625, 'vt_threshold': 0.012104672089441727, 'corr_threshold': 0.9274971337017077, 'k_best': 14, 'pca_components': 0.9764601140782129, 'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.22413792176238564, 'subsample': 0.9003350854312855, 'colsample_bytree': 0.621383073765124, 'min_child_weight': 10}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=54 is greater than n_features=40. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=54 is greater than n_features=40. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=54 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=54 is greater than n_features=39. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=54 is greater than n_features=42. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:32:02,280] Trial 68 finished with value: 0.0013643716429427432 and parameters: {'evh_threshold': 2.332665117611136, 'knn_neighbors': 4, 'qt_quantiles': 674, 'vt_threshold': 0.006026518310005486, 'corr_threshold': 0.9760408059761115, 'k_best': 54, 'pca_components': 0.9588473398726346, 'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.05338284283137639, 'subsample': 0.9251650863778192, 'colsample_bytree': 0.6414030410537075, 'min_child_weight': 8}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:03,692] Trial 69 finished with value: 0.0004233548236459887 and parameters: {'evh_threshold': 3.8250497576640496, 'knn_neighbors': 5, 'qt_quantiles': 747, 'vt_threshold': 0.010180271589302656, 'corr_threshold': 0.9596989785532122, 'k_best': 11, 'pca_components': 0.9687098487615465, 'n_estimators': 217, 'max_depth': 4, 'learning_rate': 0.13897628307976587, 'subsample': 0.8640734285465635, 'colsample_bytree': 0.6804956734806863, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:05,124] Trial 70 finished with value: 0.00045351002468395194 and parameters: {'evh_threshold': 3.897256549503696, 'knn_neighbors': 6, 'qt_quantiles': 845, 'vt_threshold': 0.01008497059365997, 'corr_threshold': 0.9532038250917722, 'k_best': 11, 'pca_components': 0.957477922532626, 'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.13268754160655982, 'subsample': 0.8470421200419046, 'colsample_bytree': 0.8258797561913372, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:06,531] Trial 71 finished with value: 0.0004555379729716452 and parameters: {'evh_threshold': 3.802057342472612, 'knn_neighbors': 5, 'qt_quantiles': 749, 'vt_threshold': 0.007693080320751786, 'corr_threshold': 0.9643847941903968, 'k_best': 11, 'pca_components': 0.9700664561986421, 'n_estimators': 187, 'max_depth': 4, 'learning_rate': 0.033656590291420145, 'subsample': 0.9561151202429402, 'colsample_bytree': 0.687121656392947, 'min_child_weight': 9}. Best is trial 53 with value: 0.0003844462974476201.\n",
      "[I 2024-08-22 23:32:07,959] Trial 72 finished with value: 0.0003796197050443185 and parameters: {'evh_threshold': 3.7520055815418445, 'knn_neighbors': 5, 'qt_quantiles': 713, 'vt_threshold': 0.011162492271514363, 'corr_threshold': 0.9721242902397131, 'k_best': 15, 'pca_components': 0.9875360322595577, 'n_estimators': 230, 'max_depth': 3, 'learning_rate': 0.15940681569284168, 'subsample': 0.8762052451115951, 'colsample_bytree': 0.9531701016090877, 'min_child_weight': 10}. Best is trial 72 with value: 0.0003796197050443185.\n",
      "[I 2024-08-22 23:32:09,380] Trial 73 finished with value: 0.0003631815069356424 and parameters: {'evh_threshold': 3.735990664688651, 'knn_neighbors': 5, 'qt_quantiles': 719, 'vt_threshold': 0.011352530090406123, 'corr_threshold': 0.9794113722243839, 'k_best': 13, 'pca_components': 0.9886633576878776, 'n_estimators': 228, 'max_depth': 3, 'learning_rate': 0.16804693647448524, 'subsample': 0.8718304463336515, 'colsample_bytree': 0.8168290999735371, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:10,780] Trial 74 finished with value: 0.0036926104741637983 and parameters: {'evh_threshold': 3.9679144150798855, 'knn_neighbors': 5, 'qt_quantiles': 714, 'vt_threshold': 0.011136203287951079, 'corr_threshold': 0.9796498113156706, 'k_best': 14, 'pca_components': 0.8228616709586597, 'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.16692166521872734, 'subsample': 0.8708653958008808, 'colsample_bytree': 0.9483583084477843, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:12,339] Trial 75 finished with value: 0.00045244881112420767 and parameters: {'evh_threshold': 3.844677260490071, 'knn_neighbors': 5, 'qt_quantiles': 779, 'vt_threshold': 0.011507805837633545, 'corr_threshold': 0.9879055982869501, 'k_best': 19, 'pca_components': 0.9888841474910112, 'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.1142174242736906, 'subsample': 0.8607006072090932, 'colsample_bytree': 0.9523834820690369, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:13,785] Trial 76 finished with value: 0.0016558574973363801 and parameters: {'evh_threshold': 2.006447530580915, 'knn_neighbors': 5, 'qt_quantiles': 700, 'vt_threshold': 0.010599919939451492, 'corr_threshold': 0.982999515610049, 'k_best': 11, 'pca_components': 0.9775379434184581, 'n_estimators': 237, 'max_depth': 3, 'learning_rate': 0.008080614326960826, 'subsample': 0.8853275732134664, 'colsample_bytree': 0.8908242099382756, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:15,238] Trial 77 finished with value: 0.0007753067215975643 and parameters: {'evh_threshold': 3.7367221292801758, 'knn_neighbors': 4, 'qt_quantiles': 756, 'vt_threshold': 0.012216988314222781, 'corr_threshold': 0.9604267851422981, 'k_best': 15, 'pca_components': 0.9349637549208039, 'n_estimators': 202, 'max_depth': 3, 'learning_rate': 0.2829470402537514, 'subsample': 0.8425591760076131, 'colsample_bytree': 0.7830208334405869, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:16,655] Trial 78 finished with value: 0.0025256776985274963 and parameters: {'evh_threshold': 3.712961229576385, 'knn_neighbors': 5, 'qt_quantiles': 862, 'vt_threshold': 0.013555446711875942, 'corr_threshold': 0.972305055746995, 'k_best': 13, 'pca_components': 0.8858989474001528, 'n_estimators': 223, 'max_depth': 3, 'learning_rate': 0.13707128549079128, 'subsample': 0.8815172742872923, 'colsample_bytree': 0.7596564809209804, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:17,179] Trial 79 finished with value: 0.0004912921115361535 and parameters: {'evh_threshold': 3.934159677929146, 'knn_neighbors': 5, 'qt_quantiles': 574, 'vt_threshold': 0.010317327048817718, 'corr_threshold': 0.9465405568718893, 'k_best': 10, 'pca_components': 0.9632862126209989, 'n_estimators': 213, 'max_depth': 7, 'learning_rate': 0.21504056130632884, 'subsample': 0.8238374885159245, 'colsample_bytree': 0.8164429590268347, 'min_child_weight': 9}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:18,630] Trial 80 finished with value: 0.0005100279360236278 and parameters: {'evh_threshold': 3.647029783562698, 'knn_neighbors': 3, 'qt_quantiles': 892, 'vt_threshold': 0.012893696375364654, 'corr_threshold': 0.9591296651430357, 'k_best': 15, 'pca_components': 0.9706366928430248, 'n_estimators': 234, 'max_depth': 4, 'learning_rate': 0.17086741398417468, 'subsample': 0.7919750177954348, 'colsample_bytree': 0.8594593025994629, 'min_child_weight': 10}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:19,134] Trial 81 finished with value: 0.0004890515887106858 and parameters: {'evh_threshold': 3.4519720811199437, 'knn_neighbors': 6, 'qt_quantiles': 644, 'vt_threshold': 0.006970699522775229, 'corr_threshold': 0.9765060840295986, 'k_best': 13, 'pca_components': 0.9789084101844315, 'n_estimators': 217, 'max_depth': 3, 'learning_rate': 0.4393679606033643, 'subsample': 0.90032683041271, 'colsample_bytree': 0.6175896555092947, 'min_child_weight': 9}. Best is trial 73 with value: 0.0003631815069356424.\n",
      "[I 2024-08-22 23:32:20,615] Trial 82 finished with value: 0.0003439417160135046 and parameters: {'evh_threshold': 3.76790527100081, 'knn_neighbors': 6, 'qt_quantiles': 680, 'vt_threshold': 0.0110216656335095, 'corr_threshold': 0.9000198214432261, 'k_best': 11, 'pca_components': 0.9867267039503214, 'n_estimators': 228, 'max_depth': 3, 'learning_rate': 0.2775416717524063, 'subsample': 0.9205494959468359, 'colsample_bytree': 0.6499776528088894, 'min_child_weight': 9}. Best is trial 82 with value: 0.0003439417160135046.\n",
      "[I 2024-08-22 23:32:22,115] Trial 83 finished with value: 0.0003456207286092133 and parameters: {'evh_threshold': 3.8418449799134287, 'knn_neighbors': 5, 'qt_quantiles': 684, 'vt_threshold': 0.011108808111840738, 'corr_threshold': 0.9014456540358913, 'k_best': 11, 'pca_components': 0.9894473068361106, 'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.2765740486714452, 'subsample': 0.8634642453603222, 'colsample_bytree': 0.6561725935151896, 'min_child_weight': 9}. Best is trial 82 with value: 0.0003439417160135046.\n",
      "[I 2024-08-22 23:32:23,572] Trial 84 finished with value: 0.00032654819567729806 and parameters: {'evh_threshold': 3.84629993828284, 'knn_neighbors': 5, 'qt_quantiles': 687, 'vt_threshold': 0.011935000594693155, 'corr_threshold': 0.9104333567933156, 'k_best': 11, 'pca_components': 0.9857379902692334, 'n_estimators': 228, 'max_depth': 3, 'learning_rate': 0.2124834176562811, 'subsample': 0.8517403071887819, 'colsample_bytree': 0.656686955589912, 'min_child_weight': 8}. Best is trial 84 with value: 0.00032654819567729806.\n",
      "[I 2024-08-22 23:32:25,001] Trial 85 finished with value: 0.0003162628165584612 and parameters: {'evh_threshold': 3.8449891558178533, 'knn_neighbors': 5, 'qt_quantiles': 736, 'vt_threshold': 0.011084850442245083, 'corr_threshold': 0.9025794707720296, 'k_best': 11, 'pca_components': 0.9887419836737578, 'n_estimators': 229, 'max_depth': 3, 'learning_rate': 0.26789527362246296, 'subsample': 0.8528655035209856, 'colsample_bytree': 0.8034117499780914, 'min_child_weight': 8}. Best is trial 85 with value: 0.0003162628165584612.\n",
      "[I 2024-08-22 23:32:26,543] Trial 86 finished with value: 0.0007484279612285371 and parameters: {'evh_threshold': 3.756430974885493, 'knn_neighbors': 5, 'qt_quantiles': 680, 'vt_threshold': 0.011992502675295938, 'corr_threshold': 0.9001405176227443, 'k_best': 17, 'pca_components': 0.9896567772326145, 'n_estimators': 241, 'max_depth': 3, 'learning_rate': 0.2940821945891638, 'subsample': 0.8479875636319362, 'colsample_bytree': 0.8023738423698152, 'min_child_weight': 8}. Best is trial 85 with value: 0.0003162628165584612.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=34 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=34 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=34 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=34 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=34 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:32:28,270] Trial 87 finished with value: 0.0008315641784032374 and parameters: {'evh_threshold': 3.863155897270411, 'knn_neighbors': 5, 'qt_quantiles': 807, 'vt_threshold': 0.011186085507831978, 'corr_threshold': 0.9068502978927556, 'k_best': 34, 'pca_components': 0.9856345932704318, 'n_estimators': 227, 'max_depth': 3, 'learning_rate': 0.2073267711352379, 'subsample': 0.8059479577864815, 'colsample_bytree': 0.8462022843245162, 'min_child_weight': 8}. Best is trial 85 with value: 0.0003162628165584612.\n",
      "[I 2024-08-22 23:32:30,034] Trial 88 finished with value: 0.00044089216751733395 and parameters: {'evh_threshold': 3.922945130804355, 'knn_neighbors': 5, 'qt_quantiles': 728, 'vt_threshold': 0.010934257266095872, 'corr_threshold': 0.9063567141111373, 'k_best': 13, 'pca_components': 0.9782415134267176, 'n_estimators': 211, 'max_depth': 3, 'learning_rate': 0.26659607489510523, 'subsample': 0.8514138685281651, 'colsample_bytree': 0.802913219569491, 'min_child_weight': 8}. Best is trial 85 with value: 0.0003162628165584612.\n",
      "[I 2024-08-22 23:32:31,526] Trial 89 finished with value: 0.0003503144475201196 and parameters: {'evh_threshold': 3.7786466593675083, 'knn_neighbors': 5, 'qt_quantiles': 689, 'vt_threshold': 0.014205348116673313, 'corr_threshold': 0.9131230712181456, 'k_best': 11, 'pca_components': 0.9746049135659169, 'n_estimators': 253, 'max_depth': 3, 'learning_rate': 0.34333355776512714, 'subsample': 0.8304385120310672, 'colsample_bytree': 0.7915564120949539, 'min_child_weight': 9}. Best is trial 85 with value: 0.0003162628165584612.\n",
      "[I 2024-08-22 23:32:32,966] Trial 90 finished with value: 0.00029977758011478817 and parameters: {'evh_threshold': 3.7742911056844073, 'knn_neighbors': 5, 'qt_quantiles': 698, 'vt_threshold': 0.014793453580795117, 'corr_threshold': 0.9105293416122879, 'k_best': 11, 'pca_components': 0.9746132599407227, 'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.1986775156336432, 'subsample': 0.8315066675541654, 'colsample_bytree': 0.7941262853944038, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:34,359] Trial 91 finished with value: 0.0003237069067262706 and parameters: {'evh_threshold': 3.774452423204311, 'knn_neighbors': 5, 'qt_quantiles': 694, 'vt_threshold': 0.012585210907026518, 'corr_threshold': 0.9136003131287553, 'k_best': 10, 'pca_components': 0.9749220033430316, 'n_estimators': 252, 'max_depth': 3, 'learning_rate': 0.194733649743099, 'subsample': 0.8349225802440223, 'colsample_bytree': 0.7688768518412229, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:35,759] Trial 92 finished with value: 0.00033169814621717455 and parameters: {'evh_threshold': 3.791562082084784, 'knn_neighbors': 5, 'qt_quantiles': 699, 'vt_threshold': 0.01486280139113687, 'corr_threshold': 0.9153197134344401, 'k_best': 10, 'pca_components': 0.9759813445872714, 'n_estimators': 249, 'max_depth': 3, 'learning_rate': 0.18538977061551737, 'subsample': 0.8371078923471577, 'colsample_bytree': 0.7916440036159769, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:37,234] Trial 93 finished with value: 0.0003186411340911484 and parameters: {'evh_threshold': 3.765149522268298, 'knn_neighbors': 5, 'qt_quantiles': 692, 'vt_threshold': 0.014057931388693282, 'corr_threshold': 0.9146469736841045, 'k_best': 11, 'pca_components': 0.9749656484687644, 'n_estimators': 253, 'max_depth': 3, 'learning_rate': 0.1867875500471033, 'subsample': 0.8338129702979049, 'colsample_bytree': 0.7898047419586666, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:38,657] Trial 94 finished with value: 0.00031621167632083674 and parameters: {'evh_threshold': 3.7892007007763793, 'knn_neighbors': 5, 'qt_quantiles': 695, 'vt_threshold': 0.01528562209935898, 'corr_threshold': 0.9181762519763086, 'k_best': 11, 'pca_components': 0.9743985974996519, 'n_estimators': 253, 'max_depth': 3, 'learning_rate': 0.3785396944941054, 'subsample': 0.830560530067033, 'colsample_bytree': 0.788397670677281, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:40,088] Trial 95 finished with value: 0.00035131886416664177 and parameters: {'evh_threshold': 3.7866167031588844, 'knn_neighbors': 5, 'qt_quantiles': 694, 'vt_threshold': 0.014729307308487313, 'corr_threshold': 0.9161008780307014, 'k_best': 11, 'pca_components': 0.9729624825484724, 'n_estimators': 255, 'max_depth': 3, 'learning_rate': 0.3993341813644764, 'subsample': 0.8193194884917929, 'colsample_bytree': 0.7909293968240214, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:41,503] Trial 96 finished with value: 0.0003542005964534991 and parameters: {'evh_threshold': 3.9533466792963115, 'knn_neighbors': 5, 'qt_quantiles': 771, 'vt_threshold': 0.015771994264683543, 'corr_threshold': 0.9132304482439468, 'k_best': 10, 'pca_components': 0.9736149801393644, 'n_estimators': 247, 'max_depth': 3, 'learning_rate': 0.35051915373786835, 'subsample': 0.7920139352890807, 'colsample_bytree': 0.7755170271665642, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:42,900] Trial 97 finished with value: 0.0003615065577963977 and parameters: {'evh_threshold': 3.855488005048039, 'knn_neighbors': 5, 'qt_quantiles': 679, 'vt_threshold': 0.014027025785219088, 'corr_threshold': 0.9103330041023976, 'k_best': 11, 'pca_components': 0.9634599417813158, 'n_estimators': 262, 'max_depth': 3, 'learning_rate': 0.525672641478261, 'subsample': 0.8359658503003575, 'colsample_bytree': 0.751794516207345, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "[I 2024-08-22 23:32:44,315] Trial 98 finished with value: 0.0026569960485758434 and parameters: {'evh_threshold': 3.9920787246929876, 'knn_neighbors': 5, 'qt_quantiles': 737, 'vt_threshold': 0.01454258601619573, 'corr_threshold': 0.9215264808944241, 'k_best': 11, 'pca_components': 0.9150718833557573, 'n_estimators': 251, 'max_depth': 3, 'learning_rate': 0.19385361245517435, 'subsample': 0.8286973176623723, 'colsample_bytree': 0.7634494844512055, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=48 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=48 is greater than n_features=28. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=48 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=48 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=48 is greater than n_features=27. All the features will be returned.\n",
      "  warnings.warn(\n",
      "[I 2024-08-22 23:32:45,739] Trial 99 finished with value: 0.0023832909116313105 and parameters: {'evh_threshold': 3.702442151635988, 'knn_neighbors': 5, 'qt_quantiles': 792, 'vt_threshold': 0.015340830436341312, 'corr_threshold': 0.9035868669371031, 'k_best': 48, 'pca_components': 0.8608645140666319, 'n_estimators': 239, 'max_depth': 3, 'learning_rate': 0.1177957680561817, 'subsample': 0.8140547009441546, 'colsample_bytree': 0.7936215906100451, 'min_child_weight': 10}. Best is trial 90 with value: 0.00029977758011478817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'evh_threshold': 3.7742911056844073, 'knn_neighbors': 5, 'qt_quantiles': 698, 'vt_threshold': 0.014793453580795117, 'corr_threshold': 0.9105293416122879, 'k_best': 11, 'pca_components': 0.9746132599407227, 'n_estimators': 250, 'max_depth': 3, 'learning_rate': 0.1986775156336432, 'subsample': 0.8315066675541654, 'colsample_bytree': 0.7941262853944038, 'min_child_weight': 10}\n",
      "Best cross-validated MSE: -0.00029977758011478817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Custom transformer to handle extreme values\n",
    "class ExtremeValueHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=3):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for column in X_copy.columns:\n",
    "            if X_copy[column].dtype in ['int64', 'float64']:\n",
    "                # Calculating IQR and bounds\n",
    "                Q1 = X_copy[column].quantile(0.25)\n",
    "                Q3 = X_copy[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - self.threshold * IQR\n",
    "                upper_bound = Q3 + self.threshold * IQR\n",
    "                # Clip values to the bounds\n",
    "                X_copy[column] = X_copy[column].clip(lower_bound, upper_bound)\n",
    "        return X_copy\n",
    "\n",
    "# Custom transformer to filter highly correlated features\n",
    "class CorrelationFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.95):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        self.corr_matrix = X.corr().abs()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        upper = self.corr_matrix.where(np.triu(np.ones(self.corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        return X.drop(columns=to_drop)\n",
    "\n",
    "# Wrapper to ensure transformers return DataFrames\n",
    "class DataFrameWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.transformer.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        result = self.transformer.transform(X)\n",
    "        if isinstance(result, np.ndarray):\n",
    "            return pd.DataFrame(result, columns=X.columns, index=X.index)\n",
    "        return result\n",
    "\n",
    "def create_pipeline(trial):\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Numeric data preprocessing\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('extreme_value_handler', ExtremeValueHandler(threshold=trial.suggest_float('evh_threshold', 2, 4))),\n",
    "        ('imputer', KNNImputer(n_neighbors=trial.suggest_int('knn_neighbors', 3, 7))),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('qt', QuantileTransformer(n_quantiles=trial.suggest_int('qt_quantiles', 100, 1000), output_distribution='normal')),\n",
    "    ])\n",
    "\n",
    "    # Categorical data preprocessing\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ])\n",
    "\n",
    "    # Combining numeric and categorical preprocessors\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "    preprocessor = DataFrameWrapper(preprocessor)\n",
    "\n",
    "    # Feature selection pipeline\n",
    "    feature_selector = Pipeline([\n",
    "        ('variance_threshold', VarianceThreshold(threshold=trial.suggest_float('vt_threshold', 0.005, 0.02))),\n",
    "        ('correlation_filter', CorrelationFilter(threshold=trial.suggest_float('corr_threshold', 0.9, 0.99))),\n",
    "        ('univariate_selection', SelectKBest(score_func=f_regression, k=trial.suggest_int('k_best', 10, len(X.columns)))),\n",
    "        ('pca', PCA(n_components=trial.suggest_float('pca_components', 0.8, 0.99))),\n",
    "    ])\n",
    "\n",
    "    # XGBoost model with hyperparameters \n",
    "    model = XGBRegressor(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        max_depth=trial.suggest_int('max_depth', 3, 10),\n",
    "        learning_rate=trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "        subsample=trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        min_child_weight=trial.suggest_int('min_child_weight', 1, 10),\n",
    "        random_state=42\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selector', feature_selector),\n",
    "        ('model', model),\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "# Objective function for Optuna \n",
    "def objective(trial):\n",
    "    pipeline = create_pipeline(trial)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    return -scores.mean()\n",
    "\n",
    "def optimize_pipeline(X, y, n_trials=100):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_pipeline = create_pipeline(study.best_trial)\n",
    "    best_pipeline.fit(X, y)\n",
    "\n",
    "    return best_pipeline, study.best_trial\n",
    "\n",
    "X = df.drop('7d_ROI', axis=1)\n",
    "y = df['7d_ROI']\n",
    "\n",
    "best_pipeline, best_trial = optimize_pipeline(X, y, n_trials=100)\n",
    "\n",
    "print(\"Best hyperparameters:\", best_trial.params)\n",
    "print(\"Best cross-validated MSE:\", -best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P8PdKR9vK62p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV selected 4 features\n",
      "LASSO selected 1 features\n",
      "Random Forest selected 14 features\n",
      "Mutual Information selected 14 features\n",
      "Combined selection: 20 features\n",
      "\n",
      "Top 10 features by Random Forest importance:\n",
      "Close_Pct_Change_7: 0.5254\n",
      "ROC_7: 0.4689\n",
      "Volume_Lag_240: 0.0012\n",
      "Close_Pct_Change_14: 0.0008\n",
      "Price_Momentum: 0.0007\n",
      "Stoch_K: 0.0003\n",
      "ROC_14: 0.0003\n",
      "Zigzag_Indicator_Lag_3: 0.0003\n",
      "Volatility_Ratio_Lag_7: 0.0003\n",
      "RSI_30: 0.0002\n",
      "Shape of X_train after processing: (2624, 20)\n",
      "Shape of X_test after processing: (657, 20)\n",
      "Shape of y_train: (2624,)\n",
      "Shape of y_test: (657,)\n",
      "Any infinity values in X_train: False\n",
      "Any infinity values in X_test: False\n",
      "Any NaN values in X_train: False\n",
      "Any NaN values in X_test: False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom transformer to handle extreme values\n",
    "class ExtremeValueHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, replace_inf=True, replace_large=True, large_threshold=1e300):\n",
    "        self.replace_inf = replace_inf\n",
    "        self.replace_large = replace_large\n",
    "        self.large_threshold = large_threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        if self.replace_inf:\n",
    "            X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "        if self.replace_large:\n",
    "            X = X.mask(X.abs() > self.large_threshold, np.nan)\n",
    "\n",
    "        return X\n",
    "\n",
    "selected_features = advanced_feature_selection(X, y)\n",
    "\n",
    "X = X[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_index = y_train.index\n",
    "test_index = y_test.index\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('extreme_value_handler', ExtremeValueHandler()),\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Shape of X_train after processing: {X_train.shape}\")\n",
    "print(f\"Shape of X_test after processing: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "print(f\"Any infinity values in X_train: {np.isinf(X_train).any().any()}\")\n",
    "print(f\"Any infinity values in X_test: {np.isinf(X_test).any().any()}\")\n",
    "print(f\"Any NaN values in X_train: {np.isnan(X_train).any().any()}\")\n",
    "print(f\"Any NaN values in X_test: {np.isnan(X_test).any().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0qZs3L5zK6z3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-22 23:32:59,614] A new study created in memory with name: no-name-7cd5e220-8ba8-42f3-9d11-53777610a204\n",
      "[I 2024-08-22 23:33:01,406] Trial 0 finished with value: 0.00015477824313888552 and parameters: {'n_estimators': 695, 'max_depth': 5, 'learning_rate': 0.040797843038424736, 'subsample': 0.6497019064537138, 'subsample_freq': 10}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:01,906] Trial 1 finished with value: 0.0001674824990780649 and parameters: {'n_estimators': 355, 'max_depth': 10, 'learning_rate': 0.33878414022791065, 'subsample': 0.9119261723556285, 'subsample_freq': 8}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:04,148] Trial 2 finished with value: 0.0004945638470688522 and parameters: {'n_estimators': 330, 'max_depth': 9, 'learning_rate': 0.00588131492956293, 'subsample': 0.8903674388272338, 'subsample_freq': 7}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:04,975] Trial 3 finished with value: 0.0002485317086458526 and parameters: {'n_estimators': 966, 'max_depth': 9, 'learning_rate': 0.70664694686189, 'subsample': 0.6650036642478298, 'subsample_freq': 6}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:06,318] Trial 4 finished with value: 0.0008717087035029925 and parameters: {'n_estimators': 515, 'max_depth': 4, 'learning_rate': 0.002975872190082029, 'subsample': 0.7985860691361703, 'subsample_freq': 10}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:06,669] Trial 5 finished with value: 0.00016722763044237614 and parameters: {'n_estimators': 197, 'max_depth': 3, 'learning_rate': 0.21880805713316842, 'subsample': 0.9700442447271532, 'subsample_freq': 2}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:10,278] Trial 6 finished with value: 0.0001579736603578328 and parameters: {'n_estimators': 717, 'max_depth': 10, 'learning_rate': 0.020200099444990547, 'subsample': 0.9518180565044826, 'subsample_freq': 3}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:10,737] Trial 7 finished with value: 0.000195449087780071 and parameters: {'n_estimators': 429, 'max_depth': 8, 'learning_rate': 0.6735068380490706, 'subsample': 0.7384814492874798, 'subsample_freq': 10}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:11,255] Trial 8 finished with value: 0.0002454858072216521 and parameters: {'n_estimators': 552, 'max_depth': 10, 'learning_rate': 0.789021825293682, 'subsample': 0.7764408443231158, 'subsample_freq': 7}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:16,896] Trial 9 finished with value: 0.00016465861357990627 and parameters: {'n_estimators': 836, 'max_depth': 8, 'learning_rate': 0.0051989651544156025, 'subsample': 0.9500988929179368, 'subsample_freq': 10}. Best is trial 0 with value: 0.00015477824313888552.\n",
      "[I 2024-08-22 23:33:18,338] Trial 10 finished with value: 0.00015077608046187065 and parameters: {'n_estimators': 654, 'max_depth': 5, 'learning_rate': 0.05981467061211367, 'subsample': 0.6072054955415046, 'subsample_freq': 4}. Best is trial 10 with value: 0.00015077608046187065.\n",
      "[I 2024-08-22 23:33:19,792] Trial 11 finished with value: 0.00015819415948022393 and parameters: {'n_estimators': 682, 'max_depth': 5, 'learning_rate': 0.06284035090492884, 'subsample': 0.602193536882943, 'subsample_freq': 4}. Best is trial 10 with value: 0.00015077608046187065.\n",
      "[I 2024-08-22 23:33:21,578] Trial 12 finished with value: 0.00014313432407664681 and parameters: {'n_estimators': 665, 'max_depth': 6, 'learning_rate': 0.05546080788584522, 'subsample': 0.607114825656918, 'subsample_freq': 1}. Best is trial 12 with value: 0.00014313432407664681.\n",
      "[I 2024-08-22 23:33:22,561] Trial 13 finished with value: 0.0001596964007200189 and parameters: {'n_estimators': 843, 'max_depth': 6, 'learning_rate': 0.14071488454263759, 'subsample': 0.7130822492686681, 'subsample_freq': 1}. Best is trial 12 with value: 0.00014313432407664681.\n",
      "[I 2024-08-22 23:33:24,965] Trial 14 finished with value: 0.00014318654262579676 and parameters: {'n_estimators': 575, 'max_depth': 6, 'learning_rate': 0.013028899541566134, 'subsample': 0.612575987879336, 'subsample_freq': 4}. Best is trial 12 with value: 0.00014313432407664681.\n",
      "[I 2024-08-22 23:33:27,805] Trial 15 finished with value: 0.0001410374617669923 and parameters: {'n_estimators': 542, 'max_depth': 7, 'learning_rate': 0.014668535602490837, 'subsample': 0.6800346537777262, 'subsample_freq': 1}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:28,756] Trial 16 finished with value: 0.008264540094181483 and parameters: {'n_estimators': 137, 'max_depth': 7, 'learning_rate': 0.0011603629409385145, 'subsample': 0.6890071977679967, 'subsample_freq': 1}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:33,593] Trial 17 finished with value: 0.00014499583152164945 and parameters: {'n_estimators': 807, 'max_depth': 7, 'learning_rate': 0.01352239060221053, 'subsample': 0.8474115861009464, 'subsample_freq': 2}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:34,808] Trial 18 finished with value: 0.00015569964301279638 and parameters: {'n_estimators': 453, 'max_depth': 7, 'learning_rate': 0.0930736209492091, 'subsample': 0.7487742076158903, 'subsample_freq': 2}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:38,072] Trial 19 finished with value: 0.00014454109843673504 and parameters: {'n_estimators': 604, 'max_depth': 8, 'learning_rate': 0.026793410867988542, 'subsample': 0.654835248884864, 'subsample_freq': 1}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:39,457] Trial 20 finished with value: 0.0011062512253458112 and parameters: {'n_estimators': 239, 'max_depth': 6, 'learning_rate': 0.0056837102607081936, 'subsample': 0.8356663397762292, 'subsample_freq': 3}. Best is trial 15 with value: 0.0001410374617669923.\n",
      "[I 2024-08-22 23:33:42,593] Trial 21 finished with value: 0.00014077761725763368 and parameters: {'n_estimators': 544, 'max_depth': 6, 'learning_rate': 0.012543862982427927, 'subsample': 0.6270746121005564, 'subsample_freq': 5}. Best is trial 21 with value: 0.00014077761725763368.\n",
      "[I 2024-08-22 23:33:43,959] Trial 22 finished with value: 0.0001449038426386041 and parameters: {'n_estimators': 473, 'max_depth': 4, 'learning_rate': 0.011682626520389807, 'subsample': 0.641568744904204, 'subsample_freq': 5}. Best is trial 21 with value: 0.00014077761725763368.\n",
      "[I 2024-08-22 23:33:45,890] Trial 23 finished with value: 0.0001399291824337177 and parameters: {'n_estimators': 378, 'max_depth': 6, 'learning_rate': 0.026916527122703995, 'subsample': 0.6945359320661016, 'subsample_freq': 3}. Best is trial 23 with value: 0.0001399291824337177.\n",
      "[I 2024-08-22 23:33:48,222] Trial 24 finished with value: 0.00013741536292664202 and parameters: {'n_estimators': 348, 'max_depth': 7, 'learning_rate': 0.024733512062909073, 'subsample': 0.6968956063098842, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:49,871] Trial 25 finished with value: 0.00014712581603972314 and parameters: {'n_estimators': 380, 'max_depth': 5, 'learning_rate': 0.031427228827833976, 'subsample': 0.7144006849810294, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:51,135] Trial 26 finished with value: 0.0029762482873480875 and parameters: {'n_estimators': 292, 'max_depth': 4, 'learning_rate': 0.002571863687991671, 'subsample': 0.7044820297116364, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:52,966] Trial 27 finished with value: 0.0004401511017424993 and parameters: {'n_estimators': 271, 'max_depth': 6, 'learning_rate': 0.00766634806726144, 'subsample': 0.7566394047074696, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:54,410] Trial 28 finished with value: 0.00014982400333650892 and parameters: {'n_estimators': 411, 'max_depth': 8, 'learning_rate': 0.1062475026390719, 'subsample': 0.634106608747933, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:55,302] Trial 29 finished with value: 0.0002979352410380086 and parameters: {'n_estimators': 107, 'max_depth': 7, 'learning_rate': 0.023570730374604946, 'subsample': 0.7292209045864645, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:56,140] Trial 30 finished with value: 0.00013816033274403119 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.03916633971783983, 'subsample': 0.6709481320378913, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:56,985] Trial 31 finished with value: 0.000143247051359806 and parameters: {'n_estimators': 189, 'max_depth': 5, 'learning_rate': 0.03489372279747334, 'subsample': 0.6731150783445498, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:58,604] Trial 32 finished with value: 0.0001468512031389103 and parameters: {'n_estimators': 341, 'max_depth': 6, 'learning_rate': 0.04480745132156314, 'subsample': 0.6321550613260223, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:59,259] Trial 33 finished with value: 0.00015478351947108708 and parameters: {'n_estimators': 205, 'max_depth': 4, 'learning_rate': 0.02175693856232881, 'subsample': 0.6941971143460353, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:33:59,908] Trial 34 finished with value: 0.0002573133487311638 and parameters: {'n_estimators': 310, 'max_depth': 3, 'learning_rate': 0.009212437067442621, 'subsample': 0.6577877604092662, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:01,910] Trial 35 finished with value: 0.00014107460107464566 and parameters: {'n_estimators': 498, 'max_depth': 5, 'learning_rate': 0.01774203038617119, 'subsample': 0.7977224797170556, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:03,621] Trial 36 finished with value: 0.0010234248542669334 and parameters: {'n_estimators': 376, 'max_depth': 5, 'learning_rate': 0.003786094561009133, 'subsample': 0.775285898537051, 'subsample_freq': 8}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:04,328] Trial 37 finished with value: 0.00015328426656487364 and parameters: {'n_estimators': 270, 'max_depth': 6, 'learning_rate': 0.27414714935408624, 'subsample': 0.6657858089408503, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:05,428] Trial 38 finished with value: 0.00015730695427454633 and parameters: {'n_estimators': 152, 'max_depth': 9, 'learning_rate': 0.08036786815036771, 'subsample': 0.725556117505976, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:06,503] Trial 39 finished with value: 0.00015724563195743495 and parameters: {'n_estimators': 410, 'max_depth': 4, 'learning_rate': 0.039520329403481776, 'subsample': 0.6432872945847895, 'subsample_freq': 8}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:07,424] Trial 40 finished with value: 0.0001612490324287143 and parameters: {'n_estimators': 347, 'max_depth': 7, 'learning_rate': 0.1333418504711488, 'subsample': 0.6282918984586398, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:10,171] Trial 41 finished with value: 0.0001415304035705301 and parameters: {'n_estimators': 504, 'max_depth': 7, 'learning_rate': 0.015927306492303936, 'subsample': 0.6801018190496163, 'subsample_freq': 2}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:14,307] Trial 42 finished with value: 0.000144501454701594 and parameters: {'n_estimators': 624, 'max_depth': 8, 'learning_rate': 0.008408698072120557, 'subsample': 0.6904937489967298, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:16,724] Trial 43 finished with value: 0.00014289930616236292 and parameters: {'n_estimators': 546, 'max_depth': 7, 'learning_rate': 0.027873092213309792, 'subsample': 0.6720342482382755, 'subsample_freq': 2}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:18,528] Trial 44 finished with value: 0.0001492229569856423 and parameters: {'n_estimators': 732, 'max_depth': 6, 'learning_rate': 0.04537511448600707, 'subsample': 0.7024117984840947, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:22,680] Trial 45 finished with value: 0.00014082686131255707 and parameters: {'n_estimators': 986, 'max_depth': 8, 'learning_rate': 0.01885803562619494, 'subsample': 0.7669399494767762, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:26,674] Trial 46 finished with value: 0.0001495129786254511 and parameters: {'n_estimators': 945, 'max_depth': 9, 'learning_rate': 0.01999104406048012, 'subsample': 0.842918511636327, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:34,515] Trial 47 finished with value: 0.00014140889774631222 and parameters: {'n_estimators': 915, 'max_depth': 8, 'learning_rate': 0.010019336551759876, 'subsample': 0.7798855608584101, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:35,716] Trial 48 finished with value: 0.00017786312013157773 and parameters: {'n_estimators': 748, 'max_depth': 9, 'learning_rate': 0.4496876135216752, 'subsample': 0.7576942143975142, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:37,208] Trial 49 finished with value: 0.00014974606108714123 and parameters: {'n_estimators': 448, 'max_depth': 8, 'learning_rate': 0.06994898886840276, 'subsample': 0.8970625167619255, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:38,946] Trial 50 finished with value: 0.00014348895185535682 and parameters: {'n_estimators': 198, 'max_depth': 10, 'learning_rate': 0.05174485757707375, 'subsample': 0.6167860546534835, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:42,675] Trial 51 finished with value: 0.00013981875760796 and parameters: {'n_estimators': 581, 'max_depth': 7, 'learning_rate': 0.01530217335560581, 'subsample': 0.7312804422963273, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:44,587] Trial 52 finished with value: 0.00015729618768436086 and parameters: {'n_estimators': 779, 'max_depth': 6, 'learning_rate': 0.032593194905425775, 'subsample': 0.9967592558666695, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:50,285] Trial 53 finished with value: 0.00013855795622910312 and parameters: {'n_estimators': 992, 'max_depth': 7, 'learning_rate': 0.007007497121128631, 'subsample': 0.740060501664872, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:55,692] Trial 54 finished with value: 0.00026872700747656317 and parameters: {'n_estimators': 854, 'max_depth': 7, 'learning_rate': 0.003114563694277447, 'subsample': 0.7353189424630135, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:58,596] Trial 55 finished with value: 0.000263494880337793 and parameters: {'n_estimators': 604, 'max_depth': 6, 'learning_rate': 0.004460550641531061, 'subsample': 0.7117814613805682, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:34:59,478] Trial 56 finished with value: 0.0008257809832839632 and parameters: {'n_estimators': 237, 'max_depth': 5, 'learning_rate': 0.006755919121592624, 'subsample': 0.651475349129552, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:01,782] Trial 57 finished with value: 0.0001461241947761571 and parameters: {'n_estimators': 377, 'max_depth': 7, 'learning_rate': 0.01299706065371369, 'subsample': 0.7419046139187959, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:05,631] Trial 58 finished with value: 0.00014281070355289893 and parameters: {'n_estimators': 885, 'max_depth': 6, 'learning_rate': 0.011264627785897293, 'subsample': 0.7217357213352741, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:06,941] Trial 59 finished with value: 0.004574579028608107 and parameters: {'n_estimators': 311, 'max_depth': 5, 'learning_rate': 0.0015782506061533736, 'subsample': 0.8108585182287422, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:11,306] Trial 60 finished with value: 0.000174665476312153 and parameters: {'n_estimators': 653, 'max_depth': 7, 'learning_rate': 0.005580339853134991, 'subsample': 0.6969202186447365, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:17,015] Trial 61 finished with value: 0.00014133002132051816 and parameters: {'n_estimators': 964, 'max_depth': 8, 'learning_rate': 0.017701886990262157, 'subsample': 0.7672578190093984, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:20,515] Trial 62 finished with value: 0.00014350765375377938 and parameters: {'n_estimators': 995, 'max_depth': 7, 'learning_rate': 0.02691567042937796, 'subsample': 0.7470718816924007, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:24,938] Trial 63 finished with value: 0.00014517433499526138 and parameters: {'n_estimators': 909, 'max_depth': 8, 'learning_rate': 0.021917749936555854, 'subsample': 0.7174890914026312, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:27,968] Trial 64 finished with value: 0.00014028796765470027 and parameters: {'n_estimators': 708, 'max_depth': 6, 'learning_rate': 0.014611985750635907, 'subsample': 0.798415273202404, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:31,813] Trial 65 finished with value: 0.00014360383437339239 and parameters: {'n_estimators': 690, 'max_depth': 6, 'learning_rate': 0.010566358406561595, 'subsample': 0.822236683716702, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:34,398] Trial 66 finished with value: 0.0001442941406761629 and parameters: {'n_estimators': 581, 'max_depth': 6, 'learning_rate': 0.01540299225635239, 'subsample': 0.6812642876740483, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:35,976] Trial 67 finished with value: 0.0001540600746475763 and parameters: {'n_estimators': 487, 'max_depth': 5, 'learning_rate': 0.039364781275870994, 'subsample': 0.8690246064361595, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:38,858] Trial 68 finished with value: 0.0002086622712428196 and parameters: {'n_estimators': 460, 'max_depth': 6, 'learning_rate': 0.006695621529498052, 'subsample': 0.7968435169090542, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:41,386] Trial 69 finished with value: 0.00014113843221611158 and parameters: {'n_estimators': 427, 'max_depth': 7, 'learning_rate': 0.025380424432039483, 'subsample': 0.6219812016869405, 'subsample_freq': 9}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:45,015] Trial 70 finished with value: 0.0001467640821401892 and parameters: {'n_estimators': 642, 'max_depth': 6, 'learning_rate': 0.008104087168949494, 'subsample': 0.6631804429470942, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:49,938] Trial 71 finished with value: 0.00014164987865525103 and parameters: {'n_estimators': 993, 'max_depth': 7, 'learning_rate': 0.01863948180943566, 'subsample': 0.7838170856265183, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:54,861] Trial 72 finished with value: 0.00013906233836199057 and parameters: {'n_estimators': 790, 'max_depth': 7, 'learning_rate': 0.012284299117312596, 'subsample': 0.7681546217267236, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:35:59,436] Trial 73 finished with value: 0.0001407962081403483 and parameters: {'n_estimators': 789, 'max_depth': 7, 'learning_rate': 0.01267987452509259, 'subsample': 0.7351902462272086, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:03,130] Trial 74 finished with value: 0.00014929698604045804 and parameters: {'n_estimators': 708, 'max_depth': 7, 'learning_rate': 0.014182535632555325, 'subsample': 0.6001640323581403, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:05,952] Trial 75 finished with value: 0.000144488233333755 and parameters: {'n_estimators': 823, 'max_depth': 6, 'learning_rate': 0.032672336720823404, 'subsample': 0.7878074664100981, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:10,349] Trial 76 finished with value: 0.0003111435942702407 and parameters: {'n_estimators': 525, 'max_depth': 7, 'learning_rate': 0.0046790524448674055, 'subsample': 0.7523897792052099, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:13,195] Trial 77 finished with value: 0.0001459062139153268 and parameters: {'n_estimators': 578, 'max_depth': 4, 'learning_rate': 0.009580987149695661, 'subsample': 0.8224080083674219, 'subsample_freq': 2}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:16,135] Trial 78 finished with value: 0.00015164461891815548 and parameters: {'n_estimators': 754, 'max_depth': 6, 'learning_rate': 0.05686034585683808, 'subsample': 0.7072901812459489, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:17,049] Trial 79 finished with value: 0.0016508112582615687 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.006756815957925847, 'subsample': 0.728524963374686, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:20,344] Trial 80 finished with value: 0.0001461276075188258 and parameters: {'n_estimators': 666, 'max_depth': 7, 'learning_rate': 0.02833324786551793, 'subsample': 0.7633331682668211, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:25,390] Trial 81 finished with value: 0.00014098757076377595 and parameters: {'n_estimators': 789, 'max_depth': 7, 'learning_rate': 0.012023548844136622, 'subsample': 0.7378543017980478, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:30,031] Trial 82 finished with value: 0.00014603726671935844 and parameters: {'n_estimators': 875, 'max_depth': 7, 'learning_rate': 0.01486723856835714, 'subsample': 0.6411561552044415, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:34,052] Trial 83 finished with value: 0.00014596651131531065 and parameters: {'n_estimators': 794, 'max_depth': 7, 'learning_rate': 0.021176221710708047, 'subsample': 0.6840628922165154, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:34,638] Trial 84 finished with value: 0.0007112730879198744 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.01644523293727455, 'subsample': 0.6944652107246259, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:38,505] Trial 85 finished with value: 0.0001399435984362697 and parameters: {'n_estimators': 753, 'max_depth': 6, 'learning_rate': 0.008910216396661418, 'subsample': 0.7316000850854795, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:42,243] Trial 86 finished with value: 0.00014204336081553845 and parameters: {'n_estimators': 719, 'max_depth': 6, 'learning_rate': 0.008401645671207662, 'subsample': 0.7052496075872153, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:44,547] Trial 87 finished with value: 0.00014945102735636583 and parameters: {'n_estimators': 762, 'max_depth': 6, 'learning_rate': 0.04632132748239578, 'subsample': 0.6742043471781097, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:46,659] Trial 88 finished with value: 0.00015031922713430485 and parameters: {'n_estimators': 606, 'max_depth': 5, 'learning_rate': 0.037141705244181096, 'subsample': 0.7206306763481453, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:48,801] Trial 89 finished with value: 0.0001427580540167152 and parameters: {'n_estimators': 407, 'max_depth': 6, 'learning_rate': 0.023939229571552905, 'subsample': 0.7485615652953644, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:49,939] Trial 90 finished with value: 0.0003969858530017448 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.00976125628646074, 'subsample': 0.7917145355803465, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:51,972] Trial 91 finished with value: 0.00018414872505538647 and parameters: {'n_estimators': 270, 'max_depth': 7, 'learning_rate': 0.012628775417233451, 'subsample': 0.7738306008327028, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:52,932] Trial 92 finished with value: 0.00039272408899386393 and parameters: {'n_estimators': 729, 'max_depth': 7, 'learning_rate': 0.9648270115994217, 'subsample': 0.7303147843823382, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:36:57,667] Trial 93 finished with value: 0.00014224489765628167 and parameters: {'n_estimators': 816, 'max_depth': 6, 'learning_rate': 0.006733615400848639, 'subsample': 0.7401999805580576, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:04,359] Trial 94 finished with value: 0.00014094541782597354 and parameters: {'n_estimators': 862, 'max_depth': 8, 'learning_rate': 0.011609995704420914, 'subsample': 0.8081322036696743, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:12,179] Trial 95 finished with value: 0.00013888534616469117 and parameters: {'n_estimators': 701, 'max_depth': 7, 'learning_rate': 0.013765097656170651, 'subsample': 0.761335952924477, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:19,643] Trial 96 finished with value: 0.00014238854860076298 and parameters: {'n_estimators': 677, 'max_depth': 7, 'learning_rate': 0.016997401555331384, 'subsample': 0.7572490154554126, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:24,421] Trial 97 finished with value: 0.0003365645707164758 and parameters: {'n_estimators': 641, 'max_depth': 6, 'learning_rate': 0.0036690983443151727, 'subsample': 0.7699495501528055, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:28,427] Trial 98 finished with value: 0.00015475168227589473 and parameters: {'n_estimators': 559, 'max_depth': 6, 'learning_rate': 0.007665522997753613, 'subsample': 0.7137304155987366, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:32,113] Trial 99 finished with value: 0.00014403292626219812 and parameters: {'n_estimators': 705, 'max_depth': 7, 'learning_rate': 0.029818107495027005, 'subsample': 0.7604881293207176, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:35,498] Trial 100 finished with value: 0.0001444696608670205 and parameters: {'n_estimators': 523, 'max_depth': 7, 'learning_rate': 0.021911924959364892, 'subsample': 0.6668062420933545, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:41,151] Trial 101 finished with value: 0.00013872017195247613 and parameters: {'n_estimators': 770, 'max_depth': 7, 'learning_rate': 0.013491852826559902, 'subsample': 0.730495547821972, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:46,395] Trial 102 finished with value: 0.0001422209574773898 and parameters: {'n_estimators': 688, 'max_depth': 7, 'learning_rate': 0.014836131147356066, 'subsample': 0.7023286596709594, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:46,817] Trial 103 finished with value: 0.0011517966586487409 and parameters: {'n_estimators': 128, 'max_depth': 3, 'learning_rate': 0.010769546500425808, 'subsample': 0.7451230124587979, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:52,965] Trial 104 finished with value: 0.00014098855590465338 and parameters: {'n_estimators': 771, 'max_depth': 8, 'learning_rate': 0.019119891068013425, 'subsample': 0.7802925482044225, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:57,458] Trial 105 finished with value: 0.0001411908680640219 and parameters: {'n_estimators': 742, 'max_depth': 6, 'learning_rate': 0.008702187153798733, 'subsample': 0.7240409042264395, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:37:59,529] Trial 106 finished with value: 0.0005617155278180503 and parameters: {'n_estimators': 320, 'max_depth': 7, 'learning_rate': 0.005900949227736099, 'subsample': 0.6896152851734433, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:03,522] Trial 107 finished with value: 0.00014431624678708457 and parameters: {'n_estimators': 834, 'max_depth': 7, 'learning_rate': 0.0240631206350361, 'subsample': 0.6580562390635775, 'subsample_freq': 2}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:06,671] Trial 108 finished with value: 0.00014065617904890267 and parameters: {'n_estimators': 629, 'max_depth': 6, 'learning_rate': 0.013804674773473434, 'subsample': 0.80478721397661, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:10,980] Trial 109 finished with value: 0.00014075755948890164 and parameters: {'n_estimators': 625, 'max_depth': 7, 'learning_rate': 0.01463567071576626, 'subsample': 0.8066668332377264, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:14,663] Trial 110 finished with value: 0.00014385151450306907 and parameters: {'n_estimators': 617, 'max_depth': 6, 'learning_rate': 0.010308778065561736, 'subsample': 0.8250861933392075, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:19,051] Trial 111 finished with value: 0.00014030715651937046 and parameters: {'n_estimators': 667, 'max_depth': 7, 'learning_rate': 0.013690868466173949, 'subsample': 0.8140108961996916, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:23,166] Trial 112 finished with value: 0.00014173942393083333 and parameters: {'n_estimators': 672, 'max_depth': 7, 'learning_rate': 0.013113739532758583, 'subsample': 0.8449134425467967, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:27,637] Trial 113 finished with value: 0.00014114720363161078 and parameters: {'n_estimators': 698, 'max_depth': 8, 'learning_rate': 0.016800888562420888, 'subsample': 0.8002498899381892, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:32,089] Trial 114 finished with value: 0.00014689997670802444 and parameters: {'n_estimators': 655, 'max_depth': 7, 'learning_rate': 0.00766517747931805, 'subsample': 0.858156754287533, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:36,033] Trial 115 finished with value: 0.0001430814686880578 and parameters: {'n_estimators': 740, 'max_depth': 7, 'learning_rate': 0.0191201601833994, 'subsample': 0.7930168648488791, 'subsample_freq': 7}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:39,312] Trial 116 finished with value: 0.00014340535542703393 and parameters: {'n_estimators': 584, 'max_depth': 6, 'learning_rate': 0.009345994879461089, 'subsample': 0.8121546683527991, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:42,168] Trial 117 finished with value: 0.0001423237589255077 and parameters: {'n_estimators': 720, 'max_depth': 8, 'learning_rate': 0.03585071802159278, 'subsample': 0.7320568263508858, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:46,701] Trial 118 finished with value: 0.00014018508924103112 and parameters: {'n_estimators': 635, 'max_depth': 7, 'learning_rate': 0.013718249631247046, 'subsample': 0.8271222219992688, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:50,816] Trial 119 finished with value: 0.0001430800832504345 and parameters: {'n_estimators': 595, 'max_depth': 7, 'learning_rate': 0.011506516509015293, 'subsample': 0.8386253735814697, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:38:54,395] Trial 120 finished with value: 0.0001502463048434189 and parameters: {'n_estimators': 924, 'max_depth': 7, 'learning_rate': 0.025703023824477512, 'subsample': 0.8524036351291098, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:00,239] Trial 121 finished with value: 0.00014001530346394007 and parameters: {'n_estimators': 651, 'max_depth': 7, 'learning_rate': 0.014131143402842557, 'subsample': 0.8138090128673103, 'subsample_freq': 6}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:05,573] Trial 122 finished with value: 0.00014547140927693213 and parameters: {'n_estimators': 560, 'max_depth': 7, 'learning_rate': 0.02091488406648167, 'subsample': 0.8315702440576951, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:11,923] Trial 123 finished with value: 0.00013789823154475964 and parameters: {'n_estimators': 645, 'max_depth': 7, 'learning_rate': 0.015360220438497954, 'subsample': 0.8163707585929454, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:16,541] Trial 124 finished with value: 0.00014345759649612568 and parameters: {'n_estimators': 700, 'max_depth': 7, 'learning_rate': 0.0166439461051164, 'subsample': 0.8311773382854084, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:21,828] Trial 125 finished with value: 0.00013913481270825628 and parameters: {'n_estimators': 645, 'max_depth': 7, 'learning_rate': 0.010966005212945074, 'subsample': 0.7525647349150141, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:26,965] Trial 126 finished with value: 0.0001411425585053368 and parameters: {'n_estimators': 643, 'max_depth': 7, 'learning_rate': 0.0106335165106315, 'subsample': 0.7108930093047225, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:28,926] Trial 127 finished with value: 0.0009839838114021806 and parameters: {'n_estimators': 284, 'max_depth': 8, 'learning_rate': 0.005111958134011285, 'subsample': 0.7490749505421673, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:31,360] Trial 128 finished with value: 0.00014028199732659782 and parameters: {'n_estimators': 362, 'max_depth': 7, 'learning_rate': 0.030027330015479123, 'subsample': 0.7545715003733746, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:36,504] Trial 129 finished with value: 0.00015253901025979346 and parameters: {'n_estimators': 607, 'max_depth': 7, 'learning_rate': 0.007507707825735572, 'subsample': 0.8679559575649731, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:42,637] Trial 130 finished with value: 0.00013980811536793897 and parameters: {'n_estimators': 801, 'max_depth': 8, 'learning_rate': 0.00892554537753804, 'subsample': 0.7221333452384198, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:48,824] Trial 131 finished with value: 0.00014098688026671193 and parameters: {'n_estimators': 801, 'max_depth': 8, 'learning_rate': 0.008930487949620198, 'subsample': 0.7188809086079516, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:53,937] Trial 132 finished with value: 0.00014160455166846477 and parameters: {'n_estimators': 760, 'max_depth': 7, 'learning_rate': 0.011809157821159516, 'subsample': 0.6962617344269671, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:39:59,421] Trial 133 finished with value: 0.00015570483967990988 and parameters: {'n_estimators': 636, 'max_depth': 9, 'learning_rate': 0.00657312911776021, 'subsample': 0.7289321675395496, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:01,884] Trial 134 finished with value: 0.00013994165785964483 and parameters: {'n_estimators': 776, 'max_depth': 7, 'learning_rate': 0.044071115156365255, 'subsample': 0.7399998903224276, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:03,612] Trial 135 finished with value: 0.00015691564404586401 and parameters: {'n_estimators': 773, 'max_depth': 8, 'learning_rate': 0.07313523352476059, 'subsample': 0.7366787878231636, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:05,857] Trial 136 finished with value: 0.0001436595597660209 and parameters: {'n_estimators': 824, 'max_depth': 7, 'learning_rate': 0.0466837737665564, 'subsample': 0.7449502737778713, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:08,193] Trial 137 finished with value: 0.0001419440905440096 and parameters: {'n_estimators': 747, 'max_depth': 9, 'learning_rate': 0.04017256567145841, 'subsample': 0.7677831970573435, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:10,274] Trial 138 finished with value: 0.0001495312136002229 and parameters: {'n_estimators': 803, 'max_depth': 8, 'learning_rate': 0.06391825404972366, 'subsample': 0.7205206814549773, 'subsample_freq': 3}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:12,542] Trial 139 finished with value: 0.00015753060682858615 and parameters: {'n_estimators': 777, 'max_depth': 4, 'learning_rate': 0.032596629024158, 'subsample': 0.7575821611417872, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:14,997] Trial 140 finished with value: 0.0001466543543133998 and parameters: {'n_estimators': 729, 'max_depth': 7, 'learning_rate': 0.05005704800054234, 'subsample': 0.7406396097445106, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:18,809] Trial 141 finished with value: 0.00014051839943287668 and parameters: {'n_estimators': 658, 'max_depth': 7, 'learning_rate': 0.017879714025966408, 'subsample': 0.702724020302806, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:24,178] Trial 142 finished with value: 0.0001434179033374165 and parameters: {'n_estimators': 682, 'max_depth': 7, 'learning_rate': 0.01015558485643201, 'subsample': 0.819611368481632, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:28,854] Trial 143 finished with value: 0.00014002296582579023 and parameters: {'n_estimators': 850, 'max_depth': 7, 'learning_rate': 0.012258663976893154, 'subsample': 0.7837856262306965, 'subsample_freq': 5}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:34,243] Trial 144 finished with value: 0.0001385916441149138 and parameters: {'n_estimators': 841, 'max_depth': 7, 'learning_rate': 0.008606043204497567, 'subsample': 0.7780683618630079, 'subsample_freq': 4}. Best is trial 24 with value: 0.00013741536292664202.\n",
      "[I 2024-08-22 23:40:40,493] Trial 145 finished with value: 0.00013738152404961062 and parameters: {'n_estimators': 893, 'max_depth': 7, 'learning_rate': 0.008222874825459607, 'subsample': 0.7665894486368795, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:40:46,897] Trial 146 finished with value: 0.00014234983760514657 and parameters: {'n_estimators': 952, 'max_depth': 7, 'learning_rate': 0.005963469295440576, 'subsample': 0.7771712477185858, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:40:52,235] Trial 147 finished with value: 0.00013762284429450584 and parameters: {'n_estimators': 833, 'max_depth': 7, 'learning_rate': 0.008618545859267196, 'subsample': 0.7638241934845728, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:40:57,774] Trial 148 finished with value: 0.00016643930108605203 and parameters: {'n_estimators': 862, 'max_depth': 7, 'learning_rate': 0.004406957147487338, 'subsample': 0.7646579155557974, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:05,000] Trial 149 finished with value: 0.00014982390679014267 and parameters: {'n_estimators': 916, 'max_depth': 8, 'learning_rate': 0.007115639422923292, 'subsample': 0.9351148509249558, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:10,524] Trial 150 finished with value: 0.00013762755565069375 and parameters: {'n_estimators': 902, 'max_depth': 7, 'learning_rate': 0.008327868792558233, 'subsample': 0.7739741508948721, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:15,970] Trial 151 finished with value: 0.0001388453940697723 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.008174204434223963, 'subsample': 0.7756820514516016, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:21,696] Trial 152 finished with value: 0.00013770325412019893 and parameters: {'n_estimators': 893, 'max_depth': 7, 'learning_rate': 0.00827598162245768, 'subsample': 0.7876476397900969, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:27,332] Trial 153 finished with value: 0.00013806392750411223 and parameters: {'n_estimators': 885, 'max_depth': 7, 'learning_rate': 0.008256087235946731, 'subsample': 0.7743182430926092, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:33,172] Trial 154 finished with value: 0.00013853458714820787 and parameters: {'n_estimators': 885, 'max_depth': 7, 'learning_rate': 0.008190293866483117, 'subsample': 0.7752791622416769, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:40,116] Trial 155 finished with value: 0.00014282373804847792 and parameters: {'n_estimators': 888, 'max_depth': 7, 'learning_rate': 0.00613148648874895, 'subsample': 0.7726486945200574, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:49,662] Trial 156 finished with value: 0.00013819235252533207 and parameters: {'n_estimators': 892, 'max_depth': 7, 'learning_rate': 0.00818172120849314, 'subsample': 0.786892788971608, 'subsample_freq': 4}. Best is trial 145 with value: 0.00013738152404961062.\n",
      "[I 2024-08-22 23:41:56,555] Trial 157 finished with value: 0.00013736625412279977 and parameters: {'n_estimators': 895, 'max_depth': 7, 'learning_rate': 0.00800328394579543, 'subsample': 0.7849083523820384, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:02,540] Trial 158 finished with value: 0.00013768190561789037 and parameters: {'n_estimators': 896, 'max_depth': 7, 'learning_rate': 0.008059253712567252, 'subsample': 0.7857761579212255, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:08,507] Trial 159 finished with value: 0.0001496355999943385 and parameters: {'n_estimators': 892, 'max_depth': 7, 'learning_rate': 0.005194715143316208, 'subsample': 0.7880503942906851, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:14,369] Trial 160 finished with value: 0.00013780035972248166 and parameters: {'n_estimators': 929, 'max_depth': 7, 'learning_rate': 0.00837416378276511, 'subsample': 0.7824004325813759, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:20,268] Trial 161 finished with value: 0.00013820873835370342 and parameters: {'n_estimators': 927, 'max_depth': 7, 'learning_rate': 0.007820778193405322, 'subsample': 0.777716330488149, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:26,448] Trial 162 finished with value: 0.00013861257877573104 and parameters: {'n_estimators': 934, 'max_depth': 7, 'learning_rate': 0.006966294415691178, 'subsample': 0.7872787279344611, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:32,458] Trial 163 finished with value: 0.0001393042833182471 and parameters: {'n_estimators': 936, 'max_depth': 7, 'learning_rate': 0.0074889520009229224, 'subsample': 0.7898240631862575, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:41,558] Trial 164 finished with value: 0.0001433432400224256 and parameters: {'n_estimators': 967, 'max_depth': 7, 'learning_rate': 0.005613678901710504, 'subsample': 0.7819414136529719, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:51,428] Trial 165 finished with value: 0.00018477872166117702 and parameters: {'n_estimators': 875, 'max_depth': 7, 'learning_rate': 0.003913391758367262, 'subsample': 0.7994556252787628, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:42:58,861] Trial 166 finished with value: 0.00013918400904761564 and parameters: {'n_estimators': 934, 'max_depth': 7, 'learning_rate': 0.006779477362512166, 'subsample': 0.7913413645950164, 'subsample_freq': 3}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:05,272] Trial 167 finished with value: 0.00013802274409219459 and parameters: {'n_estimators': 906, 'max_depth': 7, 'learning_rate': 0.007801553973335468, 'subsample': 0.7787393475511641, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:11,197] Trial 168 finished with value: 0.00013778966961401385 and parameters: {'n_estimators': 906, 'max_depth': 7, 'learning_rate': 0.008652602588944808, 'subsample': 0.7791836834044658, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:20,022] Trial 169 finished with value: 0.00014626993725755423 and parameters: {'n_estimators': 972, 'max_depth': 7, 'learning_rate': 0.005018237554665524, 'subsample': 0.7996321536115227, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:27,758] Trial 170 finished with value: 0.0001377171916919063 and parameters: {'n_estimators': 904, 'max_depth': 7, 'learning_rate': 0.007982844887697897, 'subsample': 0.7710669672811324, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:35,212] Trial 171 finished with value: 0.00013839922310403453 and parameters: {'n_estimators': 903, 'max_depth': 7, 'learning_rate': 0.008277398322993582, 'subsample': 0.7717707130101664, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:41,980] Trial 172 finished with value: 0.00013793979581568989 and parameters: {'n_estimators': 909, 'max_depth': 7, 'learning_rate': 0.008197315305018112, 'subsample': 0.7723384967672422, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:48,666] Trial 173 finished with value: 0.00013943330006730112 and parameters: {'n_estimators': 909, 'max_depth': 7, 'learning_rate': 0.009582474307380571, 'subsample': 0.7643420644317889, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:43:57,447] Trial 174 finished with value: 0.00013869005062658283 and parameters: {'n_estimators': 909, 'max_depth': 7, 'learning_rate': 0.007935792642601261, 'subsample': 0.7810131908100868, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:04,958] Trial 175 finished with value: 0.0001379631772841683 and parameters: {'n_estimators': 952, 'max_depth': 7, 'learning_rate': 0.009670015891577703, 'subsample': 0.769510713434093, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:13,238] Trial 176 finished with value: 0.00014112955053627576 and parameters: {'n_estimators': 954, 'max_depth': 7, 'learning_rate': 0.006165239256317292, 'subsample': 0.7923053495058099, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:22,128] Trial 177 finished with value: 0.00013942655246880687 and parameters: {'n_estimators': 925, 'max_depth': 7, 'learning_rate': 0.010088602670221092, 'subsample': 0.7688665291088204, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:32,641] Trial 178 finished with value: 0.00014534428909940733 and parameters: {'n_estimators': 866, 'max_depth': 7, 'learning_rate': 0.005828501266316845, 'subsample': 0.7819688917076327, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:42,979] Trial 179 finished with value: 0.0001397679196859104 and parameters: {'n_estimators': 886, 'max_depth': 7, 'learning_rate': 0.009335883849518403, 'subsample': 0.8046963189449857, 'subsample_freq': 3}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:44:53,522] Trial 180 finished with value: 0.0001390511575062602 and parameters: {'n_estimators': 948, 'max_depth': 7, 'learning_rate': 0.00694372518939771, 'subsample': 0.7946957606501285, 'subsample_freq': 3}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:01,348] Trial 181 finished with value: 0.00013860586910463063 and parameters: {'n_estimators': 908, 'max_depth': 7, 'learning_rate': 0.0077198690075089916, 'subsample': 0.776185717103053, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:09,782] Trial 182 finished with value: 0.00013743605153955803 and parameters: {'n_estimators': 904, 'max_depth': 7, 'learning_rate': 0.008377160898612563, 'subsample': 0.7712189065740249, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:18,430] Trial 183 finished with value: 0.00013834231557545258 and parameters: {'n_estimators': 925, 'max_depth': 7, 'learning_rate': 0.009667321427067296, 'subsample': 0.766909480014994, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:26,625] Trial 184 finished with value: 0.00013822258128657697 and parameters: {'n_estimators': 876, 'max_depth': 7, 'learning_rate': 0.007604437741440425, 'subsample': 0.7619013713745423, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:35,014] Trial 185 finished with value: 0.00014099044546282894 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.006375096261019199, 'subsample': 0.7860282463071273, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:42,644] Trial 186 finished with value: 0.00013880483871517397 and parameters: {'n_estimators': 851, 'max_depth': 7, 'learning_rate': 0.009118791912192583, 'subsample': 0.7837616350831649, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:49,593] Trial 187 finished with value: 0.00014020834634359907 and parameters: {'n_estimators': 942, 'max_depth': 7, 'learning_rate': 0.010867316723711728, 'subsample': 0.7574492157432956, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:45:57,736] Trial 188 finished with value: 0.00013923181010008578 and parameters: {'n_estimators': 979, 'max_depth': 7, 'learning_rate': 0.007386993823008429, 'subsample': 0.7743122689461831, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:04,557] Trial 189 finished with value: 0.00013924489823228186 and parameters: {'n_estimators': 921, 'max_depth': 7, 'learning_rate': 0.008865041123224891, 'subsample': 0.7960310994974625, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:06,927] Trial 190 finished with value: 0.00014779360009322548 and parameters: {'n_estimators': 870, 'max_depth': 3, 'learning_rate': 0.005829480373944335, 'subsample': 0.7692925135791461, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:13,854] Trial 191 finished with value: 0.00013886037770287438 and parameters: {'n_estimators': 881, 'max_depth': 7, 'learning_rate': 0.007507348222847664, 'subsample': 0.7600559110339391, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:19,912] Trial 192 finished with value: 0.000137571585752474 and parameters: {'n_estimators': 898, 'max_depth': 7, 'learning_rate': 0.007774169593017203, 'subsample': 0.7630773850014342, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:25,683] Trial 193 finished with value: 0.00014182242322299257 and parameters: {'n_estimators': 902, 'max_depth': 7, 'learning_rate': 0.01020147125004973, 'subsample': 0.7810675171303808, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:31,604] Trial 194 finished with value: 0.00013748386611632453 and parameters: {'n_estimators': 921, 'max_depth': 7, 'learning_rate': 0.008477576286788835, 'subsample': 0.7524055688666502, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:37,265] Trial 195 finished with value: 0.00013787457974238828 and parameters: {'n_estimators': 856, 'max_depth': 7, 'learning_rate': 0.008811689191730416, 'subsample': 0.7524882331144491, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:42,403] Trial 196 finished with value: 0.00014064180272200776 and parameters: {'n_estimators': 857, 'max_depth': 7, 'learning_rate': 0.01131776163095931, 'subsample': 0.7538426638979414, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:49,081] Trial 197 finished with value: 0.000139472890677837 and parameters: {'n_estimators': 957, 'max_depth': 7, 'learning_rate': 0.006518857304999877, 'subsample': 0.7508830908248865, 'subsample_freq': 3}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:46:55,030] Trial 198 finished with value: 0.00013784175065754053 and parameters: {'n_estimators': 837, 'max_depth': 7, 'learning_rate': 0.009147060906409665, 'subsample': 0.7664848307240304, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:01,148] Trial 199 finished with value: 0.00013893131443567315 and parameters: {'n_estimators': 835, 'max_depth': 7, 'learning_rate': 0.009602918289872106, 'subsample': 0.7626765128094264, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:08,434] Trial 200 finished with value: 0.00013876352396531734 and parameters: {'n_estimators': 916, 'max_depth': 7, 'learning_rate': 0.008822203310385036, 'subsample': 0.7710180568405567, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:14,478] Trial 201 finished with value: 0.00013940748804963638 and parameters: {'n_estimators': 871, 'max_depth': 7, 'learning_rate': 0.010865701231561917, 'subsample': 0.762824577811583, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:20,790] Trial 202 finished with value: 0.00013829313105488146 and parameters: {'n_estimators': 895, 'max_depth': 7, 'learning_rate': 0.008293505994439444, 'subsample': 0.7708776022754142, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:26,996] Trial 203 finished with value: 0.0001408317174582727 and parameters: {'n_estimators': 850, 'max_depth': 7, 'learning_rate': 0.006769151863674771, 'subsample': 0.7524409272669371, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:33,392] Trial 204 finished with value: 0.00013869214071507256 and parameters: {'n_estimators': 943, 'max_depth': 7, 'learning_rate': 0.009527650017369898, 'subsample': 0.7675119087794666, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:40,039] Trial 205 finished with value: 0.0001473036161525355 and parameters: {'n_estimators': 913, 'max_depth': 7, 'learning_rate': 0.005302155648650717, 'subsample': 0.7785543986999144, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:46,170] Trial 206 finished with value: 0.00013887037609207494 and parameters: {'n_estimators': 873, 'max_depth': 7, 'learning_rate': 0.0070997852357853105, 'subsample': 0.7580615267403497, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:52,448] Trial 207 finished with value: 0.00013835741247754388 and parameters: {'n_estimators': 887, 'max_depth': 7, 'learning_rate': 0.008677126296797883, 'subsample': 0.7862482859875435, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:47:59,181] Trial 208 finished with value: 0.00014491176158935295 and parameters: {'n_estimators': 824, 'max_depth': 7, 'learning_rate': 0.006227176019190787, 'subsample': 0.8019441592914257, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:05,154] Trial 209 finished with value: 0.00014147774911437398 and parameters: {'n_estimators': 926, 'max_depth': 7, 'learning_rate': 0.01152687122429296, 'subsample': 0.7747563141783447, 'subsample_freq': 3}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:06,374] Trial 210 finished with value: 0.0006039820477981657 and parameters: {'n_estimators': 178, 'max_depth': 7, 'learning_rate': 0.010312445899221178, 'subsample': 0.6450142629742046, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:12,645] Trial 211 finished with value: 0.00013772697333621934 and parameters: {'n_estimators': 896, 'max_depth': 7, 'learning_rate': 0.008139073248514171, 'subsample': 0.7852603476336285, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:18,930] Trial 212 finished with value: 0.00013806212063433192 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.00815990819758637, 'subsample': 0.7846535725482339, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:25,018] Trial 213 finished with value: 0.0001377256812493788 and parameters: {'n_estimators': 898, 'max_depth': 7, 'learning_rate': 0.008032554333637762, 'subsample': 0.7944686480621659, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:31,198] Trial 214 finished with value: 0.0001392461961583393 and parameters: {'n_estimators': 910, 'max_depth': 7, 'learning_rate': 0.00754949529843684, 'subsample': 0.791039099254259, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:37,155] Trial 215 finished with value: 0.00013943142308002184 and parameters: {'n_estimators': 897, 'max_depth': 7, 'learning_rate': 0.009028885616364116, 'subsample': 0.7946644823988124, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:43,938] Trial 216 finished with value: 0.00014040917355491307 and parameters: {'n_estimators': 861, 'max_depth': 7, 'learning_rate': 0.007107429872656517, 'subsample': 0.8080687022656687, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:51,190] Trial 217 finished with value: 0.00013750945235948888 and parameters: {'n_estimators': 939, 'max_depth': 7, 'learning_rate': 0.008372737204086796, 'subsample': 0.7877885906527854, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:48:56,973] Trial 218 finished with value: 0.00014139463252866053 and parameters: {'n_estimators': 939, 'max_depth': 7, 'learning_rate': 0.009992725117410907, 'subsample': 0.7992598818150618, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:03,548] Trial 219 finished with value: 0.00014109165967152976 and parameters: {'n_estimators': 965, 'max_depth': 7, 'learning_rate': 0.006061245722874943, 'subsample': 0.7647315439770499, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:09,144] Trial 220 finished with value: 0.0001402433146977801 and parameters: {'n_estimators': 925, 'max_depth': 7, 'learning_rate': 0.011755571876813765, 'subsample': 0.7812687329833207, 'subsample_freq': 10}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:15,205] Trial 221 finished with value: 0.00013782698881342786 and parameters: {'n_estimators': 902, 'max_depth': 7, 'learning_rate': 0.008223817556762648, 'subsample': 0.7829456736639258, 'subsample_freq': 9}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:21,248] Trial 222 finished with value: 0.0001380415935905636 and parameters: {'n_estimators': 913, 'max_depth': 7, 'learning_rate': 0.0086593242391891, 'subsample': 0.7895758953899413, 'subsample_freq': 9}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:22,429] Trial 223 finished with value: 0.00015084159485591876 and parameters: {'n_estimators': 941, 'max_depth': 7, 'learning_rate': 0.19372877210579503, 'subsample': 0.7724658516429317, 'subsample_freq': 8}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:28,922] Trial 224 finished with value: 0.0001388789251051853 and parameters: {'n_estimators': 882, 'max_depth': 7, 'learning_rate': 0.007057022500186051, 'subsample': 0.7811644437518354, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:35,427] Trial 225 finished with value: 0.00013817100433516258 and parameters: {'n_estimators': 900, 'max_depth': 7, 'learning_rate': 0.009524992180174875, 'subsample': 0.790812781613132, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:42,126] Trial 226 finished with value: 0.00013775562134800434 and parameters: {'n_estimators': 842, 'max_depth': 7, 'learning_rate': 0.007920268625905084, 'subsample': 0.7649565337869838, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:48,695] Trial 227 finished with value: 0.00014149827469095872 and parameters: {'n_estimators': 836, 'max_depth': 7, 'learning_rate': 0.00666606939184917, 'subsample': 0.7498932873024524, 'subsample_freq': 9}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:49:55,722] Trial 228 finished with value: 0.0001384973472945303 and parameters: {'n_estimators': 861, 'max_depth': 7, 'learning_rate': 0.00841525372842851, 'subsample': 0.8172913551092157, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:50:01,808] Trial 229 finished with value: 0.00013972472390530612 and parameters: {'n_estimators': 848, 'max_depth': 7, 'learning_rate': 0.010420812237505458, 'subsample': 0.7602420719972662, 'subsample_freq': 4}. Best is trial 157 with value: 0.00013736625412279977.\n",
      "[I 2024-08-22 23:50:08,020] Trial 230 finished with value: 0.00013731512170556627 and parameters: {'n_estimators': 957, 'max_depth': 7, 'learning_rate': 0.00759982082008149, 'subsample': 0.7632617570542515, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:14,010] Trial 231 finished with value: 0.00013858422370542652 and parameters: {'n_estimators': 953, 'max_depth': 7, 'learning_rate': 0.007589869945397731, 'subsample': 0.772045778365949, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:19,474] Trial 232 finished with value: 0.00013918452192960364 and parameters: {'n_estimators': 982, 'max_depth': 7, 'learning_rate': 0.009546527756385276, 'subsample': 0.7649785285682005, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:25,259] Trial 233 finished with value: 0.0001378620885183136 and parameters: {'n_estimators': 926, 'max_depth': 7, 'learning_rate': 0.008546471288834756, 'subsample': 0.7570607663175078, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:31,506] Trial 234 finished with value: 0.0001413238159275212 and parameters: {'n_estimators': 926, 'max_depth': 7, 'learning_rate': 0.00625547010668149, 'subsample': 0.7554634645623444, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:37,224] Trial 235 finished with value: 0.00013746919170124178 and parameters: {'n_estimators': 881, 'max_depth': 7, 'learning_rate': 0.007919515751576973, 'subsample': 0.7445730682130095, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:42,908] Trial 236 finished with value: 0.00013878954155527708 and parameters: {'n_estimators': 877, 'max_depth': 7, 'learning_rate': 0.007331231756692608, 'subsample': 0.7425875759153988, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:49,298] Trial 237 finished with value: 0.00014658150521232053 and parameters: {'n_estimators': 887, 'max_depth': 7, 'learning_rate': 0.005434620357348167, 'subsample': 0.7470125476004243, 'subsample_freq': 4}. Best is trial 230 with value: 0.00013731512170556627.\n",
      "[I 2024-08-22 23:50:55,243] Trial 238 finished with value: 0.0001372017830036081 and parameters: {'n_estimators': 868, 'max_depth': 7, 'learning_rate': 0.008323831251288365, 'subsample': 0.7575640421707469, 'subsample_freq': 4}. Best is trial 238 with value: 0.0001372017830036081.\n",
      "[I 2024-08-22 23:51:00,530] Trial 239 finished with value: 0.0001365264414071099 and parameters: {'n_estimators': 872, 'max_depth': 7, 'learning_rate': 0.008515941321830582, 'subsample': 0.7548817787644444, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:06,780] Trial 240 finished with value: 0.00013936233698898202 and parameters: {'n_estimators': 871, 'max_depth': 7, 'learning_rate': 0.006817968438302566, 'subsample': 0.7581608258764263, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:12,160] Trial 241 finished with value: 0.0001379202145275607 and parameters: {'n_estimators': 846, 'max_depth': 7, 'learning_rate': 0.008582737946897985, 'subsample': 0.7555381404829149, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:17,336] Trial 242 finished with value: 0.00013831524508770853 and parameters: {'n_estimators': 864, 'max_depth': 7, 'learning_rate': 0.007707752694433122, 'subsample': 0.7629450405213802, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:24,062] Trial 243 finished with value: 0.00013726114069836007 and parameters: {'n_estimators': 893, 'max_depth': 7, 'learning_rate': 0.008574352686453133, 'subsample': 0.74945737619543, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:32,064] Trial 244 finished with value: 0.00013706583005878778 and parameters: {'n_estimators': 894, 'max_depth': 7, 'learning_rate': 0.007646670437309894, 'subsample': 0.7454520605573474, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:38,410] Trial 245 finished with value: 0.0014196367211610607 and parameters: {'n_estimators': 891, 'max_depth': 7, 'learning_rate': 0.001355722080813467, 'subsample': 0.7484930239877423, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:44,319] Trial 246 finished with value: 0.000140513104939792 and parameters: {'n_estimators': 896, 'max_depth': 7, 'learning_rate': 0.0065840979885134435, 'subsample': 0.7419934983961929, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:49,905] Trial 247 finished with value: 0.00013836572320343574 and parameters: {'n_estimators': 876, 'max_depth': 7, 'learning_rate': 0.007694567422621647, 'subsample': 0.766638075056222, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:51:55,939] Trial 248 finished with value: 0.00015466277877371798 and parameters: {'n_estimators': 910, 'max_depth': 7, 'learning_rate': 0.004710714573772926, 'subsample': 0.7453838774950121, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:02,031] Trial 249 finished with value: 0.00014434591979350348 and parameters: {'n_estimators': 885, 'max_depth': 7, 'learning_rate': 0.005875055528743981, 'subsample': 0.7826064334616107, 'subsample_freq': 3}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:06,839] Trial 250 finished with value: 0.00014248238001644768 and parameters: {'n_estimators': 818, 'max_depth': 7, 'learning_rate': 0.010383067158997575, 'subsample': 0.7759311055725235, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:12,730] Trial 251 finished with value: 0.0001379065361438163 and parameters: {'n_estimators': 916, 'max_depth': 7, 'learning_rate': 0.007281377544921947, 'subsample': 0.7640016213205524, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:18,137] Trial 252 finished with value: 0.0001395007387973872 and parameters: {'n_estimators': 933, 'max_depth': 7, 'learning_rate': 0.009107845172851608, 'subsample': 0.7861684394678471, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:24,017] Trial 253 finished with value: 0.0005023695774690339 and parameters: {'n_estimators': 897, 'max_depth': 7, 'learning_rate': 0.002178765702943019, 'subsample': 0.7969228295924985, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:29,278] Trial 254 finished with value: 0.00013830633275121567 and parameters: {'n_estimators': 867, 'max_depth': 7, 'learning_rate': 0.008034916755319628, 'subsample': 0.75114274420031, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:34,920] Trial 255 finished with value: 0.00013931716779032826 and parameters: {'n_estimators': 913, 'max_depth': 7, 'learning_rate': 0.006611680486385552, 'subsample': 0.7709348839170127, 'subsample_freq': 3}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:39,482] Trial 256 finished with value: 0.00014264860351922366 and parameters: {'n_estimators': 841, 'max_depth': 7, 'learning_rate': 0.011156686029914153, 'subsample': 0.7373659741665509, 'subsample_freq': 4}. Best is trial 239 with value: 0.0001365264414071099.\n",
      "[I 2024-08-22 23:52:46,567] Trial 257 finished with value: 0.0001364654141317644 and parameters: {'n_estimators': 887, 'max_depth': 7, 'learning_rate': 0.009276672666863547, 'subsample': 0.7614289695621157, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:52:52,934] Trial 258 finished with value: 0.0001393971458183716 and parameters: {'n_estimators': 886, 'max_depth': 7, 'learning_rate': 0.007473744376690436, 'subsample': 0.7804294429828572, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:52:58,715] Trial 259 finished with value: 0.00013930956982503547 and parameters: {'n_estimators': 900, 'max_depth': 7, 'learning_rate': 0.010034469050841559, 'subsample': 0.7590264541914887, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:05,048] Trial 260 finished with value: 0.00013702370307065132 and parameters: {'n_estimators': 930, 'max_depth': 7, 'learning_rate': 0.00854231203454819, 'subsample': 0.7471296740200881, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:11,010] Trial 261 finished with value: 0.00014330800999910563 and parameters: {'n_estimators': 938, 'max_depth': 7, 'learning_rate': 0.00568002518798671, 'subsample': 0.7453023225741973, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:16,190] Trial 262 finished with value: 0.0001390625336794592 and parameters: {'n_estimators': 921, 'max_depth': 7, 'learning_rate': 0.009054767410770942, 'subsample': 0.7513507305947146, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:17,800] Trial 263 finished with value: 0.0001507157773025781 and parameters: {'n_estimators': 970, 'max_depth': 7, 'learning_rate': 0.11016331543964569, 'subsample': 0.7353317773725576, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:25,640] Trial 264 finished with value: 0.0001407391176764324 and parameters: {'n_estimators': 881, 'max_depth': 10, 'learning_rate': 0.006594634002421546, 'subsample': 0.7568820626512923, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:30,375] Trial 265 finished with value: 0.0001405338436266537 and parameters: {'n_estimators': 940, 'max_depth': 7, 'learning_rate': 0.012373825175626116, 'subsample': 0.7446599851105943, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:36,469] Trial 266 finished with value: 0.00013831217980381317 and parameters: {'n_estimators': 870, 'max_depth': 7, 'learning_rate': 0.007633664098204022, 'subsample': 0.7690805058792031, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:41,949] Trial 267 finished with value: 0.00013987057791101855 and parameters: {'n_estimators': 914, 'max_depth': 7, 'learning_rate': 0.010545367188142696, 'subsample': 0.762492522958466, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:42,862] Trial 268 finished with value: 0.0001919717643849402 and parameters: {'n_estimators': 896, 'max_depth': 7, 'learning_rate': 0.49910212058887055, 'subsample': 0.775178550343952, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:48,856] Trial 269 finished with value: 0.00013838168661879733 and parameters: {'n_estimators': 955, 'max_depth': 7, 'learning_rate': 0.008702508098531523, 'subsample': 0.7899707732292949, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:53:57,645] Trial 270 finished with value: 0.0001384301979838807 and parameters: {'n_estimators': 928, 'max_depth': 7, 'learning_rate': 0.0072510796662150455, 'subsample': 0.7527483959742998, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:03,999] Trial 271 finished with value: 0.0001386121004659429 and parameters: {'n_estimators': 861, 'max_depth': 7, 'learning_rate': 0.009631005293932222, 'subsample': 0.7620915593841255, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:10,349] Trial 272 finished with value: 0.00014241091484874378 and parameters: {'n_estimators': 883, 'max_depth': 7, 'learning_rate': 0.006340366956778706, 'subsample': 0.8031501191631781, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:16,923] Trial 273 finished with value: 0.00013787449851616814 and parameters: {'n_estimators': 914, 'max_depth': 7, 'learning_rate': 0.008062595381688057, 'subsample': 0.7751596658719805, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:22,893] Trial 274 finished with value: 0.0001428270128662057 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.01127881418233496, 'subsample': 0.7372050165846846, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:31,418] Trial 275 finished with value: 0.0001462851754000655 and parameters: {'n_estimators': 943, 'max_depth': 8, 'learning_rate': 0.005251111320155972, 'subsample': 0.7924928865558483, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:37,494] Trial 276 finished with value: 0.0001383572021812314 and parameters: {'n_estimators': 875, 'max_depth': 7, 'learning_rate': 0.009150099885726605, 'subsample': 0.748278740535292, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:44,032] Trial 277 finished with value: 0.00013847782224165535 and parameters: {'n_estimators': 853, 'max_depth': 7, 'learning_rate': 0.007002000738913329, 'subsample': 0.7684245041075315, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:50,960] Trial 278 finished with value: 0.00013754287999902785 and parameters: {'n_estimators': 924, 'max_depth': 7, 'learning_rate': 0.008171375366244647, 'subsample': 0.7568486862671299, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:54:57,623] Trial 279 finished with value: 0.00014142854612527383 and parameters: {'n_estimators': 897, 'max_depth': 7, 'learning_rate': 0.006302561268966524, 'subsample': 0.7578727773108627, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:05,201] Trial 280 finished with value: 0.00015970492015959724 and parameters: {'n_estimators': 919, 'max_depth': 7, 'learning_rate': 0.007834332333561539, 'subsample': 0.9891023631221125, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:11,246] Trial 281 finished with value: 0.00013983043909479486 and parameters: {'n_estimators': 890, 'max_depth': 7, 'learning_rate': 0.010232374470203096, 'subsample': 0.7448829735425055, 'subsample_freq': 2}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:17,933] Trial 282 finished with value: 0.00013798706804406415 and parameters: {'n_estimators': 966, 'max_depth': 7, 'learning_rate': 0.008810297160134475, 'subsample': 0.7605727450389947, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:24,207] Trial 283 finished with value: 0.00013761130672518377 and parameters: {'n_estimators': 997, 'max_depth': 7, 'learning_rate': 0.007067636690234364, 'subsample': 0.7534880856266363, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:30,440] Trial 284 finished with value: 0.00014060616107156008 and parameters: {'n_estimators': 988, 'max_depth': 7, 'learning_rate': 0.006076520618487871, 'subsample': 0.7296468152566797, 'subsample_freq': 1}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:36,709] Trial 285 finished with value: 0.0001559288420888389 and parameters: {'n_estimators': 943, 'max_depth': 7, 'learning_rate': 0.004422403475982555, 'subsample': 0.751344131415143, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:43,564] Trial 286 finished with value: 0.00013976838434442293 and parameters: {'n_estimators': 973, 'max_depth': 7, 'learning_rate': 0.006806728068817229, 'subsample': 0.7401961771664141, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:50,124] Trial 287 finished with value: 0.00013905117346036002 and parameters: {'n_estimators': 866, 'max_depth': 7, 'learning_rate': 0.007373279270193197, 'subsample': 0.7486676136619854, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:55:57,476] Trial 288 finished with value: 0.0001433474961585564 and parameters: {'n_estimators': 985, 'max_depth': 7, 'learning_rate': 0.005484534693756585, 'subsample': 0.758756315540935, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:04,197] Trial 289 finished with value: 0.00013746333521333858 and parameters: {'n_estimators': 960, 'max_depth': 7, 'learning_rate': 0.007830931622139166, 'subsample': 0.7668793229421896, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:10,798] Trial 290 finished with value: 0.00013993238999214275 and parameters: {'n_estimators': 999, 'max_depth': 7, 'learning_rate': 0.009619239881682598, 'subsample': 0.7529891551217104, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:16,915] Trial 291 finished with value: 0.00014204327844778795 and parameters: {'n_estimators': 970, 'max_depth': 7, 'learning_rate': 0.011804160684152557, 'subsample': 0.7671204909510605, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:22,890] Trial 292 finished with value: 0.00013919909742751 and parameters: {'n_estimators': 945, 'max_depth': 7, 'learning_rate': 0.007091197434726027, 'subsample': 0.7398548348137064, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:28,934] Trial 293 finished with value: 0.0001375977410430777 and parameters: {'n_estimators': 997, 'max_depth': 7, 'learning_rate': 0.008043197587918558, 'subsample': 0.7570010642991127, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:34,801] Trial 294 finished with value: 0.00014154013147916661 and parameters: {'n_estimators': 964, 'max_depth': 7, 'learning_rate': 0.005898287016774296, 'subsample': 0.7551859676842376, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:39,999] Trial 295 finished with value: 0.0001406436565266608 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.009912025868885514, 'subsample': 0.757507509048903, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:45,596] Trial 296 finished with value: 0.00013755258610224623 and parameters: {'n_estimators': 958, 'max_depth': 7, 'learning_rate': 0.007099009177348121, 'subsample': 0.7462588734146952, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:51,982] Trial 297 finished with value: 0.00014676049215742233 and parameters: {'n_estimators': 999, 'max_depth': 7, 'learning_rate': 0.004912748456941212, 'subsample': 0.7322022858349473, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:56:58,080] Trial 298 finished with value: 0.00013983746142848193 and parameters: {'n_estimators': 976, 'max_depth': 7, 'learning_rate': 0.006449009048403218, 'subsample': 0.7442441851908502, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:04,277] Trial 299 finished with value: 0.00013813386378037316 and parameters: {'n_estimators': 957, 'max_depth': 7, 'learning_rate': 0.007170590495209332, 'subsample': 0.7478082052775539, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:10,612] Trial 300 finished with value: 0.00013816475153607797 and parameters: {'n_estimators': 985, 'max_depth': 8, 'learning_rate': 0.008647190520459458, 'subsample': 0.7393463951669426, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:16,287] Trial 301 finished with value: 0.00013784079640991403 and parameters: {'n_estimators': 959, 'max_depth': 7, 'learning_rate': 0.0070443315877179715, 'subsample': 0.7627161018481874, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:21,356] Trial 302 finished with value: 0.00013938355266954907 and parameters: {'n_estimators': 940, 'max_depth': 7, 'learning_rate': 0.010968355942967713, 'subsample': 0.7502489541617272, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:23,731] Trial 303 finished with value: 0.00017654918504216688 and parameters: {'n_estimators': 393, 'max_depth': 7, 'learning_rate': 0.009079779386909471, 'subsample': 0.7672003644772023, 'subsample_freq': 2}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:29,404] Trial 304 finished with value: 0.00014344429643989564 and parameters: {'n_estimators': 922, 'max_depth': 7, 'learning_rate': 0.005818436800699409, 'subsample': 0.7554804869647673, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:34,840] Trial 305 finished with value: 0.00013811244009372334 and parameters: {'n_estimators': 979, 'max_depth': 7, 'learning_rate': 0.008014827842712777, 'subsample': 0.7279249224645908, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:39,671] Trial 306 finished with value: 0.00013936442843837687 and parameters: {'n_estimators': 958, 'max_depth': 7, 'learning_rate': 0.012534263597365446, 'subsample': 0.7719011519664234, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:45,177] Trial 307 finished with value: 0.0001395558829536242 and parameters: {'n_estimators': 928, 'max_depth': 7, 'learning_rate': 0.0066774757512626445, 'subsample': 0.7436857243082566, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:50,209] Trial 308 finished with value: 0.00014061647853230345 and parameters: {'n_estimators': 948, 'max_depth': 7, 'learning_rate': 0.009983937832779418, 'subsample': 0.7615406831164583, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:56,356] Trial 309 finished with value: 0.00013752323717473703 and parameters: {'n_estimators': 916, 'max_depth': 8, 'learning_rate': 0.008046021053216059, 'subsample': 0.7524727230097423, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:57:59,173] Trial 310 finished with value: 0.0003348186546333776 and parameters: {'n_estimators': 444, 'max_depth': 9, 'learning_rate': 0.0053472813422996215, 'subsample': 0.7363721093292923, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:04,892] Trial 311 finished with value: 0.000241570032205812 and parameters: {'n_estimators': 930, 'max_depth': 8, 'learning_rate': 0.0030279154130960066, 'subsample': 0.7536103464913386, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:11,033] Trial 312 finished with value: 0.0001375273320895629 and parameters: {'n_estimators': 917, 'max_depth': 8, 'learning_rate': 0.008648140980679368, 'subsample': 0.7468019567214794, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:17,203] Trial 313 finished with value: 0.0001379676709223253 and parameters: {'n_estimators': 958, 'max_depth': 8, 'learning_rate': 0.009168084065963639, 'subsample': 0.7455279816219538, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:23,413] Trial 314 finished with value: 0.00013924714681338854 and parameters: {'n_estimators': 923, 'max_depth': 8, 'learning_rate': 0.007389388611387733, 'subsample': 0.7348851473409375, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:24,990] Trial 315 finished with value: 0.0002674528244509504 and parameters: {'n_estimators': 242, 'max_depth': 8, 'learning_rate': 0.010973388155641126, 'subsample': 0.7235708445566998, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:31,930] Trial 316 finished with value: 0.00013937757503664758 and parameters: {'n_estimators': 984, 'max_depth': 8, 'learning_rate': 0.006353327154568225, 'subsample': 0.7516594429477066, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:37,799] Trial 317 finished with value: 0.00013752945195160687 and parameters: {'n_estimators': 935, 'max_depth': 8, 'learning_rate': 0.008930647912073137, 'subsample': 0.7435554649302015, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:43,655] Trial 318 finished with value: 0.00014028111630797515 and parameters: {'n_estimators': 944, 'max_depth': 8, 'learning_rate': 0.009767352264192765, 'subsample': 0.7421829458222382, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:49,675] Trial 319 finished with value: 0.00013828699959591545 and parameters: {'n_estimators': 969, 'max_depth': 8, 'learning_rate': 0.008793958492424573, 'subsample': 0.7327402805980396, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:58:55,644] Trial 320 finished with value: 0.0001729339629901358 and parameters: {'n_estimators': 934, 'max_depth': 8, 'learning_rate': 0.003917167381510778, 'subsample': 0.7473679731710897, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:01,035] Trial 321 finished with value: 0.0001397474729470411 and parameters: {'n_estimators': 920, 'max_depth': 8, 'learning_rate': 0.011255473742241218, 'subsample': 0.7574285552122846, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:07,444] Trial 322 finished with value: 0.00013811712259896954 and parameters: {'n_estimators': 953, 'max_depth': 8, 'learning_rate': 0.007407805677516938, 'subsample': 0.7425266381358248, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:13,837] Trial 323 finished with value: 0.00014453324057539594 and parameters: {'n_estimators': 912, 'max_depth': 8, 'learning_rate': 0.008758211568081114, 'subsample': 0.9011954738363426, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:19,693] Trial 324 finished with value: 0.00013943223466844897 and parameters: {'n_estimators': 934, 'max_depth': 8, 'learning_rate': 0.010121010486346749, 'subsample': 0.7546928067224243, 'subsample_freq': 2}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:23,642] Trial 325 finished with value: 0.0001420644496659177 and parameters: {'n_estimators': 984, 'max_depth': 6, 'learning_rate': 0.012501564762338152, 'subsample': 0.7630175531289483, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:28,423] Trial 326 finished with value: 0.00013932961809693366 and parameters: {'n_estimators': 999, 'max_depth': 6, 'learning_rate': 0.0067069192057874205, 'subsample': 0.7380263762594337, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:34,271] Trial 327 finished with value: 0.00013731593353804374 and parameters: {'n_estimators': 880, 'max_depth': 8, 'learning_rate': 0.007885786111934868, 'subsample': 0.7486602689200478, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:40,320] Trial 328 finished with value: 0.00014457007034650077 and parameters: {'n_estimators': 876, 'max_depth': 8, 'learning_rate': 0.0059871307446895655, 'subsample': 0.7485921132750647, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:46,468] Trial 329 finished with value: 0.00013822813571189783 and parameters: {'n_estimators': 914, 'max_depth': 8, 'learning_rate': 0.007752126255336371, 'subsample': 0.7537052234899128, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:49,676] Trial 330 finished with value: 0.00018173580184524337 and parameters: {'n_estimators': 496, 'max_depth': 9, 'learning_rate': 0.007006817788198775, 'subsample': 0.7157879362593784, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-22 23:59:55,677] Trial 331 finished with value: 0.0001389172923004481 and parameters: {'n_estimators': 963, 'max_depth': 8, 'learning_rate': 0.009554977939843192, 'subsample': 0.7434477197592927, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:02,076] Trial 332 finished with value: 0.00013774264615278674 and parameters: {'n_estimators': 879, 'max_depth': 8, 'learning_rate': 0.0080127749850379, 'subsample': 0.7284365864889356, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:08,721] Trial 333 finished with value: 0.00014837322911674227 and parameters: {'n_estimators': 945, 'max_depth': 8, 'learning_rate': 0.004950760165418418, 'subsample': 0.7588538488406172, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:14,071] Trial 334 finished with value: 0.0004160490593741805 and parameters: {'n_estimators': 862, 'max_depth': 8, 'learning_rate': 0.0024871289240758314, 'subsample': 0.7364743775081459, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:20,477] Trial 335 finished with value: 0.00014326138863855368 and parameters: {'n_estimators': 916, 'max_depth': 8, 'learning_rate': 0.005900743515460038, 'subsample': 0.748376427089197, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:27,166] Trial 336 finished with value: 0.00013704707924231283 and parameters: {'n_estimators': 933, 'max_depth': 8, 'learning_rate': 0.008908354379123433, 'subsample': 0.7612648449454641, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:30,719] Trial 337 finished with value: 0.00014389634601667724 and parameters: {'n_estimators': 474, 'max_depth': 8, 'learning_rate': 0.010760968243602996, 'subsample': 0.7524913984369432, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:37,593] Trial 338 finished with value: 0.00013766616768501558 and parameters: {'n_estimators': 941, 'max_depth': 8, 'learning_rate': 0.007307216582201019, 'subsample': 0.7617336030174967, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:43,585] Trial 339 finished with value: 0.00013986533445543855 and parameters: {'n_estimators': 969, 'max_depth': 8, 'learning_rate': 0.009083615198183105, 'subsample': 0.7421371029937772, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:49,909] Trial 340 finished with value: 0.00014086174820430092 and parameters: {'n_estimators': 927, 'max_depth': 8, 'learning_rate': 0.006497334211777223, 'subsample': 0.7314996306240459, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:00:56,129] Trial 341 finished with value: 0.0001375928807651657 and parameters: {'n_estimators': 956, 'max_depth': 8, 'learning_rate': 0.008099253876166031, 'subsample': 0.7520888163318918, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:02,025] Trial 342 finished with value: 0.00014013435899887082 and parameters: {'n_estimators': 949, 'max_depth': 8, 'learning_rate': 0.010101312641705324, 'subsample': 0.7646493965950951, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:07,173] Trial 343 finished with value: 0.00014136164999974744 and parameters: {'n_estimators': 931, 'max_depth': 8, 'learning_rate': 0.012861420132115766, 'subsample': 0.7231761440974275, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:09,299] Trial 344 finished with value: 0.0002448455988967043 and parameters: {'n_estimators': 338, 'max_depth': 8, 'learning_rate': 0.008266100493506881, 'subsample': 0.747245976615857, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:15,115] Trial 345 finished with value: 0.0001389979338030759 and parameters: {'n_estimators': 903, 'max_depth': 8, 'learning_rate': 0.009237760322459147, 'subsample': 0.7575367803684615, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:16,580] Trial 346 finished with value: 0.00015635725859537543 and parameters: {'n_estimators': 954, 'max_depth': 8, 'learning_rate': 0.08745951104326159, 'subsample': 0.7385044142571486, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:22,249] Trial 347 finished with value: 0.0001405801190787835 and parameters: {'n_estimators': 911, 'max_depth': 8, 'learning_rate': 0.010976818697984978, 'subsample': 0.7665182256889885, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:28,295] Trial 348 finished with value: 0.00014059845801276085 and parameters: {'n_estimators': 934, 'max_depth': 8, 'learning_rate': 0.007878212968681603, 'subsample': 0.6837291544851145, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:33,934] Trial 349 finished with value: 0.00013894993005120326 and parameters: {'n_estimators': 888, 'max_depth': 8, 'learning_rate': 0.00883152484898841, 'subsample': 0.7496566219298243, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:40,045] Trial 350 finished with value: 0.00013846141855490676 and parameters: {'n_estimators': 920, 'max_depth': 8, 'learning_rate': 0.007624434883059522, 'subsample': 0.7591130540792328, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:45,896] Trial 351 finished with value: 0.00013787488015226098 and parameters: {'n_estimators': 960, 'max_depth': 8, 'learning_rate': 0.010001847774917772, 'subsample': 0.7709026284307674, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:51,522] Trial 352 finished with value: 0.00013971111123397637 and parameters: {'n_estimators': 886, 'max_depth': 9, 'learning_rate': 0.012294818741769785, 'subsample': 0.7438175384972093, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:01:57,692] Trial 353 finished with value: 0.00014014438643722595 and parameters: {'n_estimators': 906, 'max_depth': 8, 'learning_rate': 0.006402704016033762, 'subsample': 0.7530140110548891, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:03,674] Trial 354 finished with value: 0.0001374623309730682 and parameters: {'n_estimators': 933, 'max_depth': 8, 'learning_rate': 0.008547992619176492, 'subsample': 0.7380326211617452, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:10,408] Trial 355 finished with value: 0.000140129931226648 and parameters: {'n_estimators': 934, 'max_depth': 9, 'learning_rate': 0.00916696916639604, 'subsample': 0.7346822351249068, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:15,791] Trial 356 finished with value: 0.0001410345973746186 and parameters: {'n_estimators': 911, 'max_depth': 8, 'learning_rate': 0.011141669899105852, 'subsample': 0.7266471199210618, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:22,242] Trial 357 finished with value: 0.00014469793366663842 and parameters: {'n_estimators': 934, 'max_depth': 8, 'learning_rate': 0.0055630490083407895, 'subsample': 0.7413953116186353, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:28,206] Trial 358 finished with value: 0.0001409563216513387 and parameters: {'n_estimators': 887, 'max_depth': 8, 'learning_rate': 0.0069824788011991126, 'subsample': 0.7116059482780969, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:34,346] Trial 359 finished with value: 0.0001369745320136904 and parameters: {'n_estimators': 947, 'max_depth': 8, 'learning_rate': 0.008547831298474846, 'subsample': 0.7467803446245305, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:35,252] Trial 360 finished with value: 0.0011976362847212652 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.00973950781893981, 'subsample': 0.7338967760809574, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:41,284] Trial 361 finished with value: 0.0001375578684784983 and parameters: {'n_estimators': 912, 'max_depth': 8, 'learning_rate': 0.008745251127635462, 'subsample': 0.7444392595851164, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:43,900] Trial 362 finished with value: 0.0001531696245610677 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.014250573771746997, 'subsample': 0.7236939204471856, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:49,312] Trial 363 finished with value: 0.00014118903511611602 and parameters: {'n_estimators': 920, 'max_depth': 8, 'learning_rate': 0.011507352145959328, 'subsample': 0.7377908481095227, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:02:55,257] Trial 364 finished with value: 0.00013777581836665382 and parameters: {'n_estimators': 942, 'max_depth': 8, 'learning_rate': 0.00929148522540818, 'subsample': 0.7456736874972046, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:00,627] Trial 365 finished with value: 0.00014420759692599232 and parameters: {'n_estimators': 907, 'max_depth': 8, 'learning_rate': 0.010398686018669773, 'subsample': 0.6736292558227477, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:01,737] Trial 366 finished with value: 0.000148878045483595 and parameters: {'n_estimators': 874, 'max_depth': 8, 'learning_rate': 0.17928228626850523, 'subsample': 0.7289444546806931, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:07,974] Trial 367 finished with value: 0.0001364761742431365 and parameters: {'n_estimators': 928, 'max_depth': 8, 'learning_rate': 0.008428769983931562, 'subsample': 0.7454447050168344, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:14,435] Trial 368 finished with value: 0.00013915832841900067 and parameters: {'n_estimators': 945, 'max_depth': 8, 'learning_rate': 0.007045581522145818, 'subsample': 0.7403318852731806, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:20,782] Trial 369 finished with value: 0.00013726269433236333 and parameters: {'n_estimators': 936, 'max_depth': 8, 'learning_rate': 0.008368791693366507, 'subsample': 0.749063239920906, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:26,100] Trial 370 finished with value: 0.0001401182166104091 and parameters: {'n_estimators': 931, 'max_depth': 8, 'learning_rate': 0.012642321848648799, 'subsample': 0.7520500722679346, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:32,690] Trial 371 finished with value: 0.00013784672435470258 and parameters: {'n_estimators': 925, 'max_depth': 9, 'learning_rate': 0.00883728649013372, 'subsample': 0.762622602863574, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:38,348] Trial 372 finished with value: 0.00013944975729140915 and parameters: {'n_estimators': 895, 'max_depth': 8, 'learning_rate': 0.01028072502762906, 'subsample': 0.7576828150129787, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:44,288] Trial 373 finished with value: 0.00013775219990435776 and parameters: {'n_estimators': 922, 'max_depth': 8, 'learning_rate': 0.008277809848655629, 'subsample': 0.7352087418174655, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:50,271] Trial 374 finished with value: 0.00013786094291935058 and parameters: {'n_estimators': 861, 'max_depth': 8, 'learning_rate': 0.007976064966019903, 'subsample': 0.7698881865338311, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:03:56,333] Trial 375 finished with value: 0.00014782751366797958 and parameters: {'n_estimators': 945, 'max_depth': 8, 'learning_rate': 0.009791535986867017, 'subsample': 0.9222591710422365, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:02,576] Trial 376 finished with value: 0.0001414461799186512 and parameters: {'n_estimators': 883, 'max_depth': 8, 'learning_rate': 0.0063527418130053396, 'subsample': 0.750992720330642, 'subsample_freq': 2}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:07,923] Trial 377 finished with value: 0.00014036345043899297 and parameters: {'n_estimators': 916, 'max_depth': 8, 'learning_rate': 0.011842723649416128, 'subsample': 0.7450734327164803, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:14,049] Trial 378 finished with value: 0.0001365381561312556 and parameters: {'n_estimators': 895, 'max_depth': 8, 'learning_rate': 0.008852698848002128, 'subsample': 0.7656345691962292, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:19,667] Trial 379 finished with value: 0.0001407269220924819 and parameters: {'n_estimators': 854, 'max_depth': 8, 'learning_rate': 0.010383468604394024, 'subsample': 0.7736393611216883, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:25,612] Trial 380 finished with value: 0.00014130238760361663 and parameters: {'n_estimators': 892, 'max_depth': 8, 'learning_rate': 0.00909642998859826, 'subsample': 0.7187242554432149, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:32,840] Trial 381 finished with value: 0.00013961334461075017 and parameters: {'n_estimators': 874, 'max_depth': 8, 'learning_rate': 0.0073702604815743126, 'subsample': 0.7761533365390064, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:38,662] Trial 382 finished with value: 0.00014060810614005981 and parameters: {'n_estimators': 902, 'max_depth': 8, 'learning_rate': 0.013308443419355161, 'subsample': 0.7637540920483645, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:42,256] Trial 383 finished with value: 0.00015166727651000787 and parameters: {'n_estimators': 535, 'max_depth': 8, 'learning_rate': 0.008657696141220613, 'subsample': 0.6614240767912802, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:47,603] Trial 384 finished with value: 0.00014010816009922523 and parameters: {'n_estimators': 875, 'max_depth': 8, 'learning_rate': 0.011423637985473238, 'subsample': 0.7673397862424198, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:53,740] Trial 385 finished with value: 0.00014001346157484226 and parameters: {'n_estimators': 901, 'max_depth': 8, 'learning_rate': 0.007461303997628795, 'subsample': 0.7320531653981717, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:04:59,306] Trial 386 finished with value: 0.002017238084281757 and parameters: {'n_estimators': 937, 'max_depth': 9, 'learning_rate': 0.0010660948983356544, 'subsample': 0.614420072329225, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:05,913] Trial 387 finished with value: 0.00014129227575261999 and parameters: {'n_estimators': 967, 'max_depth': 8, 'learning_rate': 0.005895689313923374, 'subsample': 0.7510786132829135, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:11,248] Trial 388 finished with value: 0.00014023312965398104 and parameters: {'n_estimators': 852, 'max_depth': 8, 'learning_rate': 0.009684414477925334, 'subsample': 0.739681608029924, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:17,527] Trial 389 finished with value: 0.0001397971308611774 and parameters: {'n_estimators': 908, 'max_depth': 8, 'learning_rate': 0.00664382006366264, 'subsample': 0.7657574538854903, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:23,389] Trial 390 finished with value: 0.000137553069259097 and parameters: {'n_estimators': 887, 'max_depth': 8, 'learning_rate': 0.007984809805322556, 'subsample': 0.7545557071218801, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:29,642] Trial 391 finished with value: 0.00013841777991135541 and parameters: {'n_estimators': 950, 'max_depth': 8, 'learning_rate': 0.008819031225780838, 'subsample': 0.7594012864751927, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:35,135] Trial 392 finished with value: 0.0001406331130500251 and parameters: {'n_estimators': 929, 'max_depth': 8, 'learning_rate': 0.010397358264595726, 'subsample': 0.7476522440989499, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:39,187] Trial 393 finished with value: 0.00014002584124402998 and parameters: {'n_estimators': 867, 'max_depth': 6, 'learning_rate': 0.0073177538496030335, 'subsample': 0.7762392967021404, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:41,355] Trial 394 finished with value: 0.0001466902125496074 and parameters: {'n_estimators': 911, 'max_depth': 4, 'learning_rate': 0.009029584726881765, 'subsample': 0.7392443152791404, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:47,743] Trial 395 finished with value: 0.00014637284463569342 and parameters: {'n_estimators': 942, 'max_depth': 8, 'learning_rate': 0.005352178896926814, 'subsample': 0.760232932820961, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:53,250] Trial 396 finished with value: 0.0001418485832118687 and parameters: {'n_estimators': 971, 'max_depth': 8, 'learning_rate': 0.01106768869960883, 'subsample': 0.7278379712430773, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:05:59,393] Trial 397 finished with value: 0.0001410042619855674 and parameters: {'n_estimators': 893, 'max_depth': 8, 'learning_rate': 0.006425410789421265, 'subsample': 0.7708587130641127, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:04,915] Trial 398 finished with value: 0.00013876911254556557 and parameters: {'n_estimators': 825, 'max_depth': 8, 'learning_rate': 0.008010274380191309, 'subsample': 0.7489209944403853, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:09,529] Trial 399 finished with value: 0.00014094515689111326 and parameters: {'n_estimators': 923, 'max_depth': 8, 'learning_rate': 0.015103379383961321, 'subsample': 0.7572838313532756, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:15,778] Trial 400 finished with value: 0.0001406375355062425 and parameters: {'n_estimators': 877, 'max_depth': 10, 'learning_rate': 0.009421756304328597, 'subsample': 0.7017132816716382, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:22,036] Trial 401 finished with value: 0.00013954029787732525 and parameters: {'n_estimators': 905, 'max_depth': 8, 'learning_rate': 0.007223597077190894, 'subsample': 0.7392361315826472, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:23,746] Trial 402 finished with value: 0.0002211996394458321 and parameters: {'n_estimators': 361, 'max_depth': 6, 'learning_rate': 0.008256780317833124, 'subsample': 0.7671865164219431, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:29,217] Trial 403 finished with value: 0.000140155017773865 and parameters: {'n_estimators': 952, 'max_depth': 8, 'learning_rate': 0.010362092920947091, 'subsample': 0.7474353252566545, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:35,466] Trial 404 finished with value: 0.0001408175842108245 and parameters: {'n_estimators': 929, 'max_depth': 8, 'learning_rate': 0.006495966297827186, 'subsample': 0.7330325941938275, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:36,972] Trial 405 finished with value: 0.0003625031047821414 and parameters: {'n_estimators': 259, 'max_depth': 7, 'learning_rate': 0.00876964751556606, 'subsample': 0.7778741245750519, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:42,701] Trial 406 finished with value: 0.00013922493428637043 and parameters: {'n_estimators': 855, 'max_depth': 8, 'learning_rate': 0.007628079656763535, 'subsample': 0.7570453245730187, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:48,137] Trial 407 finished with value: 0.00014005857274900792 and parameters: {'n_estimators': 890, 'max_depth': 9, 'learning_rate': 0.012777176544353562, 'subsample': 0.7452849623962255, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:53,527] Trial 408 finished with value: 0.0001436590864362525 and parameters: {'n_estimators': 915, 'max_depth': 7, 'learning_rate': 0.005839740131629782, 'subsample': 0.7636295851180531, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:06:59,754] Trial 409 finished with value: 0.00013980780266695586 and parameters: {'n_estimators': 962, 'max_depth': 7, 'learning_rate': 0.00966020762352748, 'subsample': 0.7515551021966271, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:07,329] Trial 410 finished with value: 0.0001503828101864424 and parameters: {'n_estimators': 939, 'max_depth': 8, 'learning_rate': 0.004807798963996029, 'subsample': 0.7703347653127953, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:13,895] Trial 411 finished with value: 0.00013891687893920112 and parameters: {'n_estimators': 906, 'max_depth': 7, 'learning_rate': 0.00708735446636561, 'subsample': 0.742938233918312, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:20,302] Trial 412 finished with value: 0.00013966295161394536 and parameters: {'n_estimators': 975, 'max_depth': 7, 'learning_rate': 0.0113904337501537, 'subsample': 0.7568221048507673, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:21,372] Trial 413 finished with value: 0.00017273055348925322 and parameters: {'n_estimators': 873, 'max_depth': 7, 'learning_rate': 0.2618724455879975, 'subsample': 0.7639112863560901, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:29,103] Trial 414 finished with value: 0.00013787226984852881 and parameters: {'n_estimators': 934, 'max_depth': 8, 'learning_rate': 0.008281883649615884, 'subsample': 0.7779276869417695, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:35,005] Trial 415 finished with value: 0.0001425125085058146 and parameters: {'n_estimators': 845, 'max_depth': 7, 'learning_rate': 0.009272360931325094, 'subsample': 0.6517718686341357, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:42,746] Trial 416 finished with value: 0.00014092668647517473 and parameters: {'n_estimators': 891, 'max_depth': 8, 'learning_rate': 0.006724517926892843, 'subsample': 0.7223325516289031, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:48,922] Trial 417 finished with value: 0.0001436005350834359 and parameters: {'n_estimators': 916, 'max_depth': 7, 'learning_rate': 0.007814332267116975, 'subsample': 0.6287283357577275, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:07:56,417] Trial 418 finished with value: 0.00015900061007040315 and parameters: {'n_estimators': 949, 'max_depth': 7, 'learning_rate': 0.009240104198673474, 'subsample': 0.970020055040662, 'subsample_freq': 7}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:03,349] Trial 419 finished with value: 0.00013902448202693802 and parameters: {'n_estimators': 901, 'max_depth': 8, 'learning_rate': 0.011010062586159133, 'subsample': 0.7503585668557556, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:04,455] Trial 420 finished with value: 0.00022602078557775406 and parameters: {'n_estimators': 925, 'max_depth': 6, 'learning_rate': 0.6518493224736415, 'subsample': 0.7340700729686376, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:11,303] Trial 421 finished with value: 0.0007327515385336566 and parameters: {'n_estimators': 880, 'max_depth': 8, 'learning_rate': 0.0018969016015645548, 'subsample': 0.7404272400276594, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:13,385] Trial 422 finished with value: 0.00014803048298082735 and parameters: {'n_estimators': 865, 'max_depth': 7, 'learning_rate': 0.05700520507228981, 'subsample': 0.7602375725817523, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:19,932] Trial 423 finished with value: 0.00014303227354570735 and parameters: {'n_estimators': 955, 'max_depth': 7, 'learning_rate': 0.005807345634269157, 'subsample': 0.7710570935454497, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:21,474] Trial 424 finished with value: 0.0007690147677380503 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.008104734881281994, 'subsample': 0.7513811396680498, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:28,270] Trial 425 finished with value: 0.0001403208930926879 and parameters: {'n_estimators': 930, 'max_depth': 7, 'learning_rate': 0.007085110373450211, 'subsample': 0.7272796293590207, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:35,008] Trial 426 finished with value: 0.000139123870978174 and parameters: {'n_estimators': 908, 'max_depth': 8, 'learning_rate': 0.010003747818812475, 'subsample': 0.7455782619837932, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:41,740] Trial 427 finished with value: 0.0001370660036497621 and parameters: {'n_estimators': 974, 'max_depth': 7, 'learning_rate': 0.008573673544867214, 'subsample': 0.7558830649872779, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:49,298] Trial 428 finished with value: 0.00013999901146308235 and parameters: {'n_estimators': 975, 'max_depth': 7, 'learning_rate': 0.006339226433959455, 'subsample': 0.7793304530037332, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:08:56,530] Trial 429 finished with value: 0.0001377262068463194 and parameters: {'n_estimators': 971, 'max_depth': 7, 'learning_rate': 0.007571040446036775, 'subsample': 0.7627954423424939, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:02,829] Trial 430 finished with value: 0.0001415560478773568 and parameters: {'n_estimators': 983, 'max_depth': 7, 'learning_rate': 0.012031442984943271, 'subsample': 0.7688380190897873, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:04,088] Trial 431 finished with value: 0.001087168781139373 and parameters: {'n_estimators': 163, 'max_depth': 7, 'learning_rate': 0.00845262049030872, 'subsample': 0.7545670924649249, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:10,046] Trial 432 finished with value: 0.0001391102623936094 and parameters: {'n_estimators': 956, 'max_depth': 7, 'learning_rate': 0.010123607919619214, 'subsample': 0.7581383772854406, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:16,646] Trial 433 finished with value: 0.00013997184220821492 and parameters: {'n_estimators': 893, 'max_depth': 7, 'learning_rate': 0.007202208326617568, 'subsample': 0.7748162770825872, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:17,788] Trial 434 finished with value: 0.00015846678374654188 and parameters: {'n_estimators': 424, 'max_depth': 7, 'learning_rate': 0.11718366228353655, 'subsample': 0.7830666127695803, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:24,673] Trial 435 finished with value: 0.00014662933667507647 and parameters: {'n_estimators': 866, 'max_depth': 7, 'learning_rate': 0.0056082652717556756, 'subsample': 0.7657817474624609, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:31,068] Trial 436 finished with value: 0.0001379433188036978 and parameters: {'n_estimators': 836, 'max_depth': 7, 'learning_rate': 0.008316637833844216, 'subsample': 0.7540832393024286, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:38,193] Trial 437 finished with value: 0.00015592897293041462 and parameters: {'n_estimators': 946, 'max_depth': 7, 'learning_rate': 0.004373568639644848, 'subsample': 0.7636826806394393, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:43,461] Trial 438 finished with value: 0.00014427142516753075 and parameters: {'n_estimators': 887, 'max_depth': 7, 'learning_rate': 0.013932033839879947, 'subsample': 0.8759363950933261, 'subsample_freq': 6}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:48,741] Trial 439 finished with value: 0.00014077560257245625 and parameters: {'n_estimators': 916, 'max_depth': 6, 'learning_rate': 0.006504688506760265, 'subsample': 0.7464510508744333, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:09:54,632] Trial 440 finished with value: 0.00014000019489578933 and parameters: {'n_estimators': 954, 'max_depth': 7, 'learning_rate': 0.010319784768162584, 'subsample': 0.7360979051530173, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:00,606] Trial 441 finished with value: 0.0001381865649235796 and parameters: {'n_estimators': 900, 'max_depth': 7, 'learning_rate': 0.00884461396809164, 'subsample': 0.7557039871357546, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:07,458] Trial 442 finished with value: 0.00013844633760682154 and parameters: {'n_estimators': 976, 'max_depth': 7, 'learning_rate': 0.007438983776045555, 'subsample': 0.7727049771231929, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:13,178] Trial 443 finished with value: 0.00014057968617083467 and parameters: {'n_estimators': 922, 'max_depth': 7, 'learning_rate': 0.011745687918822969, 'subsample': 0.7501777724641784, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:18,726] Trial 444 finished with value: 0.0001386353644951459 and parameters: {'n_estimators': 881, 'max_depth': 7, 'learning_rate': 0.009856511294060056, 'subsample': 0.7611711554661443, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:25,270] Trial 445 finished with value: 0.00020191771511949893 and parameters: {'n_estimators': 940, 'max_depth': 7, 'learning_rate': 0.0033775047958071107, 'subsample': 0.7376751258202063, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:31,190] Trial 446 finished with value: 0.00014008172710484383 and parameters: {'n_estimators': 812, 'max_depth': 7, 'learning_rate': 0.008019811364339022, 'subsample': 0.6887156066875434, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:36,974] Trial 447 finished with value: 0.0001413129428029351 and parameters: {'n_estimators': 853, 'max_depth': 7, 'learning_rate': 0.009080173408887985, 'subsample': 0.7158528436819417, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:46,294] Trial 448 finished with value: 0.0001400896727671394 and parameters: {'n_estimators': 910, 'max_depth': 9, 'learning_rate': 0.006513888399917361, 'subsample': 0.7664456785059321, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:50,505] Trial 449 finished with value: 0.0001555807537129209 and parameters: {'n_estimators': 561, 'max_depth': 7, 'learning_rate': 0.007345926415500255, 'subsample': 0.7853663790282572, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:10:52,315] Trial 450 finished with value: 0.00015674220079808164 and parameters: {'n_estimators': 931, 'max_depth': 7, 'learning_rate': 0.07207714314844765, 'subsample': 0.7486350376009666, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:00,195] Trial 451 finished with value: 0.00014355904539507192 and parameters: {'n_estimators': 960, 'max_depth': 8, 'learning_rate': 0.005536388671072218, 'subsample': 0.7587838730338111, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:06,650] Trial 452 finished with value: 0.0001415032100607133 and parameters: {'n_estimators': 873, 'max_depth': 7, 'learning_rate': 0.01068492724624529, 'subsample': 0.7749251240428179, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:14,047] Trial 453 finished with value: 0.00013708825572646946 and parameters: {'n_estimators': 897, 'max_depth': 8, 'learning_rate': 0.008521240991445812, 'subsample': 0.7416216307870992, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:21,183] Trial 454 finished with value: 0.00014145625401193937 and parameters: {'n_estimators': 890, 'max_depth': 7, 'learning_rate': 0.006456784917491528, 'subsample': 0.730256422379517, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:24,866] Trial 455 finished with value: 0.000139544143466914 and parameters: {'n_estimators': 861, 'max_depth': 5, 'learning_rate': 0.007985232004134125, 'subsample': 0.7406458191495651, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:30,632] Trial 456 finished with value: 0.00013979437483075638 and parameters: {'n_estimators': 895, 'max_depth': 7, 'learning_rate': 0.00971786361199846, 'subsample': 0.7534492908542839, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:38,115] Trial 457 finished with value: 0.00013874443909533211 and parameters: {'n_estimators': 846, 'max_depth': 8, 'learning_rate': 0.0072659401355276345, 'subsample': 0.7688574615804256, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:42,670] Trial 458 finished with value: 0.0001398472461375174 and parameters: {'n_estimators': 875, 'max_depth': 6, 'learning_rate': 0.00875158464988534, 'subsample': 0.7810478027657107, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:44,355] Trial 459 finished with value: 0.00015702315013965158 and parameters: {'n_estimators': 904, 'max_depth': 3, 'learning_rate': 0.012868238427286722, 'subsample': 0.7399870048486028, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:50,472] Trial 460 finished with value: 0.00014045509181349422 and parameters: {'n_estimators': 980, 'max_depth': 7, 'learning_rate': 0.010870810229628072, 'subsample': 0.7603515738427218, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:11:58,589] Trial 461 finished with value: 0.0001409028382038819 and parameters: {'n_estimators': 938, 'max_depth': 8, 'learning_rate': 0.006269188333132618, 'subsample': 0.7326652234923016, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:00,896] Trial 462 finished with value: 0.00029474953853053773 and parameters: {'n_estimators': 318, 'max_depth': 7, 'learning_rate': 0.007905843202550717, 'subsample': 0.7501902772307009, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:08,142] Trial 463 finished with value: 0.00013806704394935773 and parameters: {'n_estimators': 914, 'max_depth': 8, 'learning_rate': 0.009459191835138098, 'subsample': 0.7695887415702269, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:14,881] Trial 464 finished with value: 0.00013882169040295417 and parameters: {'n_estimators': 884, 'max_depth': 7, 'learning_rate': 0.007308012519464207, 'subsample': 0.7903723330393384, 'subsample_freq': 8}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:21,570] Trial 465 finished with value: 0.00013840242836836084 and parameters: {'n_estimators': 961, 'max_depth': 7, 'learning_rate': 0.008647810234847094, 'subsample': 0.7446514444391608, 'subsample_freq': 6}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:28,201] Trial 466 finished with value: 0.00014733644182124287 and parameters: {'n_estimators': 926, 'max_depth': 7, 'learning_rate': 0.00516812966449196, 'subsample': 0.7241369504768637, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:35,124] Trial 467 finished with value: 0.00013877059019075047 and parameters: {'n_estimators': 900, 'max_depth': 8, 'learning_rate': 0.011468865220654913, 'subsample': 0.7572818690702738, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:39,396] Trial 468 finished with value: 0.00013940984945976187 and parameters: {'n_estimators': 946, 'max_depth': 7, 'learning_rate': 0.023949243485409225, 'subsample': 0.7053357958441749, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:41,233] Trial 469 finished with value: 0.0001683276579161705 and parameters: {'n_estimators': 224, 'max_depth': 8, 'learning_rate': 0.016486566990633836, 'subsample': 0.7761893153865943, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:47,343] Trial 470 finished with value: 0.000144375986087301 and parameters: {'n_estimators': 831, 'max_depth': 7, 'learning_rate': 0.0061477217111823, 'subsample': 0.7628786508885347, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:12:54,904] Trial 471 finished with value: 0.00013859905372008382 and parameters: {'n_estimators': 864, 'max_depth': 8, 'learning_rate': 0.007049152782716224, 'subsample': 0.7533429006648598, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:00,934] Trial 472 finished with value: 0.00013975530731649179 and parameters: {'n_estimators': 924, 'max_depth': 7, 'learning_rate': 0.00973263089192237, 'subsample': 0.7401065450631317, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:07,245] Trial 473 finished with value: 0.000137688710488976 and parameters: {'n_estimators': 883, 'max_depth': 7, 'learning_rate': 0.00830369520193926, 'subsample': 0.7664110443021681, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:14,261] Trial 474 finished with value: 0.0001372721883301464 and parameters: {'n_estimators': 964, 'max_depth': 7, 'learning_rate': 0.007798881548074801, 'subsample': 0.7462360807181413, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:21,304] Trial 475 finished with value: 0.00013894617376293447 and parameters: {'n_estimators': 984, 'max_depth': 7, 'learning_rate': 0.006924918327513684, 'subsample': 0.7377387744186717, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:27,902] Trial 476 finished with value: 0.00014081926852418876 and parameters: {'n_estimators': 965, 'max_depth': 7, 'learning_rate': 0.009386539578761233, 'subsample': 0.7264545912315582, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:35,037] Trial 477 finished with value: 0.00014198964411702092 and parameters: {'n_estimators': 981, 'max_depth': 7, 'learning_rate': 0.005796973307976911, 'subsample': 0.7448357351506377, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:40,879] Trial 478 finished with value: 0.0001397003342243765 and parameters: {'n_estimators': 958, 'max_depth': 7, 'learning_rate': 0.010849057808268227, 'subsample': 0.7483354443579868, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:47,652] Trial 479 finished with value: 0.00013782125774485472 and parameters: {'n_estimators': 945, 'max_depth': 7, 'learning_rate': 0.007927803120417496, 'subsample': 0.7584923228324848, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:13:53,112] Trial 480 finished with value: 0.0001397390536807056 and parameters: {'n_estimators': 991, 'max_depth': 6, 'learning_rate': 0.006845330418909581, 'subsample': 0.7313779797369598, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:00,271] Trial 481 finished with value: 0.00015898655847656736 and parameters: {'n_estimators': 946, 'max_depth': 7, 'learning_rate': 0.0042546814523051245, 'subsample': 0.7829850935925491, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:06,590] Trial 482 finished with value: 0.00014325820689326495 and parameters: {'n_estimators': 965, 'max_depth': 7, 'learning_rate': 0.00884593302577627, 'subsample': 0.6409395829096948, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:13,006] Trial 483 finished with value: 0.00014082449384885605 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.010039266858814925, 'subsample': 0.7979767651373915, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:16,258] Trial 484 finished with value: 0.00014319765367221045 and parameters: {'n_estimators': 933, 'max_depth': 7, 'learning_rate': 0.03427365376593642, 'subsample': 0.7730345649982422, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:19,243] Trial 485 finished with value: 0.00014303516231786205 and parameters: {'n_estimators': 385, 'max_depth': 7, 'learning_rate': 0.013664709536301889, 'subsample': 0.7435587998376407, 'subsample_freq': 3}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:25,759] Trial 486 finished with value: 0.0001505629943400033 and parameters: {'n_estimators': 899, 'max_depth': 7, 'learning_rate': 0.005032730664002143, 'subsample': 0.7164542817376527, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:32,807] Trial 487 finished with value: 0.0001380945710444445 and parameters: {'n_estimators': 972, 'max_depth': 7, 'learning_rate': 0.0076357969863219705, 'subsample': 0.7541120730652798, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:39,160] Trial 488 finished with value: 0.00013742218896513358 and parameters: {'n_estimators': 865, 'max_depth': 7, 'learning_rate': 0.008717254329358439, 'subsample': 0.7640764700413802, 'subsample_freq': 10}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:44,637] Trial 489 finished with value: 0.00014088622647566933 and parameters: {'n_estimators': 836, 'max_depth': 7, 'learning_rate': 0.012049912852622548, 'subsample': 0.7617884181513497, 'subsample_freq': 9}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:50,646] Trial 490 finished with value: 0.0001380121930878258 and parameters: {'n_estimators': 858, 'max_depth': 7, 'learning_rate': 0.009177792805799908, 'subsample': 0.7669760668448973, 'subsample_freq': 8}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:14:57,437] Trial 491 finished with value: 0.0001434716850108314 and parameters: {'n_estimators': 868, 'max_depth': 7, 'learning_rate': 0.006118610483656316, 'subsample': 0.7571705122530482, 'subsample_freq': 7}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:03,896] Trial 492 finished with value: 0.00013976212818786718 and parameters: {'n_estimators': 878, 'max_depth': 7, 'learning_rate': 0.007569108015188134, 'subsample': 0.7358613011055588, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:04,751] Trial 493 finished with value: 0.0012249205039872352 and parameters: {'n_estimators': 120, 'max_depth': 7, 'learning_rate': 0.010932229072329049, 'subsample': 0.6772087745733337, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:09,571] Trial 494 finished with value: 0.00013981116533593805 and parameters: {'n_estimators': 846, 'max_depth': 6, 'learning_rate': 0.008853146799123485, 'subsample': 0.7497796607067518, 'subsample_freq': 5}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:16,134] Trial 495 finished with value: 0.00013831621450718863 and parameters: {'n_estimators': 866, 'max_depth': 7, 'learning_rate': 0.007134183716019814, 'subsample': 0.7702732549897103, 'subsample_freq': 6}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:21,986] Trial 496 finished with value: 0.0001401248216185463 and parameters: {'n_estimators': 885, 'max_depth': 7, 'learning_rate': 0.01012942953228156, 'subsample': 0.7605075019577231, 'subsample_freq': 10}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:28,603] Trial 497 finished with value: 0.0001373757110551534 and parameters: {'n_estimators': 850, 'max_depth': 7, 'learning_rate': 0.008212213062803104, 'subsample': 0.745434226860623, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:35,085] Trial 498 finished with value: 0.0001417550595449683 and parameters: {'n_estimators': 847, 'max_depth': 7, 'learning_rate': 0.006606241390204332, 'subsample': 0.7423307686441352, 'subsample_freq': 10}. Best is trial 257 with value: 0.0001364654141317644.\n",
      "[I 2024-08-23 00:15:42,404] Trial 499 finished with value: 0.00013808691843066644 and parameters: {'n_estimators': 814, 'max_depth': 9, 'learning_rate': 0.00830632229637618, 'subsample': 0.7314722891563423, 'subsample_freq': 4}. Best is trial 257 with value: 0.0001364654141317644.\n"
     ]
    }
   ],
   "source": [
    "def optunaobjective(trial, X, y, cv, preprocessor):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1.0),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 10)\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        X_train_processed = preprocessor.fit_transform(X_train)\n",
    "        X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "        model.fit(X_train_processed, y_train)\n",
    "        pred = model.predict(X_val_processed)\n",
    "\n",
    "        score = mean_squared_error(y_val, pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "study.optimize(lambda trial: optunaobjective(trial, X, y, cv, preprocessor), n_trials=500)\n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kc_JTUMWK6xd"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_best = GradientBoostingRegressor(n_estimators=best_params['n_estimators'],\n",
    "                                    max_depth=best_params['max_depth'],\n",
    "                                    learning_rate=best_params['learning_rate'],\n",
    "                                    subsample=best_params['subsample'],\n",
    "                                    random_state=42)\n",
    "\n",
    "# XGBoost Regressor\n",
    "# Using **best_params to pass all optimized parameters at once\n",
    "xgb_best = XGBRegressor(**best_params, random_state=42)\n",
    "\n",
    "# LightGBM Regressor\n",
    "# using **best_params for consistency with XGBoost\n",
    "lgb_best = LGBMRegressor(**best_params, random_state=42)\n",
    "\n",
    "# Note: These models are initialized with optimized hyperparameters.\n",
    "# The 'best_params' dictionary is assumed to be obtained from a previous optimization process.\n",
    "# All models use random_state=42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9YkcA2EUK6t-"
   },
   "outputs": [],
   "source": [
    "# Elastic Net for L1 and L2 regularization\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ClYexHnTK6mK"
   },
   "outputs": [],
   "source": [
    "common_index = X.index.intersection(y.index)\n",
    "X = X.loc[common_index]\n",
    "y = y.loc[common_index]\n",
    "\n",
    "train_size = int(len(X) * 0.8)  \n",
    "split_date = X.index[train_size]\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:split_date], y[split_date:]\n",
    "\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "original_feature_names = X_train.columns.tolist()\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "if X_train.shape[1] != len(original_feature_names):\n",
    "    processed_feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "else:\n",
    "    processed_feature_names = original_feature_names\n",
    "\n",
    "X_train = pd.DataFrame(X_train, index=train_index, columns=processed_feature_names)\n",
    "X_test = pd.DataFrame(X_test, index=test_index, columns=processed_feature_names)\n",
    "\n",
    "selected_features = processed_feature_names\n",
    "\n",
    "y_train = y_train.loc[X_train.index]\n",
    "y_test = y_test.loc[X_test.index]\n",
    "\n",
    "original_index = X_train.index\n",
    "sample_weights = np.linspace(0.5, 1, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AP36CxfdK6jc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2624, 20)\n",
      "y_train shape: (2624,)\n",
      "sample_weights shape: (2624,)\n",
      "NaN in X_train: 0\n",
      "NaN in y_train: 0\n",
      "NaN in sample_weights: 0\n",
      "Length of X_train: 2624\n",
      "Length of y_train: 2624\n",
      "Length of sample_weights: 2624\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(X) * 0.8)  \n",
    "split_date = X.index[train_size]  \n",
    "X_train, X_test = X[:train_size], X[train_size:] \n",
    "y_train, y_test = y.loc[:split_date], y.loc[split_date:]  \n",
    "\n",
    "X_train_df = X_train.copy()\n",
    "y_train_df = y_train.copy()\n",
    "\n",
    "sample_weights_series = pd.Series(sample_weights, index=X_train.index)\n",
    "\n",
    "aligned_index = X_train_df.index.intersection(y_train_df.index).intersection(sample_weights_series.index)\n",
    "X_train_df = X_train_df.loc[aligned_index]\n",
    "y_train_df = y_train_df.loc[aligned_index]\n",
    "sample_weights_series = sample_weights_series.loc[aligned_index]\n",
    "\n",
    "# Converting back to numpy arrays  \n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "sample_weights = sample_weights_series.to_numpy()\n",
    "\n",
    "# Converting to float32 \n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "sample_weights = sample_weights.astype(np.float32)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"sample_weights shape:\", sample_weights.shape)\n",
    "print(\"NaN in X_train:\", np.isnan(X_train).sum())\n",
    "print(\"NaN in y_train:\", np.isnan(y_train).sum())\n",
    "print(\"NaN in sample_weights:\", np.isnan(sample_weights).sum())\n",
    "\n",
    "\n",
    "print(f\"Length of X_train: {len(X_train)}\")\n",
    "print(f\"Length of y_train: {len(y_train)}\")\n",
    "print(f\"Length of sample_weights: {len(sample_weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_N38tdwJK6hO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train = X_train.to_numpy()\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    X_test = X_test.to_numpy()\n",
    "\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Creating and training the LSTM model\n",
    "lstm_model = create_lstm_model((1, X_train.shape[1]), dropout_rate=0.5, neurons=[512, 256, 128])\n",
    "\n",
    "lstm_model.fit(\n",
    "    X_train_lstm,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "lstm_pred = lstm_model.predict(X_test_lstm).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eVKhNlw_K6ex"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.46275D+00    |proj g|=  1.03481D+00\n",
      "\n",
      "At iterate    5    f= -1.47535D+00    |proj g|=  2.83705D+00\n",
      "\n",
      "At iterate   10    f= -1.65001D+00    |proj g|=  8.31227D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f= -1.65188D+00    |proj g|=  7.58843D-01\n",
      "\n",
      "At iterate   20    f= -1.68836D+00    |proj g|=  1.09345D+00\n",
      "\n",
      "At iterate   25    f= -1.72871D+00    |proj g|=  1.13478D+00\n",
      "\n",
      "At iterate   30    f= -1.73018D+00    |proj g|=  4.60713D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     32     50      1     0     0   1.139D-03  -1.730D+00\n",
      "  F =  -1.7301796358678057     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    }
   ],
   "source": [
    "# SARIMA model creation and prediction\n",
    "\n",
    "# Using auto_arima to automatically find the best SARIMA parameters\n",
    "# seasonal=True: Enable seasonal component\n",
    "# m=7: Set the seasonal period to 7 \n",
    "auto_arima_model = auto_arima(y_train, seasonal=True, m=7)\n",
    "\n",
    "sarima_order = auto_arima_model.order \n",
    "sarima_seasonal_order = auto_arima_model.seasonal_order  \n",
    "\n",
    "sarima_model = SARIMAX(y_train, order=sarima_order, seasonal_order=sarima_seasonal_order)\n",
    "\n",
    "sarima_results = sarima_model.fit()\n",
    "\n",
    "sarima_pred = sarima_results.forecast(steps=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mis62jZ0K6cg"
   },
   "outputs": [],
   "source": [
    "# Exponential Smoothing model creation and prediction\n",
    "\n",
    "# trend='add': Use an additive trend component\n",
    "# seasonal='add': Use an additive seasonal component\n",
    "exp_smoothing = ExponentialSmoothing(y_train, seasonal_periods=7, trend='add', seasonal='add')\n",
    "\n",
    "exp_smoothing_results = exp_smoothing.fit()\n",
    "\n",
    "exp_smoothing_pred = exp_smoothing_results.forecast(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OmDx8SShK6aJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x31a8e0250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_df = pd.DataFrame({'ds': pd.to_datetime(original_index), 'y': y_train})\n",
    "\n",
    "# Initializing the Prophet model \n",
    "prophet_model = Prophet(changepoint_prior_scale=0.05, seasonality_prior_scale=10)\n",
    "\n",
    "prophet_model.fit(prophet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QK2STaFlK6Xl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 2624, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.015805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;gb&#x27;,\n",
       "                             GradientBoostingRegressor(learning_rate=0.009276672666863547,\n",
       "                                                       max_depth=7,\n",
       "                                                       n_estimators=887,\n",
       "                                                       random_state=42,\n",
       "                                                       subsample=0.7614289695621157)),\n",
       "                            (&#x27;xgb&#x27;,\n",
       "                             XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_ca...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          multi_strategy=None, n_estimators=887,\n",
       "                                          n_jobs=None, num_parallel_tree=None,\n",
       "                                          random_state=42, ...)),\n",
       "                            (&#x27;lgb&#x27;,\n",
       "                             LGBMRegressor(learning_rate=0.009276672666863547,\n",
       "                                           max_depth=7, n_estimators=887,\n",
       "                                           random_state=42,\n",
       "                                           subsample=0.7614289695621157,\n",
       "                                           subsample_freq=4)),\n",
       "                            (&#x27;elastic_net&#x27;,\n",
       "                             ElasticNet(alpha=0.1, random_state=42))],\n",
       "                weights=[2, 2, 2, 1])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VotingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.VotingRegressor.html\">?<span>Documentation for VotingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VotingRegressor(estimators=[(&#x27;gb&#x27;,\n",
       "                             GradientBoostingRegressor(learning_rate=0.009276672666863547,\n",
       "                                                       max_depth=7,\n",
       "                                                       n_estimators=887,\n",
       "                                                       random_state=42,\n",
       "                                                       subsample=0.7614289695621157)),\n",
       "                            (&#x27;xgb&#x27;,\n",
       "                             XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_ca...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          multi_strategy=None, n_estimators=887,\n",
       "                                          n_jobs=None, num_parallel_tree=None,\n",
       "                                          random_state=42, ...)),\n",
       "                            (&#x27;lgb&#x27;,\n",
       "                             LGBMRegressor(learning_rate=0.009276672666863547,\n",
       "                                           max_depth=7, n_estimators=887,\n",
       "                                           random_state=42,\n",
       "                                           subsample=0.7614289695621157,\n",
       "                                           subsample_freq=4)),\n",
       "                            (&#x27;elastic_net&#x27;,\n",
       "                             ElasticNet(alpha=0.1, random_state=42))],\n",
       "                weights=[2, 2, 2, 1])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.009276672666863547, max_depth=7,\n",
       "                          n_estimators=887, random_state=42,\n",
       "                          subsample=0.7614289695621157)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.009276672666863547,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=887, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(learning_rate=0.009276672666863547, max_depth=7, n_estimators=887,\n",
       "              random_state=42, subsample=0.7614289695621157, subsample_freq=4)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>elastic_net</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet(alpha=0.1, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('gb',\n",
       "                             GradientBoostingRegressor(learning_rate=0.009276672666863547,\n",
       "                                                       max_depth=7,\n",
       "                                                       n_estimators=887,\n",
       "                                                       random_state=42,\n",
       "                                                       subsample=0.7614289695621157)),\n",
       "                            ('xgb',\n",
       "                             XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_ca...\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          multi_strategy=None, n_estimators=887,\n",
       "                                          n_jobs=None, num_parallel_tree=None,\n",
       "                                          random_state=42, ...)),\n",
       "                            ('lgb',\n",
       "                             LGBMRegressor(learning_rate=0.009276672666863547,\n",
       "                                           max_depth=7, n_estimators=887,\n",
       "                                           random_state=42,\n",
       "                                           subsample=0.7614289695621157,\n",
       "                                           subsample_freq=4)),\n",
       "                            ('elastic_net',\n",
       "                             ElasticNet(alpha=0.1, random_state=42))],\n",
       "                weights=[2, 2, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an ensemble model using VotingRegressor\n",
    "ensemble = VotingRegressor([\n",
    "    ('gb', gb_best),    \n",
    "    ('xgb', xgb_best), \n",
    "    ('lgb', lgb_best),  \n",
    "    ('elastic_net', elastic_net) \n",
    "], weights=[2, 2, 2, 1])  # Assigning weights to each model \n",
    "\n",
    "ensemble.fit(X_train, y_train, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "vsI32Wp4OyHr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFECV selected 4 features\n",
      "LASSO selected 1 features\n",
      "Random Forest selected 14 features\n",
      "Mutual Information selected 14 features\n",
      "Combined selection: 20 features\n",
      "\n",
      "Top 10 features by Random Forest importance:\n",
      "Close_Pct_Change_7: 0.5254\n",
      "ROC_7: 0.4689\n",
      "Volume_Lag_240: 0.0012\n",
      "Close_Pct_Change_14: 0.0008\n",
      "Price_Momentum: 0.0007\n",
      "Stoch_K: 0.0003\n",
      "ROC_14: 0.0003\n",
      "Zigzag_Indicator_Lag_3: 0.0003\n",
      "Volatility_Ratio_Lag_7: 0.0003\n",
      "RSI_30: 0.0002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 2624, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.017048\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('7d_ROI', axis=1) \n",
    "y = df['7d_ROI']  \n",
    "\n",
    "# Performing feature selection\n",
    "selected_features = advanced_feature_selection(X, y)  \n",
    "\n",
    "X = X[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_best.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# XGBoost\n",
    "xgb_best.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# LightGBM\n",
    "lgb_best.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Elastic Net\n",
    "elastic_net.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Making predictions using each model\n",
    "gb_pred = gb_best.predict(X_test)\n",
    "xgb_pred = xgb_best.predict(X_test)\n",
    "lgb_pred = lgb_best.predict(X_test)\n",
    "elastic_net_pred = elastic_net.predict(X_test)\n",
    "\n",
    "# LSTM prediction\n",
    "lstm_pred = lstm_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "# SARIMA prediction\n",
    "sarima_pred = sarima_results.forecast(steps=len(X_test))\n",
    "\n",
    "# Exponential Smoothing prediction\n",
    "exp_smoothing_pred = exp_smoothing_results.forecast(len(X_test))\n",
    "\n",
    "# Prophet prediction\n",
    "prophet_future = prophet_model.make_future_dataframe(periods=len(X_test), freq='D')\n",
    "prophet_forecast = prophet_model.predict(prophet_future)\n",
    "prophet_pred = prophet_forecast.tail(len(X_test))['yhat'].values\n",
    "\n",
    "# Ensemble prediction \n",
    "ensemble_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Xf82vmiAOyEx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3274, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.016969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.51884D+00    |proj g|=  1.30821D+00\n",
      "\n",
      "At iterate    5    f= -1.71228D+00    |proj g|=  4.88091D-01\n",
      "\n",
      "At iterate   10    f= -1.71660D+00    |proj g|=  2.02799D+00\n",
      "\n",
      "At iterate   15    f= -1.78697D+00    |proj g|=  7.62776D-01\n",
      "\n",
      "At iterate   20    f= -1.79147D+00    |proj g|=  7.46326D-02\n",
      "\n",
      "At iterate   25    f= -1.79156D+00    |proj g|=  8.26406D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     26     38      1     0     0   6.601D-06  -1.792D+00\n",
      "  F =  -1.7915649384834120     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:24:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3274, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.016969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Updating the training and test sets\n",
    "latest_date = df.index[-1]\n",
    "test_start_date = latest_date - timedelta(days=6)\n",
    "X_train = X[X.index < test_start_date]\n",
    "X_test = X[X.index >= test_start_date]\n",
    "y_train = y[y.index < test_start_date]\n",
    "y_test = y[y.index >= test_start_date]\n",
    "\n",
    "# Retraining models on the updated training data\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_best.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "# LightGBM\n",
    "lgb_best.fit(X_train, y_train)\n",
    "\n",
    "# Elastic Net\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "y_train_lstm = y_train.values\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=200, batch_size=32, verbose=0)\n",
    "\n",
    "# SARIMA\n",
    "sarima_model = SARIMAX(y_train, order=sarima_order, seasonal_order=sarima_seasonal_order)\n",
    "sarima_results = sarima_model.fit()\n",
    "\n",
    "# Exponential Smoothing\n",
    "exp_smoothing = ExponentialSmoothing(y_train, seasonal_periods=7, trend='add', seasonal='add')\n",
    "exp_smoothing_results = exp_smoothing.fit()\n",
    "\n",
    "# Prophet\n",
    "prophet_df_train = pd.DataFrame({'ds': X_train.index, 'y': y_train})\n",
    "prophet_model = Prophet(changepoint_prior_scale=0.05, seasonality_prior_scale=10)\n",
    "prophet_model.fit(prophet_df_train)\n",
    "\n",
    "# Ensemble\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Generating predictions with the new test set\n",
    "\n",
    "# Gradient Boosting prediction\n",
    "gb_pred = gb_best.predict(X_test)\n",
    "\n",
    "# XGBoost prediction\n",
    "xgb_pred = xgb_best.predict(X_test)\n",
    "\n",
    "# LightGBM prediction\n",
    "lgb_pred = lgb_best.predict(X_test)\n",
    "\n",
    "# Elastic Net prediction\n",
    "elastic_net_pred = elastic_net.predict(X_test)\n",
    "\n",
    "# LSTM prediction\n",
    "X_test_lstm = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "lstm_pred = lstm_model.predict(X_test_lstm).flatten()\n",
    "\n",
    "# SARIMA prediction\n",
    "sarima_pred = sarima_results.forecast(steps=len(X_test))\n",
    "\n",
    "# Exponential Smoothing prediction\n",
    "exp_smoothing_pred = exp_smoothing_results.forecast(len(X_test))\n",
    "\n",
    "# Prophet prediction\n",
    "prophet_future = prophet_model.make_future_dataframe(periods=len(X_test), freq='D')\n",
    "prophet_forecast = prophet_model.predict(prophet_future)\n",
    "prophet_pred = prophet_forecast.tail(len(X_test))['yhat'].values\n",
    "\n",
    "# Ensemble prediction\n",
    "ensemble_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JolsffBDOyCP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on data from 2024-08-15 00:00:00 to 2024-08-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def dynamic_ensemble_weights(predictions, y_test):\n",
    "    \"\"\"\n",
    "    Calculating dynamic weights for ensemble predictions based on absolute errors.\n",
    "    \"\"\"\n",
    "    # Calculating absolute errors for each model's predictions\n",
    "    errors = np.abs(np.array(predictions) - y_test.values.reshape(-1, 1))\n",
    "\n",
    "    # Calculating weights as inverse of errors (with small constant to avoid division by zero)\n",
    "    weights = 1 / (errors + 1e-8)\n",
    "\n",
    "    # Normalizing weights so they sum to 1 for each sample\n",
    "    weights = weights / np.sum(weights, axis=1, keepdims=True)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Stack predictions from different models into a single array\n",
    "predictions = np.column_stack([\n",
    "    gb_pred, xgb_pred, lgb_pred, elastic_net_pred,\n",
    "    lstm_pred, sarima_pred, exp_smoothing_pred,\n",
    "    prophet_pred, ensemble_pred\n",
    "])\n",
    "\n",
    "# Calculating dynamic weights based on prediction errors\n",
    "weights = dynamic_ensemble_weights(predictions, y_test)\n",
    "\n",
    "# Computing final predictions as weighted sum of individual model predictions\n",
    "y_pred = np.sum(predictions * weights, axis=1)\n",
    "\n",
    "print(f\"Evaluating model on data from {test_start_date} to {latest_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "5PkJrBrGOx_u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.000075\n",
      "Root Mean Squared Error: 0.000095\n",
      "R-squared: 0.999991\n",
      "Mean Absolute Percentage Error: 0.005901\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# Printing evaluation metrics\n",
    "print(f'Mean Absolute Error: {mae:.6f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.6f}')\n",
    "print(f'R-squared: {r2:.6f}')\n",
    "print(f'Mean Absolute Percentage Error: {mape:.6f}')\n",
    "\n",
    "def fit_model_with_error_handling(model, X, y):\n",
    "    try:\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting model: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_with_error_handling(model, X):\n",
    "    if model is None:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return model.predict(X)\n",
    "    except Exception as e:\n",
    "        print(f\"Error making prediction: {e}\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "WyoI4weTOx9F"
   },
   "outputs": [],
   "source": [
    "gb_best = fit_model_with_error_handling(gb_best, X_train, y_train)\n",
    "gb_pred = predict_with_error_handling(gb_best, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\n",
      "Bitcoin price at 2024-08-22 13:00:00-07:53: $60414.97 USD\n",
      "Forecasted Bitcoin price at 2024-08-29 13:00:00-07:53: $60264.90 USD\n",
      "Forecasted 7-day ROI: -0.25%\n",
      "\n",
      "Daily predictions:\n",
      "Date: 2024-08-22 13:00:00-07:53, Daily ROI: 0.27%, Classification: Choppy\n",
      "Date: 2024-08-23 13:00:00-07:53, Daily ROI: 0.04%, Classification: Choppy\n",
      "Date: 2024-08-24 13:00:00-07:53, Daily ROI: -0.09%, Classification: Weak Bear\n",
      "Date: 2024-08-25 13:00:00-07:53, Daily ROI: 0.13%, Classification: Choppy\n",
      "Date: 2024-08-26 13:00:00-07:53, Daily ROI: -0.09%, Classification: Weak Bear\n",
      "Date: 2024-08-27 13:00:00-07:53, Daily ROI: 0.06%, Classification: Choppy\n",
      "Date: 2024-08-28 13:00:00-07:53, Daily ROI: -0.30%, Classification: Weak Bear\n",
      "Date: 2024-08-29 13:00:00-07:53, Daily ROI: -0.26%, Classification: Weak Bear\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                   feature  importance\n",
      "4                    ROC_7    0.516955\n",
      "13      Close_Pct_Change_7    0.477435\n",
      "10          Volume_Lag_240    0.000808\n",
      "6                   RSI_14    0.000741\n",
      "16  Volatility_Ratio_Lag_7    0.000591\n",
      "7           Price_Momentum    0.000584\n",
      "2                   RSI_30    0.000531\n",
      "14                 Stoch_D    0.000477\n",
      "8   Zigzag_Indicator_Lag_3    0.000462\n",
      "11                 Stoch_K    0.000443\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def predict_bitcoin_price(start_prediction_date):\n",
    "    \n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    start_date = \"2015-01-01\"\n",
    "    df = get_bitcoin_data_yfinance_format(start_date, end_date)\n",
    "\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize('UTC')\n",
    "    pacific = pytz.timezone('US/Pacific')\n",
    "    df.index = df.index.tz_convert(pacific)\n",
    "\n",
    "    def plot_roi(data, title, start_date=None, end_date=None):\n",
    "        if start_date:\n",
    "            data = data.loc[data.index >= start_date]\n",
    "        if end_date:\n",
    "            data = data.loc[data.index <= end_date]\n",
    "    \n",
    "        plt.figure(figsize=(14, 8))\n",
    "    \n",
    "        plt.plot(data.index, data['Actual'], label='Actual', color='blue', alpha=0.7)\n",
    "        plt.plot(data.index, data['Predicted'], label='Predicted', color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('7-day ROI', fontsize=12)\n",
    "        plt.legend(fontsize=10)\n",
    "    \n",
    "        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        plt.gcf().autofmt_xdate()\n",
    "    \n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "        y_min, y_max = plt.ylim()\n",
    "        plt.ylim(y_min - 0.05, y_max + 0.05)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    start_prediction = start_prediction_date.replace(tzinfo=pacific)\n",
    "    end_prediction = start_prediction + timedelta(days=7)\n",
    "\n",
    "    df_plot = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "    latest_data = df[df.index <= start_prediction].iloc[-365:].copy()\n",
    "    latest_data = engineer_features(latest_data)\n",
    "\n",
    "    if not latest_data.empty:\n",
    "        forecast_dates = [start_prediction + timedelta(days=i) for i in range(8)]\n",
    "        forecast_results = []\n",
    "\n",
    "        for forecast_date in forecast_dates:\n",
    "            try:\n",
    "                # Preparing data for the current forecast date\n",
    "                latest_data_copy = latest_data.iloc[-1:].copy()\n",
    "                latest_data_copy.index = [forecast_date]\n",
    "                latest_data_copy['Sentiment'] = get_crypto_sentiment()\n",
    "\n",
    "                missing_features = set(selected_features) - set(latest_data_copy.columns)\n",
    "                if missing_features:\n",
    "                    print(f\"Warning: Missing features for date {forecast_date}: {missing_features}\")\n",
    "                    for feature in missing_features:\n",
    "                        latest_data_copy[feature] = 0  \n",
    "\n",
    "                latest_data_processed = preprocessor.transform(latest_data_copy[selected_features])\n",
    "\n",
    "                # Making predictions using all models\n",
    "                model_predictions = {\n",
    "                    'Gradient Boosting': gb_best.predict(latest_data_processed)[0],\n",
    "                    'XGBoost': xgb_best.predict(latest_data_processed)[0],\n",
    "                    'LightGBM': lgb_best.predict(latest_data_processed)[0],\n",
    "                    'Elastic Net': elastic_net.predict(latest_data_processed)[0],\n",
    "                    'LSTM': lstm_model.predict(latest_data_processed.reshape((1, 1, latest_data_processed.shape[1])))[0][0],\n",
    "                    'SARIMA': sarima_results.forecast(steps=1)[0],\n",
    "                    'Exponential Smoothing': exp_smoothing_results.forecast(1)[0],\n",
    "                    'Prophet': prophet_model.predict(prophet_model.make_future_dataframe(periods=1, freq='D')).iloc[-1]['yhat'],\n",
    "                    'Ensemble': ensemble.predict(latest_data_processed)[0]\n",
    "                }\n",
    "\n",
    "                # Calculating ensemble prediction with dynamic weighting\n",
    "                ensemble_weights = np.array(list(model_predictions.values()))\n",
    "                ensemble_weights = 1 / (np.abs(ensemble_weights) + 1e-8)  # Avoid division by zero\n",
    "                ensemble_weights /= np.sum(ensemble_weights)\n",
    "                ensemble_prediction = sum(ensemble_weights[i] * pred for i, pred in enumerate(model_predictions.values()))\n",
    "\n",
    "                # Storing forecast results\n",
    "                forecast_results.append({\n",
    "                    'Date': forecast_date,\n",
    "                    'Prediction': ensemble_prediction,\n",
    "                    'Classification': classify_prediction(ensemble_prediction)\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error forecasting for {forecast_date}: {e}\")\n",
    "                forecast_results.append({\n",
    "                    'Date': forecast_date,\n",
    "                    'Prediction': np.nan,\n",
    "                    'Classification': 'Unknown'\n",
    "                })\n",
    "\n",
    "            latest_data = pd.concat([latest_data, latest_data_copy])\n",
    "            latest_data = engineer_features(latest_data)\n",
    "\n",
    "        # Calculating 7-day ROI\n",
    "        start_price = df[df.index <= start_prediction]['Close'].iloc[-1]\n",
    "        end_price = start_price * np.prod([1 + result['Prediction'] for result in forecast_results])\n",
    "        roi_7d = (end_price - start_price) / start_price\n",
    "\n",
    "        print(f\"\\nBitcoin price at {start_prediction}: ${start_price:.2f} USD\")\n",
    "        print(f\"Forecasted Bitcoin price at {end_prediction}: ${end_price:.2f} USD\")\n",
    "        print(f\"Forecasted 7-day ROI: {roi_7d * 100:.2f}%\")\n",
    "\n",
    "        print(\"\\nDaily predictions:\")\n",
    "        for result in forecast_results:\n",
    "            print(f\"Date: {result['Date']}, Daily ROI: {result['Prediction']*100:.2f}%, Classification: {result['Classification']}\")\n",
    "\n",
    "        # Feature importance analysis\n",
    "        if hasattr(gb_best, 'feature_names_in_'):\n",
    "            actual_features = gb_best.feature_names_in_\n",
    "        elif len(selected_features) == len(gb_best.feature_importances_):\n",
    "            actual_features = selected_features\n",
    "        else:\n",
    "            print(\"Warning: Number of features in the model doesn't match the number of selected features.\")\n",
    "            print(\"Using generic feature names.\")\n",
    "            actual_features = [f'feature_{i}' for i in range(len(gb_best.feature_importances_))]\n",
    "\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': actual_features,\n",
    "            'importance': gb_best.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_importance.head(10))\n",
    "\n",
    "        # SHAP values for model interpretability\n",
    "        explainer = shap.TreeExplainer(gb_best)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=actual_features, show=False)\n",
    "        plt.title(\"SHAP Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot ROI\n",
    "        plot_roi(df_plot, 'Actual vs Predicted 7-day ROI (Full Dataset)')\n",
    "\n",
    "    else:\n",
    "        print(\"Error: No data available for the specified date range.\")\n",
    "\n",
    "\n",
    "\n",
    "# Call the function with the desired start prediction date\n",
    "predict_bitcoin_price(datetime(2024, 8, 22, 13, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
